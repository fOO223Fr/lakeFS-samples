{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e42664a",
   "metadata": {},
   "source": [
    "<img src=\"./images/logo.svg\" alt=\"lakeFS logo\" width=300/> \n",
    "\n",
    "# Using multiple [hooks]((https://docs.lakefs.io/hooks/)) in lakeFS (similar to GitHub Actions)\n",
    "\n",
    "Use Cases:\n",
    "\n",
    "1. Don't allow PII data\n",
    "2. Don't allow unintended schema changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba212d7e",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "**_If you're not using the provided lakeFS server and MinIO storage then change these values to match your environment_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8562cd9c",
   "metadata": {},
   "source": [
    "### lakeFS endpoint and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3996e294",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefsEndPoint = 'http://lakefs:8000' # e.g. 'https://username.aws_region_name.lakefscloud.io' \n",
    "lakefsAccessKey = 'AKIAIOSFODNN7EXAMPLE'\n",
    "lakefsSecretKey = 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301bf027",
   "metadata": {},
   "source": [
    "### Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f8d66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storageNamespace = 's3://example' # e.g. \"s3://bucket\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfed2068",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dbf6a2",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "**(you shouldn't need to change anything in this section, just run it)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b2ba0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_name = \"schema-and-pii-validation-example\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c279b3fb",
   "metadata": {},
   "source": [
    "### Create lakeFSClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d980f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lakefs_client\n",
    "from lakefs_client.models import *\n",
    "from lakefs_client.client import LakeFSClient\n",
    "\n",
    "# lakeFS credentials and endpoint\n",
    "configuration = lakefs_client.Configuration()\n",
    "configuration.username = lakefsAccessKey\n",
    "configuration.password = lakefsSecretKey\n",
    "configuration.host = lakefsEndPoint\n",
    "\n",
    "lakefs = LakeFSClient(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce092a6",
   "metadata": {},
   "source": [
    "#### Verify lakeFS credentials by getting lakeFS version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874b5e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Verifying lakeFS credentials‚Ä¶\")\n",
    "try:\n",
    "    v=lakefs.config.get_lake_fs_version()\n",
    "except:\n",
    "    print(\"üõë failed to get lakeFS version\")\n",
    "else:\n",
    "    print(f\"‚Ä¶‚úÖlakeFS credentials verified\\n\\n‚ÑπÔ∏èlakeFS version{v.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6cb699",
   "metadata": {},
   "source": [
    "### Define lakeFS Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f1457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lakefs_client.exceptions import NotFoundException\n",
    "\n",
    "try:\n",
    "    repo=lakefs.repositories.get_repository(repo_name)\n",
    "    print(f\"Found existing repo {repo.id} using storage namespace {repo.storage_namespace}\")\n",
    "except NotFoundException as f:\n",
    "    print(f\"Repository {repo_name} does not exist, so going to try and create it now.\")\n",
    "    try:\n",
    "        repo=lakefs.repositories.create_repository(repository_creation=RepositoryCreation(name=repo_name,\n",
    "                                                                                                storage_namespace=f\"{storageNamespace}/{repo_name}\"))\n",
    "        print(f\"Created new repo {repo.id} using storage namespace {repo.storage_namespace}\")\n",
    "    except lakefs_client.ApiException as e:\n",
    "        print(f\"Error creating repo {repo_name}. Error is {e}\")\n",
    "        os._exit(00)\n",
    "except lakefs_client.ApiException as e:\n",
    "    print(f\"Error getting repo {repo_name}: {e}\")\n",
    "    os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755ce40e",
   "metadata": {},
   "source": [
    "### Set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17541fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ByteType, IntegerType, LongType, StringType, StructType, StructField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef72d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"lakeFS / Jupyter\") \\\n",
    "        .config(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", lakefsEndPoint) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", lakefsAccessKey) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", lakefsSecretKey) \\\n",
    "        .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.3.0\") \\\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "        .config(\"spark.delta.logStore.class\", \"org.apache.spark.sql.delta.storage.S3SingleDriverLogStore\") \\\n",
    "        .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a71473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mainBranch = \"main\"\n",
    "schemaValidationBranch1stAttempt = \"schema_validation_branch_1st_attempt\"\n",
    "schemaValidationBranch2ndAttempt = \"schema_validation_branch_2nd_attempt\"\n",
    "schemaChangeBranch = \"schema_change_branch\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0a9e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b33b29",
   "metadata": {},
   "source": [
    "# Main demo starts here üö¶ üëáüèª"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85af001",
   "metadata": {},
   "source": [
    "## Setup and Configure Hook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f93b4c2",
   "metadata": {},
   "source": [
    "### Configure hooks in the repository\n",
    "\n",
    "* Upload [Hooks config YAML file](./LuaHooks/pre-merge-schema-validation.yaml) for schema validation to check for any schema changes before data is merged to main branch\n",
    "* Hooks config file must be uploaded to \"_lakefs_actions\" prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0755e65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hooks_config_yaml = \"pre-merge-schema-and-pii-validation.yaml\"\n",
    "hooks_prefix = \"_lakefs_actions\"\n",
    "with open(f'./hooks/{hooks_config_yaml}', 'rb') as f:\n",
    "    lakefs.objects.upload_object(repository=repo.id, \n",
    "                                 branch=mainBranch, \n",
    "                                 path=f'{hooks_prefix}/{hooks_config_yaml}', \n",
    "                                 content=f\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f87a95",
   "metadata": {},
   "source": [
    "### Upload script\n",
    "\n",
    "The script (`hooks/parquet_schema_change.lua`) checks for any schema changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cac7ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lua_script_file_names = [\"parquet_schema_validator.lua\", \"parquet_schema_change.lua\"]\n",
    "lua_scripts_path = \"scripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce9abe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fn in lua_script_file_names:\n",
    "    with open(f'./hooks/{fn}', 'rb') as f:\n",
    "        lakefs.objects.upload_object(repository=repo.id, \n",
    "                                    branch=mainBranch, \n",
    "                                    path=f'{lua_scripts_path}/{fn}', \n",
    "                                    content=f\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf92989",
   "metadata": {},
   "source": [
    "### Commit changes to the lakeFS repo and attach some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b3b1b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(\n",
    "    repository=repo.id,\n",
    "    branch=mainBranch,\n",
    "    commit_creation=CommitCreation(\n",
    "        message='Added hooks config file validation scripts'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194bbe34-db01-4128-84d9-43d782aa3a77",
   "metadata": {},
   "source": [
    "# ETL Job Starts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a7ce6-c23e-4529-91d4-d50c7e273ca4",
   "metadata": {},
   "source": [
    "## Create a new branch which will be used to ingest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa8e43-f998-4e66-835f-6b3c38dca0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.branches.create_branch(\n",
    "    repository=repo.id, \n",
    "    branch_creation=BranchCreation(\n",
    "        name=schemaValidationBranch1stAttempt, source=mainBranch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5dde0-d39b-4ecd-b3c4-0d16968f4c29",
   "metadata": {},
   "source": [
    "## For this demo - we'll be utilizing a dataset - [Orion Star - Sports and outdoors RDBMS dataset](https://www.kaggle.com/datasets/chethanp11/orion-star-sports-and-outdoors-rdbms-dataset) from [Kaggle](https://www.kaggle.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee4da42-2d3c-4e1c-9b9b-91925d6d659c",
   "metadata": {},
   "source": [
    "## Define [CUSTOMER.csv](../data/samples/OrionStar/CUSTOMER.csv) data file schema\n",
    "\n",
    "#### Notice that 1st column, \"user_id\" is not allowed as blocked PII columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad323351-29ab-4f97-83bc-dd4d81f663d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customersSchema = StructType([\n",
    "  StructField(\"user_id\", IntegerType(), False), # \"user_id\" is not allowed as blocked PII columns.\n",
    "  StructField(\"Country\", StringType(), False),\n",
    "  StructField(\"Gender\", StringType(), False),\n",
    "  StructField(\"Personal_ID\", IntegerType(), True),\n",
    "  StructField(\"Customer_Name\", StringType(), False),\n",
    "  StructField(\"Customer_FirstName\", StringType(), False),\n",
    "  StructField(\"Customer_LastName\", StringType(), False),\n",
    "  StructField(\"Birth_Date\", StringType(), False),\n",
    "  StructField(\"Customer_Address\", StringType(), False),\n",
    "  StructField(\"Street_ID\", LongType(), False),\n",
    "  StructField(\"Street_Number\", IntegerType(), False),\n",
    "  StructField(\"Customer_Type_ID\", IntegerType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a30a2-dc6f-4774-b960-2b16b460d658",
   "metadata": {},
   "source": [
    "## Define [ORDER_FACT.csv](../data/samples/OrionStar/ORDER_FACT.csv) data file schema\n",
    "\n",
    "#### Notice that 1st column \"user_id\" is not allowed as blocked PII columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eb674c-8837-4d25-85c2-8681606f65b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ordersSchema = StructType([\n",
    "  StructField(\"user_id\", IntegerType(), False), # \"user_id\" is not allowed as blocked PII columns.\n",
    "  StructField(\"Employee_ID\", IntegerType(), False),\n",
    "  StructField(\"Street_ID\", LongType(), False),\n",
    "  StructField(\"Order_Date\", StringType(), False),\n",
    "  StructField(\"Delivery_Date\", StringType(), False),\n",
    "  StructField(\"Order_ID\", LongType(), True),\n",
    "  StructField(\"Order_Type\", ByteType(), False),\n",
    "  StructField(\"Product_ID\", LongType(), False),\n",
    "  StructField(\"Quantity\", ByteType(), False),\n",
    "  StructField(\"Total_Retail_Price\", StringType(), False),\n",
    "  StructField(\"CostPrice_Per_Unit\", StringType(), False),\n",
    "  StructField(\"Discount\", LongType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed8461a-6eb8-49d0-9652-229c7465c095",
   "metadata": {},
   "source": [
    "## Create Customers delta table in the new branch (using [CUSTOMER.csv](./data/samples/OrionStar/CUSTOMER.csv) file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca91e8de-7a05-468c-ad1a-05a2db3071d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customersTablePath = f\"s3a://{repo.id}/{schemaValidationBranch1stAttempt}/tables/customers\"\n",
    "df = spark.read.csv('/data/OrionStar/CUSTOMER.csv',header=True,schema=customersSchema)\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(customersTablePath)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b5d0f-1b43-4ac0-83ee-66a299ce35c2",
   "metadata": {},
   "source": [
    "## Create Orders delta table in the new branch (using [ORDER_FACT.csv](./data/samples/OrionStar/ORDER_FACT.csv) file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc14097-bfe7-4783-a559-53df4a1e9b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ordersTablePath = f\"s3a://{repo.id}/{schemaValidationBranch1stAttempt}/tables/orders\"\n",
    "df = spark.read.csv('/data/OrionStar/ORDER_FACT.csv',header=True,schema=ordersSchema)\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(ordersTablePath)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c751463-94ae-42e2-92e4-b8ff42b8d73d",
   "metadata": {},
   "source": [
    "## Commit changes and attach some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c59fde-bdd4-40ae-af01-05d4f85e06c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(\n",
    "    repository=repo.id,\n",
    "    branch=schemaValidationBranch1stAttempt,\n",
    "    commit_creation=CommitCreation(\n",
    "        message='Added customers and orders Delta tables!', \n",
    "        metadata={'using': 'python_api'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a3b56d-e4c5-4a9b-90ff-bac820520e92",
   "metadata": {},
   "source": [
    "## Merge new branch to the main branch.\n",
    "\n",
    "#### üõëüõë Merge will fail because Delta tables have blocked column i.e. user_id.  Review the error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf5219-f8e5-456c-ac34-906f2197d7be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.refs.merge_into_branch(\n",
    "    repository=repo.id,\n",
    "    source_ref=schemaValidationBranch1stAttempt, \n",
    "    destination_branch=mainBranch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5845674-99f9-4974-81ac-f5e7df8e94b8",
   "metadata": {},
   "source": [
    "The error will look like this: \n",
    "    \n",
    "```\n",
    "(412)\n",
    "Reason: Precondition Failed\n",
    "```\n",
    "    \n",
    "```\n",
    "update branch main: pre-merge hook aborted, run id '5ir9j6ol1aas77gat540': 1 error occurred:\n",
    "    * hook run id '0000_0000' failed on action 'pre merge checks on main branch' \n",
    "                                          hook 'check_blocked_pii_columns': \n",
    "    runtime error: [string \\\"lua\\\"]:47: Column is not allowed: 'user_id': type: INT32 \n",
    "    in path: tables/customers/part-00000-bfe440bc-787d-4b4f-a8f8-0b0761e13536-c000.snappy.parquet\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cab646-5817-4a79-ae68-ca5d29cc3d34",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7408739-f73e-4da4-95bf-2f21e08c045e",
   "metadata": {},
   "source": [
    "## Let's attempt to ingest data again without any PII columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d25b55-4bfa-4557-a022-05af5df585b7",
   "metadata": {},
   "source": [
    "#### Create a new branch for 2nd attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3912867-c9fe-4d28-b391-c310f6437070",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakefs.branches.create_branch(\n",
    "    repository=repo.id, \n",
    "    branch_creation=BranchCreation(\n",
    "        name=schemaValidationBranch2ndAttempt, source=mainBranch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014cf814-d285-463f-a67b-beb9e67632d8",
   "metadata": {},
   "source": [
    "## Change \"user_id\" column to \"Customer_ID\" in the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dd66db-530d-462c-88a5-d8432585af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "customersSchema = StructType([\n",
    "  StructField(\"Customer_ID\", IntegerType(), False), # Change \"user_id\" column to \"Customer_ID\"\n",
    "  StructField(\"Country\", StringType(), False),\n",
    "  StructField(\"Gender\", StringType(), False),\n",
    "  StructField(\"Personal_ID\", IntegerType(), True),\n",
    "  StructField(\"Customer_Name\", StringType(), False),\n",
    "  StructField(\"Customer_FirstName\", StringType(), False),\n",
    "  StructField(\"Customer_LastName\", StringType(), False),\n",
    "  StructField(\"Birth_Date\", StringType(), False),\n",
    "  StructField(\"Customer_Address\", StringType(), False),\n",
    "  StructField(\"Street_ID\", LongType(), False),\n",
    "  StructField(\"Street_Number\", IntegerType(), False),\n",
    "  StructField(\"Customer_Type_ID\", IntegerType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67037c82-709f-493c-bdf0-32d58bc0c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordersSchema = StructType([\n",
    "  StructField(\"Customer_ID\", IntegerType(), False), # Change \"user_id\" column to \"Customer_ID\"\n",
    "  StructField(\"Employee_ID\", IntegerType(), False),\n",
    "  StructField(\"Street_ID\", LongType(), False),\n",
    "  StructField(\"Order_Date\", StringType(), False),\n",
    "  StructField(\"Delivery_Date\", StringType(), False),\n",
    "  StructField(\"Order_ID\", LongType(), True),\n",
    "  StructField(\"Order_Type\", ByteType(), False),\n",
    "  StructField(\"Product_ID\", LongType(), False),\n",
    "  StructField(\"Quantity\", ByteType(), False),\n",
    "  StructField(\"Total_Retail_Price\", StringType(), False),\n",
    "  StructField(\"CostPrice_Per_Unit\", StringType(), False),\n",
    "  StructField(\"Discount\", LongType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5784d4e7-f9c9-4e33-baea-da515c6bc5f3",
   "metadata": {},
   "source": [
    "## Create Customers delta table in the new branch (using [CUSTOMER.csv](./data/samples/OrionStar/CUSTOMER.csv) file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a8de1-9c69-46b7-bccc-6a1c0c99b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "customersTablePath = f\"s3a://{repo.id}/{schemaValidationBranch2ndAttempt}/tables/customers\"\n",
    "df = spark.read.csv('/data/OrionStar/CUSTOMER.csv',header=True,schema=customersSchema)\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(customersTablePath)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69639830-482f-4160-af74-21a2f1a449bd",
   "metadata": {},
   "source": [
    "## Create Orders delta table in the new branch (using [ORDER_FACT.csv](./data/samples/OrionStar/ORDER_FACT.csv) file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c84480-b43a-4b20-ae43-72c58a58fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordersTablePath = f\"s3a://{repo.id}/{schemaValidationBranch2ndAttempt}/tables/orders\"\n",
    "df = spark.read.csv('/data/OrionStar/ORDER_FACT.csv',header=True,schema=ordersSchema)\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(ordersTablePath)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f892a899-ce32-4d8b-a8ef-06db27f4a9a4",
   "metadata": {},
   "source": [
    "## Commit changes and attach some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba055bee-b86f-4a0d-b355-da2abb42a1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakefs.commits.commit(\n",
    "    repository=repo.id,\n",
    "    branch=schemaValidationBranch2ndAttempt,\n",
    "    commit_creation=CommitCreation(\n",
    "        message='Added customers and orders Delta tables without any PII columns!', \n",
    "        metadata={'using': 'python_api'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b55776-d176-4b9c-af96-e37157d67530",
   "metadata": {},
   "source": [
    "## Merge new branch to the main branch\n",
    "\n",
    "#### Merge will succeed this time because there are no PII columns in the Delta tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b0764c-dc1b-4333-a042-8fd51d9438d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakefs.refs.merge_into_branch(\n",
    "    repository=repo.id,\n",
    "    source_ref=schemaValidationBranch2ndAttempt, \n",
    "    destination_branch=mainBranch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4227e9-7144-423f-becc-386661166133",
   "metadata": {},
   "source": [
    "# Check for any schema changes next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c767e9c7-28b0-4bc3-8a0a-c1f144e2dcec",
   "metadata": {},
   "source": [
    "## Create a new branch which will be used to ingest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ec2e75-3580-4a69-ab95-ffad0d2ee9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakefs.branches.create_branch(\n",
    "    repository=repo.id, \n",
    "    branch_creation=BranchCreation(\n",
    "        name=schemaChangeBranch, source=mainBranch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e7a6e-d625-4dd5-8802-916346a5e80b",
   "metadata": {},
   "source": [
    "## Change \"Country\" column to \"Country_Name\" in the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67bced5-a8c1-4955-a036-9f23c46df85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customersSchema = StructType([\n",
    "  StructField(\"Customer_ID\", IntegerType(), False),\n",
    "  StructField(\"Country_Name\", StringType(), False), # Column name changes from Country to Country_name\n",
    "  StructField(\"Gender\", StringType(), False),\n",
    "  StructField(\"Personal_ID\", IntegerType(), True),\n",
    "  StructField(\"Customer_Name\", StringType(), False),\n",
    "  StructField(\"Customer_FirstName\", StringType(), False),\n",
    "  StructField(\"Customer_LastName\", StringType(), False),\n",
    "  StructField(\"Birth_Date\", StringType(), False),\n",
    "  StructField(\"Customer_Address\", StringType(), False),\n",
    "  StructField(\"Street_ID\", LongType(), False),\n",
    "  StructField(\"Street_Number\", IntegerType(), False),\n",
    "  StructField(\"Customer_Type_ID\", IntegerType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140ede14-fe17-48e8-a1fd-d62c63531173",
   "metadata": {},
   "source": [
    "## Change data type for column \"Quantity\" from ByteType to LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba4331-c307-4e4d-be94-7839fe37f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordersSchema = StructType([\n",
    "  StructField(\"Customer_ID\", IntegerType(), False),\n",
    "  StructField(\"Employee_ID\", IntegerType(), False),\n",
    "  StructField(\"Street_ID\", LongType(), False),\n",
    "  StructField(\"Order_Date\", StringType(), False),\n",
    "  StructField(\"Delivery_Date\", StringType(), False),\n",
    "  StructField(\"Order_ID\", LongType(), True), \n",
    "  StructField(\"Order_Type\", ByteType(), False),\n",
    "  StructField(\"Product_ID\", LongType(), False),\n",
    "  StructField(\"Quantity\", LongType(), False), # Data type changes from ByteType() to LongType()\n",
    "  StructField(\"Total_Retail_Price\", StringType(), False),\n",
    "  StructField(\"CostPrice_Per_Unit\", StringType(), False),\n",
    "  StructField(\"Discount\", LongType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f38b6f-11db-4bfe-8f92-dc3a65152f96",
   "metadata": {},
   "source": [
    "## Create Customers delta table in the new branch (using [CUSTOMER.csv](./data/samples/OrionStar/CUSTOMER.csv) file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c8352-ec8b-483a-be03-2162eb2a1a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customersTablePath = f\"s3a://{repo.id}/{schemaChangeBranch}/tables/customers\"\n",
    "df = spark.read.csv('/data/OrionStar/CUSTOMER.csv',header=True,schema=customersSchema)\n",
    "df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(customersTablePath)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20ab37-7a57-47fe-88b8-d17906d49711",
   "metadata": {},
   "source": [
    "## Create Orders delta table in the new branch (using [ORDER_FACT.csv](./data/samples/OrionStar/ORDER_FACT.csv) file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814e970f-dec2-4dfa-adc2-9bf477762318",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordersTablePath = f\"s3a://{repo.id}/{schemaChangeBranch}/tables/orders\"\n",
    "df = spark.read.csv('/data/OrionStar/ORDER_FACT.csv',header=True,schema=ordersSchema)\n",
    "df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(ordersTablePath)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7346df42-d5a5-4aa6-bc04-94febc80e4c3",
   "metadata": {},
   "source": [
    "## Commit changes and attach some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9146afa-00fb-4fbe-9d82-5f020ecbced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakefs.commits.commit(\n",
    "    repository=repo.id,\n",
    "    branch=schemaChangeBranch,\n",
    "    commit_creation=CommitCreation(\n",
    "        message='Added customers and orders Delta tables with schema changes!', \n",
    "        metadata={'using': 'python_api'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a7aa3d-215e-4a06-b69f-a5acc0f00cd3",
   "metadata": {},
   "source": [
    "## Merge new branch to the main branch\n",
    "\n",
    "#### Merge will fail because schema changed. Review the error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bfc738-f7fa-4170-abfe-95895f5d928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakefs.refs.merge_into_branch(\n",
    "    repository=repo.id,\n",
    "    source_ref=schemaChangeBranch, \n",
    "    destination_branch=mainBranch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b05def4-1536-4871-8b66-327a81622870",
   "metadata": {
    "tags": []
   },
   "source": [
    "Error will look like this: \n",
    "    \n",
    "```\n",
    "(412)\n",
    "Reason: Precondition Failed\n",
    "```\n",
    "\n",
    "```\n",
    "update branch main: pre-merge hook aborted, run id '5ir9htgl1aas77gat5eg': 1 error occurred:\n",
    "    * hook run id '0000_0001' failed on action 'pre merge checks on main branch' hook 'check_schema_changes': \n",
    "runtime error: [string \\\"lua\\\"]:109: \n",
    "    Schema changed for 'tables/customers/part-00000-dbbb3d72-f911-4bdf-ad8f-b6f073be5df1-c000.snappy.parquet'. \n",
    "    Column name changed. Original column name was 'Country' and new column name is 'Country_Name'. \n",
    "    \n",
    "    Schema changed for 'tables/orders/part-00000-6020f550-c445-4e01-b72b-91d542850b5e-c000.snappy.parquet'. \n",
    "    Data type for column 'Quantity' changed. Original data type was 'INT32' and new data type is 'INT64'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a0587-8c74-4cbe-a213-d766ea23cb65",
   "metadata": {},
   "source": [
    "## You can also review all Actions in lakeFS UI\n",
    "\n",
    "üëâüèª http://localhost:8000/repositories/schema-and-pii-validation-example/actions\n",
    "\n",
    "![Actions UI](./images/LuaHooks/Actions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df67fb0-7c3a-41d4-9906-d204cda98b86",
   "metadata": {},
   "source": [
    "## Click on any Run ID to review Action details in lakeFS UI\n",
    "\n",
    "#### Click on \"pre merge checks on main branch\" Action on left panel. Expand multiple sections on right panel to see logs and error messages.\n",
    "\n",
    "![Action Details UI](./images/LuaHooks/ActionDetails.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f36b6f-0cd2-4ffb-9b82-eecd06c8b5a8",
   "metadata": {},
   "source": [
    "## More Questions?\n",
    "\n",
    "###### Join the lakeFS Slack group - https://lakefs.io/slack"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
