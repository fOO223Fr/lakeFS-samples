{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c053f0c-88da-4972-bdbe-686a37af7325",
   "metadata": {},
   "source": [
    "<img src=\"./images/logo.svg\" alt=\"lakeFS logo\" width=300/> \n",
    "\n",
    "# Creating Dev-Test environments with lakeFS branches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7acc430",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "**_If you're not using the provided lakeFS server and MinIO storage then change these values to match your environment_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e998fa2",
   "metadata": {},
   "source": [
    "### lakeFS endpoint and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb6b66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefsEndPoint = 'http://lakefs:8000' # e.g. 'https://username.aws_region_name.lakefscloud.io' \n",
    "lakefsAccessKey = 'AKIAIOSFOLKFSSAMPLES'\n",
    "lakefsSecretKey = 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d1d58d",
   "metadata": {},
   "source": [
    "### Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6997ec87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storageNamespace = 's3://example' # e.g. \"s3://bucket\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb8ed22-80d2-4524-93ce-22fe733a020e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba98dd-cc7b-464e-9d73-dae0e2f632fb",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "**(you shouldn't need to change anything in this section, just run it)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec9114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_name = \"netflix\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73a00ce-c62b-4819-99ec-017e8c53d28d",
   "metadata": {},
   "source": [
    "### Versioning Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0984c0-d4b5-41b9-8bd2-00e11fb9cb99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingest_branch = \"ingress-landing-area\"\n",
    "staging_branch = \"staging-area\"\n",
    "prod_branch = \"main\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e066f-150b-4159-8de8-6daa952d478b",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833db97-a9d8-409d-aef5-45d0140fca29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import lakefs\n",
    "from assets.lakefs_demo import print_commit, print_diff\n",
    "from datetime import date, time\n",
    "from pyspark.sql.functions import col,isnan,when,count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e7a7a9",
   "metadata": {},
   "source": [
    "### Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa377e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"LAKECTL_SERVER_ENDPOINT_URL\"] = lakefsEndPoint\n",
    "os.environ[\"LAKECTL_CREDENTIALS_ACCESS_KEY_ID\"] = lakefsAccessKey\n",
    "os.environ[\"LAKECTL_CREDENTIALS_SECRET_ACCESS_KEY\"] = lakefsSecretKey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eb360a-ebc2-4276-9ba1-645aad95e64e",
   "metadata": {},
   "source": [
    "#### Verify lakeFS credentials by getting lakeFS version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e47f76-abd9-49a0-9057-b2fc9dc7307e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Verifying lakeFS credentials‚Ä¶\")\n",
    "try:\n",
    "    v=lakefs.client.Client().version\n",
    "except:\n",
    "    print(\"üõë failed to get lakeFS version\")\n",
    "else:\n",
    "    print(f\"‚Ä¶‚úÖlakeFS credentials verified\\n\\n‚ÑπÔ∏èlakeFS version {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a29477",
   "metadata": {},
   "source": [
    "### Define lakeFS Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc3f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo = lakefs.Repository(repo_name).create(storage_namespace=f\"{storageNamespace}/{repo_name}\", default_branch=prod_branch, exist_ok=True)\n",
    "branchProd = repo.branch(prod_branch)\n",
    "print(repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170a834d-30ae-46e0-b03f-f17ac88230a5",
   "metadata": {},
   "source": [
    "### Set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05952f12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"lakeFS / Jupyter\") \\\n",
    "        .config(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", lakefsEndPoint) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", lakefsAccessKey) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", lakefsSecretKey) \\\n",
    "        .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d07acc4",
   "metadata": {},
   "source": [
    "## Creating Ingest and Staging branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a267eee-667b-4502-93f7-866db8ff2320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "branchIngest = repo.branch(ingest_branch).create(source_reference=prod_branch, exist_ok=True)\n",
    "print(f\"{ingest_branch} ref:\", branchIngest.get_commit().id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb8a291-c609-4fd6-bacc-81d6024ae205",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "branchStaging = repo.branch(staging_branch).create(source_reference=prod_branch, exist_ok=True)\n",
    "print(f\"{staging_branch} ref:\", branchStaging.get_commit().id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12656def-31f2-4c20-8120-ea392268a922",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for branch in repo.branches():\n",
    "    print(branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22215b",
   "metadata": {},
   "source": [
    "## Load some sample data about Netflix movies\n",
    "\n",
    "The daily partition lands in ingress path (branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897649d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingest_data = \"movies.csv\"\n",
    "\n",
    "ingest_path = f'dt={str(date.today())}/{ingest_data}'\n",
    "ingest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ecdb9-b9da-466e-8754-c5748dc383d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contentToUpload = open(f'/data/{ingest_data}', 'r').read()\n",
    "print(branchIngest.object(ingest_path).upload(data=contentToUpload, mode='wb', pre_sign=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d8ac41-5fa6-4827-9f7a-c4d27acedb7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = branchIngest.commit(message=\"netflix movie data arrived at landing area (today's partition)\")\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1251272-cfa0-4bac-9f5c-8a193b954c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff = branchProd.diff(other_ref=branchIngest)\n",
    "print_diff(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7c8c5f",
   "metadata": {},
   "source": [
    "## Copying daily partition from ingress to staging area (branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cee0af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "staging_long_path = f\"s3a://{repo_name}/{staging_branch}\"\n",
    "staging_long_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d28da1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_path = f\"{staging_long_path}/raw/dt={str(date.today())}/csv\"\n",
    "csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba929a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df = spark.read.option(\"header\",\"true\").csv(f\"s3a://{repo_name}/{ingest_branch}/{ingest_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c206173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.write.option(\"header\",True)\\\n",
    "        .mode(\"append\")\\\n",
    "        .csv(csv_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3d26c2-96cd-43da-9e98-84a9e62398ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = branchStaging.commit(message=\"netflix movie data copied to staging area (today's partition)\")\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f71b8da-1aee-43b3-908f-8153b8d04989",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff = branchProd.diff(other_ref=branchStaging)\n",
    "print_diff(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b02831",
   "metadata": {},
   "source": [
    "## Data Exploration and Cleaning in staging area (branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5c6a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df = spark.read.option(\"header\",\"true\").csv(csv_path)\n",
    "df_columns=movies_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c712b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(movies_df.count())\n",
    "print(movies_df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f834f72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7910b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.sample(False,0.1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ed985",
   "metadata": {},
   "source": [
    "## Null checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2c64ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3aeabe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df = movies_df.na.drop(\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c3c577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02adefe0-89cd-4d03-8117-34434784134a",
   "metadata": {},
   "source": [
    "## Writing Transformed Parquet files to staging area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe7278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.write.option(\"header\",True)\\\n",
    "        .partitionBy(\"country\")\\\n",
    "        .mode(\"append\")\\\n",
    "        .parquet(f\"{staging_long_path}/analytics/movies-by-country-parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ddb5e8",
   "metadata": {},
   "source": [
    "### View uncommitted changes and clean up the files not needed\n",
    "\n",
    "Go to the lakeFS UI to inspect the uncommitted changes, e.g. http://localhost:8000/repositories/netflix/changes?ref=staging-area&prefix=analytics%2Fmovies-by-country-parquet%2F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69af4f42-68fd-4850-ae85-2508a9f09deb",
   "metadata": {},
   "source": [
    "## Commit the changes to staging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383bc59b-0cf4-48a0-ae73-4c91c39fd3df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = branchStaging.commit(message='loaded paritioned movies parquet to staging area')\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacee3db",
   "metadata": {},
   "source": [
    "## Merging Daily Data (Parquet files) to Prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cace124-b26e-4020-8097-aca7dd8a5cee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = branchStaging.merge_into(branchProd)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db7864-d2e2-477f-bd7c-f5f19930fc1b",
   "metadata": {},
   "source": [
    "## More Questions?\n",
    "\n",
    "###### Join the lakeFS Slack group - https://lakefs.io/slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da087f-28f3-4428-95f6-e0b88e378afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
