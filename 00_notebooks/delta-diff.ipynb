{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78797e22",
   "metadata": {},
   "source": [
    "<img src=\"./images/logo.svg\" alt=\"lakeFS logo\" width=300/> \n",
    "\n",
    "# lakeFS and Delta Lake diff\n",
    "\n",
    "This shows the use of Delta Lake with lakeFS and the Delta Lake diff plugin.\n",
    "\n",
    "For more details see [the published blog article](https://lakefs.io/blog/lakefs-supports-delta-lake-diff/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d96f6-9fd2-4517-b637-df4e650ceb15",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Config\n",
    "\n",
    "**_If you're not using the provided lakeFS server and MinIO storage then change these values to match your environment_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fc5503-474e-4d40-8b48-2959f2f4909b",
   "metadata": {},
   "source": [
    "### lakeFS endpoint and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad336dd-cb3d-478a-bc90-cd1df7ca7e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefsEndPoint = 'http://lakefs:8000' # e.g. 'https://username.aws_region_name.lakefscloud.io' \n",
    "lakefsAccessKey = 'AKIAIOSFOLKFSSAMPLES'\n",
    "lakefsSecretKey = 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1560461-b34b-466c-a77e-d6f3ef28a450",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f452ecfd-a7be-4a3a-9e5c-5a59b1d6c9de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storageNamespace = 's3://example' # e.g. \"s3://bucket\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bbe5bc-ba34-44a3-a55a-57abb81e8658",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d341f8f-3c32-4bbf-8d1d-2b114f7f0f14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "**(you shouldn't need to change anything in this section, just run it)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada2113d-b298-4606-88ef-42e0a3b528ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_name = \"delta-lake-diff\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b200e-8c57-4fd7-bf3f-df05374236a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create lakeFSClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d274e-88e3-4567-9dd3-bc9af3397a5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lakefs_client\n",
    "from lakefs_client.models import *\n",
    "from lakefs_client.client import LakeFSClient\n",
    "\n",
    "# lakeFS credentials and endpoint\n",
    "configuration = lakefs_client.Configuration()\n",
    "configuration.username = lakefsAccessKey\n",
    "configuration.password = lakefsSecretKey\n",
    "configuration.host = lakefsEndPoint\n",
    "\n",
    "lakefs = LakeFSClient(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ece48d-ad22-4396-b2cc-59cb47eee3a6",
   "metadata": {},
   "source": [
    "#### Verify lakeFS credentials by getting lakeFS version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d332303-8ceb-40a7-9c4c-1956480bdcad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Verifying lakeFS credentials‚Ä¶\")\n",
    "try:\n",
    "    v=lakefs.config.get_config()\n",
    "except:\n",
    "    print(\"üõë failed to get lakeFS version\")\n",
    "else:\n",
    "    print(f\"‚Ä¶‚úÖlakeFS credentials verified\\n\\n‚ÑπÔ∏èlakeFS version {v['version_config']['latest_version']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf7146-3510-47fe-8672-9515619f7ab1",
   "metadata": {},
   "source": [
    "### Define lakeFS Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2db150-3df3-43b9-97e0-e6fe69aea3d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lakefs_client.exceptions import NotFoundException\n",
    "\n",
    "try:\n",
    "    repo=lakefs.repositories.get_repository(repo_name)\n",
    "    print(f\"Found existing repo {repo.id} using storage namespace {repo.storage_namespace}\")\n",
    "except NotFoundException as f:\n",
    "    print(f\"Repository {repo_name} does not exist, so going to try and create it now.\")\n",
    "    try:\n",
    "        repo=lakefs.repositories.create_repository(repository_creation=RepositoryCreation(name=repo_name,\n",
    "                                                                                                storage_namespace=f\"{storageNamespace}/{repo_name}\"))\n",
    "        print(f\"Created new repo {repo.id} using storage namespace {repo.storage_namespace}\")\n",
    "    except lakefs_client.ApiException as e:\n",
    "        print(f\"Error creating repo {repo_name}. Error is {e}\")\n",
    "        os._exit(00)\n",
    "except lakefs_client.ApiException as e:\n",
    "    print(f\"Error getting repo {repo_name}: {e}\")\n",
    "    os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ebce6-a0a7-4605-aba7-6123e78deca6",
   "metadata": {},
   "source": [
    "### Set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae1b76-5c4f-44e7-9fa2-d9029722b58e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"lakeFS / Jupyter\") \\\n",
    "                    .config(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "                    .config(\"spark.hadoop.fs.s3a.endpoint\", lakefsEndPoint) \\\n",
    "                    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "                    .config(\"spark.hadoop.fs.s3a.access.key\", lakefsAccessKey) \\\n",
    "                    .config(\"spark.hadoop.fs.s3a.secret.key\", lakefsSecretKey) \\\n",
    "                    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.3.0\") \\\n",
    "                    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "                    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "                    .config(\"spark.delta.logStore.class\", \"org.apache.spark.sql.delta.storage.S3SingleDriverLogStore\") \\\n",
    "                    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d3e5f-410c-4616-8309-7f70dc291be3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a225cea-e203-419f-bade-6933874ad9f3",
   "metadata": {},
   "source": [
    "# Main demo starts here üö¶ üëáüèª"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a45118a",
   "metadata": {},
   "source": [
    "## Load some data into lakeFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff22dfb5",
   "metadata": {},
   "source": [
    "Read a parquet file from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a87c7ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(f\"/data/userdata/userdata1.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c22768b",
   "metadata": {},
   "source": [
    "How many rows of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec747fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f17847",
   "metadata": {},
   "source": [
    "What does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6268496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(df.show(n=1,vertical=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41dab2b",
   "metadata": {},
   "source": [
    "## Write data to lakeFS (on the `main` branch) in Delta format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40be34f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "branch='main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68718621",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.write.format(\"delta\").mode('overwrite').save('s3a://'+repo.id+'/'+branch+'/demo/users')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6963a378",
   "metadata": {},
   "source": [
    "#### üëâüèª[The data as seen from LakeFS](http://localhost:8000/repositories/example/objects?ref=main&path=demo%2Fusers%2F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcdcb3c",
   "metadata": {},
   "source": [
    "### Commit the new file in `main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0078cc8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo.id,\n",
    "                      branch=branch,\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message=\"Initial user data load\"\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3c5e94",
   "metadata": {},
   "source": [
    "## Create a branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa39ade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "branch='modify_user_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd1769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.branches.create_branch(repository=repo.id, \n",
    "                              branch_creation=BranchCreation(name=branch, \n",
    "                                                                    source=\"main\")\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e1a416",
   "metadata": {},
   "source": [
    "### List the current branches in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118732d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for b in lakefs.branches.list_branches(repo.id).results:\n",
    "    display(b.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1378435c",
   "metadata": {},
   "source": [
    "## Add some new data with merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad246bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc637861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df = spark.read.parquet(f\"/data/userdata/userdata2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f818de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "users_deltaTable = DeltaTable.forPath(spark, 's3a://'+repo.id+'/'+branch+'/demo/users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e93b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "users_deltaTable.alias(\"users\").merge(\n",
    "    source = new_df.alias(\"new_users\"),\n",
    "    condition = \"users.id = new_users.id\") \\\n",
    "  .whenNotMatchedInsertAll() \\\n",
    "  .execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb92fada",
   "metadata": {},
   "source": [
    "### Commit in lakeFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae6261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo.id,\n",
    "                      branch=branch,\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message=\"Merge in new user data\"\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b64c675",
   "metadata": {},
   "source": [
    "## Update some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d2041a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, f\"s3a://{repo.id}/{branch}/demo/users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1cce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deltaTable.toDF().filter(col(\"country\").isin(\"Portugal\", \"China\")).select(\"country\",\"ip_address\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2dd8c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deltaTable.update(\n",
    "    condition = \"country == 'Portugal'\",\n",
    "    set = { \"ip_address\" : \"'x.x.x.x'\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab657830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deltaTable.toDF().filter(col(\"country\").isin(\"Portugal\", \"China\")).select(\"country\",\"ip_address\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc8abc",
   "metadata": {},
   "source": [
    "### Commit in lakeFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a6843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo.id,\n",
    "                      branch=branch,\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message=\"Mask all IPs for users in Portugal\"\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97239613",
   "metadata": {},
   "source": [
    "## Delete some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60544aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deltaTable.toDF().filter(col(\"salary\") > 60000).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9a8a5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deltaTable.delete(col(\"salary\") > 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c094678f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deltaTable.toDF().filter(col(\"salary\") > 60000).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295fedaa",
   "metadata": {},
   "source": [
    "### Commit in lakeFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210fd6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo.id,\n",
    "                      branch=branch,\n",
    "                      commit_creation=CommitCreation(\n",
    "                            message=\"Delete users with salary over 60k\"\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24fcd35",
   "metadata": {},
   "source": [
    "### Look at the data and diffs in LakeFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c7a46c-812c-4d7c-a53d-8f59159ab98a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "if lakefsEndPoint=='http://lakefs:8000':\n",
    "    lakeFSWebUI='http://localhost:8000'\n",
    "else:\n",
    "    lakeFSWebUI=lakefsEndPoint\n",
    "\n",
    "md(f\"### üëâüèª Go to lakeFS UI and click on [Show table changes]({lakeFSWebUI}/repositories/{repo.id}/compare?ref=main&compare=modify_user_data&prefix=demo%2F)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
