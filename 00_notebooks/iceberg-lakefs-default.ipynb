{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89718426",
   "metadata": {},
   "source": [
    "# What happens if you use Iceberg on lakeFS _without_ the new built-in support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cdd878-04a7-4d6b-ad99-f98f5b37080e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Config\n",
    "\n",
    "**_If you're not using the provided lakeFS server and MinIO storage then change these values to match your environment_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df43edc-2b34-40e0-807d-f2a4acb8b14a",
   "metadata": {},
   "source": [
    "### lakeFS endpoint and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e64da-c208-49f3-963d-9bf9c488b52a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefsEndPoint = 'http://lakefs:8000' # e.g. 'https://username.aws_region_name.lakefscloud.io' \n",
    "lakefsAccessKey = 'AKIAIOSFODNN7EXAMPLE'\n",
    "lakefsSecretKey = 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa24c3-eafe-4faf-974d-b66b65509833",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce9539c-ca43-466c-a820-ee8f3f6fa312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storageNamespace = 's3://example' # e.g. \"s3://bucket\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e0f61-2739-4ec8-87aa-2e1bdacca395",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3590918-d6f7-4c5e-b09a-5c66afc4fad2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup\n",
    "\n",
    "**(you shouldn't need to change anything in this section, just run it)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d51253-2d89-4dc0-9879-1104a5228b60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_name = \"iceberg-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eac0e7-a3ba-4423-9d2e-275d39b7fbc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create lakeFSClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde3e9b6-2da3-4ae2-968a-acf874867a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lakefs_client\n",
    "from lakefs_client.models import *\n",
    "from lakefs_client.client import LakeFSClient\n",
    "\n",
    "# lakeFS credentials and endpoint\n",
    "configuration = lakefs_client.Configuration()\n",
    "configuration.username = lakefsAccessKey\n",
    "configuration.password = lakefsSecretKey\n",
    "configuration.host = lakefsEndPoint\n",
    "\n",
    "lakefs = LakeFSClient(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f8490e-bf64-441a-bd01-02b13420ac6b",
   "metadata": {},
   "source": [
    "#### Verify lakeFS credentials by getting lakeFS version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d9debc-e52e-4b42-8e56-b52e7d798410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Verifying lakeFS credentials‚Ä¶\")\n",
    "try:\n",
    "    v=lakefs.config.get_lake_fs_version()\n",
    "except:\n",
    "    print(\"üõë failed to get lakeFS version\")\n",
    "else:\n",
    "    print(f\"‚Ä¶‚úÖlakeFS credentials verified\\n\\n‚ÑπÔ∏èlakeFS version {v.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9f9a7f-fb91-4f8b-aa02-75919e15edba",
   "metadata": {},
   "source": [
    "### Define lakeFS Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf73bf83-546b-4cc0-a920-cfcb16d87a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lakefs_client.exceptions import NotFoundException\n",
    "\n",
    "try:\n",
    "    repo=lakefs.repositories.get_repository(repo_name)\n",
    "    print(f\"Found existing repo {repo.id} using storage namespace {repo.storage_namespace}\")\n",
    "except NotFoundException as f:\n",
    "    print(f\"Repository {repo_name} does not exist, so going to try and create it now.\")\n",
    "    try:\n",
    "        repo=lakefs.repositories.create_repository(repository_creation=RepositoryCreation(name=repo_name,\n",
    "                                                                                                storage_namespace=f\"{storageNamespace}/{repo_name}\"))\n",
    "        print(f\"Created new repo {repo.id} using storage namespace {repo.storage_namespace}\")\n",
    "    except lakefs_client.ApiException as e:\n",
    "        print(f\"Error creating repo {repo_name}. Error is {e}\")\n",
    "        os._exit(00)\n",
    "except lakefs_client.ApiException as e:\n",
    "    print(f\"Error getting repo {repo_name}: {e}\")\n",
    "    os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b647611",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir=f\"s3a://{repo.id.replace('s3','s3a')}\"\n",
    "print(f\"Using {data_dir} for data storage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90c5ab-3285-4afb-a663-859e0d883007",
   "metadata": {},
   "source": [
    "### Set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36742058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(f\"lakeFS sample / {repo.id}\") \\\n",
    "        .config(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", lakefsEndPoint) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", lakefsAccessKey) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", lakefsSecretKey) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.3_2.12:1.3.0\") \\\n",
    "        .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "        .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "        .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
    "        .config(\"spark.sql.catalog.local.warehouse\", (f\"{data_dir}/main\")) \\\n",
    "        .config(\"spark.sql.defaultCatalog\", \"local\") \\\n",
    "        .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb4be6-1813-44d7-8e16-ce651e854689",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b668f2-9541-46bc-8769-439a97b3074e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec5d9ea-fc59-41bc-8b86-18fa7ca09161",
   "metadata": {},
   "source": [
    "# Main demo starts here üö¶ üëáüèª"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceeaa9b",
   "metadata": {},
   "source": [
    "## Load test data and write it as an Iceberg table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad496308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.option(\"inferSchema\",\"true\").option(\"multiline\",\"true\").json(\"/data/nyc_film_permits.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626e4207-e93a-4416-b859-6a28d48c4fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.write.saveAsTable(\"nyc.permits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f066ed7-7808-45a1-9640-6a2270fcc827",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql DESCRIBE EXTENDED nyc.permits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcdcb3c",
   "metadata": {},
   "source": [
    "## Commit the data to the `main` branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec33a1-6332-4fc9-a003-a4b93914d218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repo.id, \"main\", CommitCreation(\n",
    "    message=\"Initial data load\",\n",
    "    metadata={'author': 'rmoff',\n",
    "              'data source': 'https://data.cityofnewyork.us/City-Government/Film-Permits/tg4x-b46p'}\n",
    ") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321bfe42-8dda-4ea8-8f1d-e95e46142517",
   "metadata": {},
   "source": [
    "## Create branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d1de1-eac2-4cf3-9fc9-6975f01201ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.branches.create_branch(repo.id, \n",
    "                              BranchCreation(name=\"dev\",\n",
    "                                             source=\"main\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ca3441-b010-4f30-9ba1-df4a99d40185",
   "metadata": {},
   "source": [
    "## Query the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e85de42-2737-4c23-9539-522939c94149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql SELECT COUNT(*) FROM nyc.permits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b9f564-6f6b-4742-9600-e2d3368e7679",
   "metadata": {},
   "source": [
    "# Stop the Spark session and create a new one to read the dev version of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a741c3cb-9db9-4c6f-8003-7ac3c70fad43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(f\"lakeFS sample / {repo.id}\") \\\n",
    "        .config(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", lakefsEndPoint) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", lakefsAccessKey) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", lakefsSecretKey) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.3_2.12:1.3.0\") \\\n",
    "        .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "        .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "        .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
    "        .config(\"spark.sql.catalog.local.warehouse\", (f\"{data_dir}/dev\")) \\\n",
    "        .config(\"spark.sql.defaultCatalog\", \"local\") \\\n",
    "        .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84832add-d388-44c8-92f4-fc14ac213b74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql SELECT COUNT(*) FROM nyc.permits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5eb6c-0eed-4d96-a075-43d95dcc7ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql DESCRIBE EXTENDED nyc.permits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce5951-b501-4866-a938-0e23420f5b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql show databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5942abe7-4f8d-4088-84d4-1f5fb7aafb66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql show tables from nyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3189d6b-f612-450c-b666-9bc1dddf79f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql show tblproperties nyc.permits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411d7c2f-3056-4a38-9773-f34ea39bd95d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql DESCRIBE TABLE EXTENDED nyc.permits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d985eb0a-c870-4e29-9d78-84052819b116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.option(\"inferSchema\",\"true\").option(\"multiline\",\"true\").json(\"/data/nyc_film_permits.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10356853-9df5-4763-a56b-8ab20c5635e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.write.saveAsTable(\"nyc.permits_written_to_dev\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
