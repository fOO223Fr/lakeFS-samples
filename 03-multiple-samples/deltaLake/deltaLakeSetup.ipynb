{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b2c8fa0-1702-411a-b11c-3190679bf31c",
   "metadata": {},
   "source": [
    "# [Integration of lakeFS with Delta Lake](https://docs.lakefs.io/integrations/delta.html)\n",
    "\n",
    "## Use Cases:\n",
    "### 1. Isolating ETL job and atomic promotion to production\n",
    "### 2. Atomic rollback of Multi-Table Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a24fa50-8557-4a9e-8463-f093ce8d2bf9",
   "metadata": {},
   "source": [
    "## Import Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfe84c-fce2-4be0-8314-073c6b9aa1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lakefs_client\n",
    "import os\n",
    "import lakefs_demo\n",
    "from pyspark.sql.types import ByteType, IntegerType, LongType, StringType, StructType, StructField\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ede096-1b84-4b59-bdd1-2608ced6be51",
   "metadata": {},
   "source": [
    "## Working with the lakeFS Python client API\n",
    "\n",
    "###### Note: To learn more about lakeFS Python integration visit https://docs.lakefs.io/integrations/python.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468e98e4-7e06-4373-b36b-f1763cc7755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%xmode Minimal\n",
    "from lakefs_client import models\n",
    "from lakefs_client.client import LakeFSClient\n",
    "\n",
    "# lakeFS credentials and endpoint\n",
    "configuration = lakefs_client.Configuration()\n",
    "configuration.username = lakefsAccessKey\n",
    "configuration.password = lakefsSecretKey\n",
    "configuration.host = lakefsEndPoint\n",
    "\n",
    "client = LakeFSClient(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144747fc-cade-4929-8ae2-d488091ff273",
   "metadata": {},
   "source": [
    "## Verify lakeFS credentials by getting lakeFS version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20525e09-3b2a-4ac1-827f-c0d87a6b0f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Verifying lakeFS credentials\")\n",
    "client.config.get_lake_fs_version()\n",
    "print(\"lakeFS credentials verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a552a097-3156-4d3a-8981-c2fdadac63b5",
   "metadata": {},
   "source": [
    "## Run PySpark with the Delta Lake package and additional configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2113cea0-92b5-46b2-83f9-5f0a2d8a7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages io.delta:delta-core_2.12:2.0.0 --conf \"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension\" --conf \"spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\" pyspark-shell'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a2057a-24ba-4478-b166-825a2c49abf4",
   "metadata": {},
   "source": [
    "## S3A Gateway configuration\n",
    "\n",
    "##### Note: lakeFS can be configured to work with Spark in two ways:\n",
    "###### * Access lakeFS using the S3A gateway https://docs.lakefs.io/integrations/spark.html#access-lakefs-using-the-s3a-gateway.\n",
    "###### * Access lakeFS using the lakeFS-specific Hadoop FileSystem https://docs.lakefs.io/integrations/spark.html#access-lakefs-using-the-lakefs-specific-hadoop-filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9f169f-95c8-4432-886f-937d0f86e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", lakefsAccessKey)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", lakefsSecretKey)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", lakefsEndPoint)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0942274f-b91c-4971-80e3-a4a29af40dc2",
   "metadata": {},
   "source": [
    "## Function to count records in a Delta table in different branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3c32c-8622-4b68-986f-0263f9482b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_table_compare_branches(table, refs):\n",
    "  spark.createDataFrame(\n",
    "    data=zip(\n",
    "      refs,\n",
    "      map(lambda r: spark.read.format('delta').load(f's3a://{repo}/{r}/{table}').count(), refs)\n",
    "    ), \n",
    "    schema=StructType([ \n",
    "      StructField(\"Branch\", StringType(), True),\n",
    "      StructField(\"Count\", IntegerType(), True)\n",
    "    ])\n",
    "  ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef30d21-72e4-43df-91d7-ee5a90c3142e",
   "metadata": {},
   "source": [
    "## For this demo - we'll be utilizing a dataset - [Orion Star - Sports and outdoors RDBMS dataset](https://www.kaggle.com/datasets/chethanp11/orion-star-sports-and-outdoors-rdbms-dataset) from [Kaggle](https://www.kaggle.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0dfc4c-b34d-40d7-9811-eb5f4ff051f3",
   "metadata": {},
   "source": [
    "## Define [CUSTOMER.csv](../data/samples/OrionStar/CUSTOMER.csv) data file schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3beb774-9196-4b9c-85f8-5e318a866b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "customersSchema = StructType([\n",
    "  StructField(\"Customer_ID\", IntegerType(), False),\n",
    "  StructField(\"Country\", StringType(), False),\n",
    "  StructField(\"Gender\", StringType(), False),\n",
    "  StructField(\"Personal_ID\", IntegerType(), True),\n",
    "  StructField(\"Customer_Name\", StringType(), False),\n",
    "  StructField(\"Customer_FirstName\", StringType(), False),\n",
    "  StructField(\"Customer_LastName\", StringType(), False),\n",
    "  StructField(\"Birth_Date\", StringType(), False),\n",
    "  StructField(\"Customer_Address\", StringType(), False),\n",
    "  StructField(\"Street_ID\", LongType(), False),\n",
    "  StructField(\"Street_Number\", IntegerType(), False),\n",
    "  StructField(\"Customer_Type_ID\", IntegerType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0531a442-f506-45b4-92f1-2c2bc464b825",
   "metadata": {},
   "source": [
    "## Define [ORDER_FACT.csv](../data/samples/OrionStar/ORDER_FACT.csv) data file schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75155db0-9c86-43da-8c81-fd8ecf2cf0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordersSchema = StructType([\n",
    "  StructField(\"Customer_ID\", IntegerType(), False),\n",
    "  StructField(\"Employee_ID\", IntegerType(), False),\n",
    "  StructField(\"Street_ID\", LongType(), False),\n",
    "  StructField(\"Order_Date\", StringType(), False),\n",
    "  StructField(\"Delivery_Date\", StringType(), False),\n",
    "  StructField(\"Order_ID\", LongType(), True),\n",
    "  StructField(\"Order_Type\", ByteType(), False),\n",
    "  StructField(\"Product_ID\", LongType(), False),\n",
    "  StructField(\"Quantity\", ByteType(), False),\n",
    "  StructField(\"Total_Retail_Price\", StringType(), False),\n",
    "  StructField(\"CostPrice_Per_Unit\", StringType(), False),\n",
    "  StructField(\"Discount\", LongType(), False)\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
