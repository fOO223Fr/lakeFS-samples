## lakeFS + Github + Airflow - example

This sample will give you an idea of how you can use the [lakeFS Airflow provider](https://github.com/treeverse/airflow-provider-lakeFS) to:
* Version control your raw, intermediate and processed data.
* Link between code versions and the data generated by running them.

### Prerequisites 

* Build a custom **CD process** to make your code and git metadata accessible for an Airflow DAG.
* Use Airflow to orchestrate your ETL run.

![](assets/git-lakefs-airflow.png)

### Run Instructions

1. Clone the sample.

2. Spin up the environment:
   `docker-compose up`

3. Browse to Airflow in [http://localhost:8085/](http://localhost:8085/). User: _airflow_, password: _airflow_.

4. Browse to the lakeFS UI in [http://localhost:8084/](http://localhost:8084/). User: AKIAIOSFODNN7EXAMPLE, password: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY.

5. Run the _etl_ DAG in Airflow and observe the results in lakeFS.
