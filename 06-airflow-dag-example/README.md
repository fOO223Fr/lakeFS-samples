## lakeFS + Github + Airflow - example

* Build a custom **CD process** to make your code and git metadata accessible for an Airflow DAG.
* Use Airflow to orchestrate your ETL run.
* Use [lakeFS Airflow provider](https://github.com/treeverse/airflow-provider-lakeFS) to:
   * Version control your raw, intermediate and processed data
   * Link code versions and the data generated by running them
   * Link Airflow DAG code versions to the data generated during a DAG run

![](assets/git-lakefs-airflow.png)

**Note:**
This example can work with any web-based repository service.

### Run Instructions

1. Clone the sample.

2. Spin up the environment:
   `docker-compose up`

3. Browse to Airflow in [http://localhost:8085/](http://localhost:8085/). User: _airflow_, password: _airflow_.

4. Browse to the lakeFS UI in [http://localhost:8084/](http://localhost:8084/). User: AKIAIOSFODNN7EXAMPLE, password: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY.

5. Run the _etl_ DAG in Airflow and observe the results in lakeFS.
