{"cells":[{"cell_type":"code","source":["%python\n\nfile_path_lakefs = \"lakefs://dais22-data-books/main/\"\ns3_path = \"s3://adi-lakefs/dais22/\"\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"19c435ff-3f73-4183-aa4a-b8038c7c58a6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%python\n\n\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType\nbooks = [(\"54278345\",\"Building Resilient Data Pipelines\",\"Iron Man\"),\n    (\"15678345\",\"Building Data Platforms\",\"Gamora\"),\n    (\"89898782\",\"Scaling metadata\",\"catwoman\"),\n    (\"32278345\",\"Beyond the clean data curve\",\"batman\"),\n    (\"31478888\",\"Project lightspeed - the definitive guide\",\"Databricks\"),\n    (\"32278888\",\"Hello Spark Fans\",\"Advanced Analytics\"),\n    (\"73825104\",\"Fundamentals of Data Observability\",\"Andy Petrella\"),\n    (\"73825103\",\"High Performance Spark\",\"Holden Karau\"),\n    (\"73341143\",\"Data Engineering with Apache Spark, Delta Lake, and Lakehouse\",\"Manoj Kukreja\"),\n    (\"54725104\",\"Fundamentals of Data Observability\",\"Andy Petrella\"),\n    (\"54725222\",\"Designing Data-Intensive Applications\",\"Martin Kleppmann\"),\n    (\"54725283\",\"Data Management at Scale\",\"Piethein Strengholt\"),     \n    (\"29829283\",\"Database Internals\",\"Alex Petrov\"),  \n         \n         \n         \n    (\"25678345\",\"Scaling Data Platforms\",\"Gamora\"),\n    (\"39898782\",\"Project metadata\",\"catwoman\"),\n    (\"42278345\",\"Intro to Hive metastore\",\"she-hulk\"),\n    (\"52278888\",\"Reviving zookeper\",\"dr-strange\"),\n    (\"62278888\",\"Life after Hadoop\",\"Green Arrow\"),\n    (\"83825104\",\"Fundamentals of Lakehouse\",\"Barry Allen\"),\n    (\"93825104\",\"High Performance Yarn\",\"Harley Quinn\"),  \n  ]\n\nschema = StructType([ \\\n    StructField(\"isbn\",StringType(),True), \\\n    StructField(\"name\",StringType(),True), \\\n    StructField(\"author\",StringType(),True) \\\n  ])\n \nbooks_df = spark.createDataFrame(data=books,schema=schema)\nbooks_df.printSchema()\nbooks_df.show(truncate=False)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"508c2763-a016-42e7-a8ce-c72b96fef5bd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"books_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"isbn","nullable":true,"type":"string"},{"metadata":{},"name":"name","nullable":true,"type":"string"},{"metadata":{},"name":"author","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">root\n |-- isbn: string (nullable = true)\n |-- name: string (nullable = true)\n |-- author: string (nullable = true)\n\n+--------+-------------------------------------------------------------+-------------------+\n|isbn    |name                                                         |author             |\n+--------+-------------------------------------------------------------+-------------------+\n|54278345|Building Resilient Data Pipelines                            |Iron Man           |\n|15678345|Building Data Platforms                                      |Gamora             |\n|89898782|Scaling metadata                                             |catwoman           |\n|32278345|Beyond the clean data curve                                  |batman             |\n|31478888|Project lightspeed - the definitive guide                    |Databricks         |\n|32278888|Hello Spark Fans                                             |Advanced Analytics |\n|73825104|Fundamentals of Data Observability                           |Andy Petrella      |\n|73825103|High Performance Spark                                       |Holden Karau       |\n|73341143|Data Engineering with Apache Spark, Delta Lake, and Lakehouse|Manoj Kukreja      |\n|54725104|Fundamentals of Data Observability                           |Andy Petrella      |\n|54725222|Designing Data-Intensive Applications                        |Martin Kleppmann   |\n|54725283|Data Management at Scale                                     |Piethein Strengholt|\n|29829283|Database Internals                                           |Alex Petrov        |\n|25678345|Scaling Data Platforms                                       |Gamora             |\n|39898782|Project metadata                                             |catwoman           |\n|42278345|Intro to Hive metastore                                      |she-hulk           |\n|52278888|Reviving zookeper                                            |dr-strange         |\n|62278888|Life after Hadoop                                            |Green Arrow        |\n|83825104|Fundamentals of Lakehouse                                    |Barry Allen        |\n|93825104|High Performance Yarn                                        |Harley Quinn       |\n+--------+-------------------------------------------------------------+-------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- isbn: string (nullable = true)\n-- name: string (nullable = true)\n-- author: string (nullable = true)\n\n+--------+-------------------------------------------------------------+-------------------+\nisbn    |name                                                         |author             |\n+--------+-------------------------------------------------------------+-------------------+\n54278345|Building Resilient Data Pipelines                            |Iron Man           |\n15678345|Building Data Platforms                                      |Gamora             |\n89898782|Scaling metadata                                             |catwoman           |\n32278345|Beyond the clean data curve                                  |batman             |\n31478888|Project lightspeed - the definitive guide                    |Databricks         |\n32278888|Hello Spark Fans                                             |Advanced Analytics |\n73825104|Fundamentals of Data Observability                           |Andy Petrella      |\n73825103|High Performance Spark                                       |Holden Karau       |\n73341143|Data Engineering with Apache Spark, Delta Lake, and Lakehouse|Manoj Kukreja      |\n54725104|Fundamentals of Data Observability                           |Andy Petrella      |\n54725222|Designing Data-Intensive Applications                        |Martin Kleppmann   |\n54725283|Data Management at Scale                                     |Piethein Strengholt|\n29829283|Database Internals                                           |Alex Petrov        |\n25678345|Scaling Data Platforms                                       |Gamora             |\n39898782|Project metadata                                             |catwoman           |\n42278345|Intro to Hive metastore                                      |she-hulk           |\n52278888|Reviving zookeper                                            |dr-strange         |\n62278888|Life after Hadoop                                            |Green Arrow        |\n83825104|Fundamentals of Lakehouse                                    |Barry Allen        |\n93825104|High Performance Yarn                                        |Harley Quinn       |\n+--------+-------------------------------------------------------------+-------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%python\nbooks_df.write.mode('overwrite').parquet(s3_path+\"books_table\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c257da0e-35cb-4aaf-9719-8252540029fc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%python\n\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType\ngenre = [(\"68978345\",\"Building Resilient Data Pipelines\",\"fiction\"),\n    (\"15678345\",\"Building Data Platforms\",\"drama\"),\n    (\"89898782\",\"Scaling metadata\",\"mystery\"),\n    (\"32278345\",\"Beyond the clean data curve\",\"tragedy\"),\n    # (\"31478888\",\"Project lightspeed - the definitive guide\",\"classics\"),\n    (\"32278888\",\"Hello Spark Fans\",\"classics\"),\n    (\"73825104\",\"Fundamentals of Data Observability\",\"adventure\"),\n    # (\"73825103\",\"High Performance Spark\",\"classics\"),\n    (\"73341143\",\"Data Engineering with Apache Spark, Delta Lake, and Lakehouse\",\"adventure\"),\n    (\"54725104\",\"Fundamentals of Data Observability\",\"classics\"),\n    (\"54725222\",\"Designing Data-Intensive Applications\",\"classics\"),\n    (\"54725283\",\"Data Management at Scale\",\"classics\"),\n    # (\"29829283\",\"Database Internals\",\"classics\"), \n  \n         \n    (\"25678345\",\"Scaling Data Platforms\",\"drama\"),\n    (\"39898782\",\"Project metadata\",\"adventure\"),\n    (\"42278345\",\"Intro to Hive metastore\",\"mystery\"),\n    (\"52278888\",\"Reviving zookeper\",\"drama\"),\n    (\"62278888\",\"Life after Hadoop\",\"crime\"),\n    (\"83825104\",\"Fundamentals of Lakehouse\",\"adventure\"),\n    (\"93825104\",\"High Performance Yarn\",\"fiction\"),  \n  ]\n\nschema = StructType([ \\\n    StructField(\"isbn\",StringType(),True), \\\n    StructField(\"name\",StringType(),True), \\\n    StructField(\"genre\",StringType(),True) \\\n  ])\n \ngenre_df = spark.createDataFrame(data=genre,schema=schema)\ngenre_df.printSchema()\ngenre_df.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57e4be25-9330-4dc1-9cd5-e4303963cbda"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"genre_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"isbn","nullable":true,"type":"string"},{"metadata":{},"name":"name","nullable":true,"type":"string"},{"metadata":{},"name":"genre","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">root\n |-- isbn: string (nullable = true)\n |-- name: string (nullable = true)\n |-- genre: string (nullable = true)\n\n+--------+-------------------------------------------------------------+---------+\n|isbn    |name                                                         |genre    |\n+--------+-------------------------------------------------------------+---------+\n|68978345|Building Resilient Data Pipelines                            |fiction  |\n|15678345|Building Data Platforms                                      |drama    |\n|89898782|Scaling metadata                                             |mystery  |\n|32278345|Beyond the clean data curve                                  |tragedy  |\n|32278888|Hello Spark Fans                                             |classics |\n|73825104|Fundamentals of Data Observability                           |adventure|\n|73341143|Data Engineering with Apache Spark, Delta Lake, and Lakehouse|adventure|\n|54725104|Fundamentals of Data Observability                           |classics |\n|54725222|Designing Data-Intensive Applications                        |classics |\n|54725283|Data Management at Scale                                     |classics |\n|25678345|Scaling Data Platforms                                       |drama    |\n|39898782|Project metadata                                             |adventure|\n|42278345|Intro to Hive metastore                                      |mystery  |\n|52278888|Reviving zookeper                                            |drama    |\n|62278888|Life after Hadoop                                            |crime    |\n|83825104|Fundamentals of Lakehouse                                    |adventure|\n|93825104|High Performance Yarn                                        |fiction  |\n+--------+-------------------------------------------------------------+---------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- isbn: string (nullable = true)\n-- name: string (nullable = true)\n-- genre: string (nullable = true)\n\n+--------+-------------------------------------------------------------+---------+\nisbn    |name                                                         |genre    |\n+--------+-------------------------------------------------------------+---------+\n68978345|Building Resilient Data Pipelines                            |fiction  |\n15678345|Building Data Platforms                                      |drama    |\n89898782|Scaling metadata                                             |mystery  |\n32278345|Beyond the clean data curve                                  |tragedy  |\n32278888|Hello Spark Fans                                             |classics |\n73825104|Fundamentals of Data Observability                           |adventure|\n73341143|Data Engineering with Apache Spark, Delta Lake, and Lakehouse|adventure|\n54725104|Fundamentals of Data Observability                           |classics |\n54725222|Designing Data-Intensive Applications                        |classics |\n54725283|Data Management at Scale                                     |classics |\n25678345|Scaling Data Platforms                                       |drama    |\n39898782|Project metadata                                             |adventure|\n42278345|Intro to Hive metastore                                      |mystery  |\n52278888|Reviving zookeper                                            |drama    |\n62278888|Life after Hadoop                                            |crime    |\n83825104|Fundamentals of Lakehouse                                    |adventure|\n93825104|High Performance Yarn                                        |fiction  |\n+--------+-------------------------------------------------------------+---------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%python\ngenre_df.write.mode('overwrite').parquet(s3_path+\"genre_table\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec1e7c2b-eff6-416e-b2d7-5f3d1c0993e6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%python\ndisplay(genre_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d1ae4943-92a2-4c12-a987-316355d61b02"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["68978345","Building Resilient Data Pipelines","fiction"],["15678345","Building Data Platforms","drama"],["89898782","Scaling metadata","mystery"],["32278345","Beyond the clean data curve","tragedy"],["32278888","Hello Spark Fans","classics"],["73825104","Fundamentals of Data Observability","adventure"],["73341143","Data Engineering with Apache Spark, Delta Lake, and Lakehouse","adventure"],["54725104","Fundamentals of Data Observability","classics"],["54725222","Designing Data-Intensive Applications","classics"],["54725283","Data Management at Scale","classics"],["25678345","Scaling Data Platforms","drama"],["39898782","Project metadata","adventure"],["42278345","Intro to Hive metastore","mystery"],["52278888","Reviving zookeper","drama"],["62278888","Life after Hadoop","crime"],["83825104","Fundamentals of Lakehouse","adventure"],["93825104","High Performance Yarn","fiction"]],"plotOptions":{"displayType":"plotlyBar","customPlotOptions":{"histogram":[{"key":"bins","value":"20"}],"plotlyBar":[{"key":"grouped","value":false},{"key":"stacked","value":true},{"key":"100_stacked","value":false}]},"pivotColumns":[],"pivotAggregation":"count","xColumns":["genre"],"yColumns":["genre"]},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"isbn","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"genre","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>isbn</th><th>name</th><th>genre</th></tr></thead><tbody><tr><td>68978345</td><td>Building Resilient Data Pipelines</td><td>fiction</td></tr><tr><td>15678345</td><td>Building Data Platforms</td><td>drama</td></tr><tr><td>89898782</td><td>Scaling metadata</td><td>mystery</td></tr><tr><td>32278345</td><td>Beyond the clean data curve</td><td>tragedy</td></tr><tr><td>32278888</td><td>Hello Spark Fans</td><td>classics</td></tr><tr><td>73825104</td><td>Fundamentals of Data Observability</td><td>adventure</td></tr><tr><td>73341143</td><td>Data Engineering with Apache Spark, Delta Lake, and Lakehouse</td><td>adventure</td></tr><tr><td>54725104</td><td>Fundamentals of Data Observability</td><td>classics</td></tr><tr><td>54725222</td><td>Designing Data-Intensive Applications</td><td>classics</td></tr><tr><td>54725283</td><td>Data Management at Scale</td><td>classics</td></tr><tr><td>25678345</td><td>Scaling Data Platforms</td><td>drama</td></tr><tr><td>39898782</td><td>Project metadata</td><td>adventure</td></tr><tr><td>42278345</td><td>Intro to Hive metastore</td><td>mystery</td></tr><tr><td>52278888</td><td>Reviving zookeper</td><td>drama</td></tr><tr><td>62278888</td><td>Life after Hadoop</td><td>crime</td></tr><tr><td>83825104</td><td>Fundamentals of Lakehouse</td><td>adventure</td></tr><tr><td>93825104</td><td>High Performance Yarn</td><td>fiction</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%python\ngenre_df.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96236eb6-1b96-4e27-9b1b-385ba4965caf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[7]: 17</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[7]: 17</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%python\nbooks_df.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"005811cf-f4e5-40c5-ad65-0be9228b997d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[8]: 20</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[8]: 20</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%python\nbooks_df.write.saveAsTable(\"books\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fdfc68b1-2cbe-4460-adef-58da7b8e5eb5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-51401291651224&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>books_df<span class=\"ansi-blue-fg\">.</span>write<span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;books&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">saveAsTable</span><span class=\"ansi-blue-fg\">(self, name, format, mode, partitionBy, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    866</span>         <span class=\"ansi-green-fg\">if</span> format <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    867</span>             self<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>format<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 868</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_jwrite<span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    869</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    870</span>     <span class=\"ansi-blue-fg\">@</span>since<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1.4</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    131</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    132</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 133</span><span class=\"ansi-red-fg\">                 </span>raise_from<span class=\"ansi-blue-fg\">(</span>converted<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    134</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    135</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">raise_from</span><span class=\"ansi-blue-fg\">(e)</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: Table `books` already exists.;</div>","errorSummary":"<span class=\"ansi-red-fg\">AnalysisException</span>: Table `books` already exists.;","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-51401291651224&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>books_df<span class=\"ansi-blue-fg\">.</span>write<span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;books&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">saveAsTable</span><span class=\"ansi-blue-fg\">(self, name, format, mode, partitionBy, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    866</span>         <span class=\"ansi-green-fg\">if</span> format <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    867</span>             self<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>format<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 868</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_jwrite<span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    869</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    870</span>     <span class=\"ansi-blue-fg\">@</span>since<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1.4</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    131</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    132</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 133</span><span class=\"ansi-red-fg\">                 </span>raise_from<span class=\"ansi-blue-fg\">(</span>converted<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    134</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    135</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">raise_from</span><span class=\"ansi-blue-fg\">(e)</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: Table `books` already exists.;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%python\ngenre_df.write.saveAsTable(\"genre\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"115c081f-db96-403c-bbc4-d7f7f1253490"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Git like interface - Branching out\n\n![](https://docs.lakefs.io/assets/img/branching_7.png)\n<!-- ![](https://miro.medium.com/max/1400/0*2N9qc0DlQmD_nK_Q.png) -->\n<!-- <img src=\"https://miro.medium.com/max/1400/0*2N9qc0DlQmD_nK_Q.png\" alt=\"drawing\" style=\"width:50px;height:20px;\"/> -->"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"49eb8c96-a26d-4b59-8017-d1c8f0a3c342"}}},{"cell_type":"markdown","source":["## Cross collection consistency\nWe often need consistency between different data collections. A few examples may be:\n\n* To join different collections in order to create a unified view of an account, a user or another entity we measure.\n* To introduce the same data in different formats\n* To introduce the same data with a different leading index or sorting due to performance considerations\n\n![](https://docs.lakefs.io/assets/img/branching_8.png)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"12766f99-d304-4e34-95f9-8ddf4c6e02b5"}}},{"cell_type":"code","source":["%python\nbooks_df = spark.read.option(\"header\",True).format(\"parquet\").load(main_repo_path+\"books.csv\")\n\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec43a38c-3f9e-421e-8d48-d1a8097ae8fc"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\nmain_repo_path = \"lakefs://dais22-adi/main/\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6183054d-d5ef-40b4-8b35-6be3bb6bef6d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%python\nbooks_df.write.parquet(main_repo_path+\"books\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f9ed8c1-26f2-4073-8dff-20b258e36f6e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%python\ngenre_df.write.parquet(main_repo_path+\"genres\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e8f5826-bf23-4638-9e67-c4ca913e3081"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Data books - Generate data","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":51401291651215}},"nbformat":4,"nbformat_minor":0}
