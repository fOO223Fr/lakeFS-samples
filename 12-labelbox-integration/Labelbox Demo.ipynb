{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3f8456-55df-4049-9a8f-72e536ad2ec4",
   "metadata": {},
   "source": [
    "## Setup Task: Import required Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc28cf0-9a6d-4bf0-8dd8-0fd49f996216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import labelbox\n",
    "import datetime\n",
    "from tabulate import tabulate\n",
    "from uuid import uuid4 ## to generate unique IDs\n",
    "import json\n",
    "from labelbox.schema.ontology import OntologyBuilder, Tool, Classification,Option\n",
    "import random\n",
    "from labelbox.data.annotation_types import (\n",
    "    Label,\n",
    "    Point,\n",
    "    LabelList,\n",
    "    ImageData,\n",
    "    Rectangle,\n",
    "    ObjectAnnotation,\n",
    ")\n",
    "from labelbox.data.serialization import NDJsonConverter\n",
    "import time\n",
    "from labelbox.schema.annotation_import import LabelImport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fd2b3c-ce61-4550-9e2d-d13dbb3e95d2",
   "metadata": {},
   "source": [
    "## Setup Task: Change your lakeFS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054f3d82-eb19-431c-b872-b2ea2b970c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakefsEndPoint = '<lakeFS Endpoint URL>' # e.g. 'https://username.aws_region_name.lakefscloud.io'\n",
    "lakefsAccessKey = '<lakeFS Access Key>'\n",
    "lakefsSecretKey = '<lakeFS Secret Key>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aa0da4-31f1-4a3d-82dc-fb521a92467e",
   "metadata": {},
   "source": [
    "## Setup Task: Storage Information for lakeFS repository\n",
    "#### Change the Storage Namespace to a location in the bucket youâ€™ve configured. The storage namespace is a location in the underlying storage where data for lakeFS repository will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f80f353-42ca-4290-8103-9df7dbb07ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageNamespace = 's3://<S3 Bucket Name>/' # e.g. \"s3://username-lakefs-cloud/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa6cbd-db4a-4a91-bebd-a694eb996eea",
   "metadata": {},
   "source": [
    "## Setup Task: You can change lakeFS repo name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370fed7d-c4fb-4f13-82d8-4a376eda2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"labelbox-repo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e17a225-8813-4da9-8da4-8f660093d243",
   "metadata": {},
   "source": [
    "## Setup Task: Versioning Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf704e6-c3b0-4adb-800a-0305aef26973",
   "metadata": {},
   "outputs": [],
   "source": [
    "mainBranch = \"main\"\n",
    "emptyBranch = \"empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b10f1c-2b0c-4e87-9a6c-7e046e6a07e5",
   "metadata": {},
   "source": [
    "## Setup Task: Change S3 Storage Information for storing images\n",
    "#### Provide a S3 bucket, AWS region and access key information. This demo will upload few images to this S3 bucket and both lakeFS and Labelbox will access those images to create the datasets.\n",
    "#### Enable AWS S3 integration and access to this S3 bucket by Labelbox by following instructions in the Labelbox docs: https://docs.labelbox.com/docs/import-aws-s3-data\n",
    "#### lakeFS should also be able to read from this S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544cdd6a-318a-4fd8-8788-d60763123bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketName = '<S3 Bucket Name>' # e.g. labelbox-geospatial-vessel-detection\n",
    "awsRegion = '<AWS region name>' # e.g. us-east-1\n",
    "aws_access_key_id = 'aaaaaaaaaaaaa'\n",
    "aws_secret_access_key = 'bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb'\n",
    "contentTypeJPG = \"image/jpeg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ea1ec-71f7-463b-a48e-dd16148cb1c8",
   "metadata": {},
   "source": [
    "## Setup Task: Change your Labelbox credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e67394-8ab0-4a6f-b494-7c1653959f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "LB_API_KEY = \"<Labelbox API Key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd960a9-6bd5-4d92-88ca-087d2f818877",
   "metadata": {},
   "source": [
    "## Setup Task: Labelbox dataset name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dd992e-8397-46b3-925f-224b6f303c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbDataSetName = 'lakeFS Geospatial Vessel Detection'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1259ef-d6d6-48d5-80ab-9c23ce15de8c",
   "metadata": {},
   "source": [
    "## Setup Task: lakeFS Upload Objects Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb0dbf1-6115-43ec-80ce-36ee3547e07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_files(repo, branch, path, files):\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        contentToUpload = open(file, 'rb') # Only a single file per upload which must be named \\\\\\\"content\\\\\\\"\n",
    "        client.objects.upload_object(\n",
    "            repository=repo,\n",
    "            branch=branch,\n",
    "            path=path+'/'+os.path.basename(file), content=contentToUpload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee258c-e939-41c6-bf5f-f456333ffac0",
   "metadata": {},
   "source": [
    "## Setup Task: lakeFS Stage Object Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0094af-c6e0-465f-8be5-bc3cac41575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lakefs_client.model.object_stage_creation import ObjectStageCreation\n",
    "from lakefs_client.model.object_user_metadata import ObjectUserMetadata\n",
    "\n",
    "def object_stage(source_uri, size_bytes, content_type):\n",
    "    object_stage_creation = ObjectStageCreation(\n",
    "        physical_address=source_uri,\n",
    "        checksum=\"\",\n",
    "        size_bytes=size_bytes,\n",
    "        mtime=1,\n",
    "        metadata=ObjectUserMetadata( # optional\n",
    "            key=\"version: v1\",\n",
    "        ),\n",
    "        content_type=content_type,\n",
    "    ) # ObjectStageCreation | \n",
    "    return object_stage_creation\n",
    " \n",
    "def stage_objects(repo_name, importBranch, source_uri, path, size_bytes, content_type):   \n",
    "    object_stage_creation = object_stage(source_uri, size_bytes, content_type)\n",
    "    try:       \n",
    "        api_response_1 = client.objects.stage_object(repo_name, importBranch, path, object_stage_creation)\n",
    "       \n",
    "    except lakefs_client.ApiException as e:\n",
    "        print(\"Exception when calling objects->stage_object: %s\\n\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64be33a9-e80f-43db-a7a0-9ffe22649d49",
   "metadata": {},
   "source": [
    "## Setup Task: Create S3 client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903271f5-ff5c-4b25-9d64-517a75b95ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.client('s3',\n",
    "    endpoint_url='https://s3.' + awsRegion + '.amazonaws.com',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b28561-2878-4299-b566-3039b6e605ef",
   "metadata": {},
   "source": [
    "## Setup Task: Create lakeFS Python client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69327827-9bd2-44b3-b1e2-e2ae47b7a6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%xmode Minimal\n",
    "import lakefs_client\n",
    "from lakefs_client import models\n",
    "from lakefs_client.client import LakeFSClient\n",
    "import datetime\n",
    "\n",
    "# lakeFS credentials and endpoint\n",
    "configuration = lakefs_client.Configuration()\n",
    "configuration.username = lakefsAccessKey\n",
    "configuration.password = lakefsSecretKey\n",
    "configuration.host = lakefsEndPoint\n",
    "\n",
    "client = LakeFSClient(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f8f1c2-65d7-4d03-b68b-064d3194672c",
   "metadata": {},
   "source": [
    "## Setup Task: S3A Gateway configuration\n",
    "\n",
    "##### Note: lakeFS can be configured to work with Spark in two ways:\n",
    "###### * Access lakeFS using the S3A gateway https://docs.lakefs.io/integrations/spark.html#access-lakefs-using-the-s3a-gateway.\n",
    "###### * Access lakeFS using the lakeFS-specific Hadoop FileSystem https://docs.lakefs.io/integrations/spark.html#access-lakefs-using-the-lakefs-specific-hadoop-filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03c95ae-6447-4f61-b4ed-6f2ad00f2cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", lakefsAccessKey)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", lakefsSecretKey)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", lakefsEndPoint)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7749cd-2748-4c55-b420-ac79f6a2bc28",
   "metadata": {},
   "source": [
    "# Next few steps are same as used in Labelbox tutorial:\n",
    "#### https://docs.labelbox.com/reference/import-a-labeled-dataset-images-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16dcdd-12cb-445c-89c2-b34640ac562c",
   "metadata": {},
   "source": [
    "## Setup Task: Create Labelbox Python client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9122a925-d080-401f-b666-b556323cb25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_client = labelbox.Client(LB_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb8789e-32b1-41eb-b560-10929edfe11a",
   "metadata": {},
   "source": [
    "## Setup Task: Upload images to S3 bucket\n",
    "#### These images are same as used in Labelbox tutorial: https://docs.labelbox.com/reference/import-a-labeled-dataset-images-1\n",
    "#### This process may take few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42618bad-cacb-464c-a993-fbe9507e7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, subdirs, files in os.walk(os.path.expanduser('~')+'/Images/Labelbox/AllImages/'):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            folder = path.rsplit(\"/\")[-1]\n",
    "            s3.upload_file(Filename=path+'/'+file, Bucket=bucketName, Key=folder+'/'+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe4fd1d-de2e-48ce-b41a-10a89854ba02",
   "metadata": {},
   "source": [
    "## Read annotations file\n",
    "#### This annotations file is same as used in Labelbox tutorial: https://docs.labelbox.com/reference/import-a-labeled-dataset-images-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea8b79-3c78-4661-9974-6b4d17861fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.expanduser('~')+'/Images/Labelbox/geospatial_annotations.json', 'r') as fp:\n",
    "    annotations = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbfab67-1179-47b5-ad8d-25879ec80e4e",
   "metadata": {},
   "source": [
    "## Create Labelbox dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74f9880-0711-40eb-9917-4c8a7f1ddc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = lb_client.create_dataset(name=lbDataSetName)\n",
    "data_rows = []\n",
    "\n",
    "for path, subdirs, files in os.walk(os.path.expanduser('~')+'/Images/Labelbox/AllImages/'):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            folder = path.rsplit(\"/\")[-1]\n",
    "            data_row_dict = {'row_data': \"https://\"+ bucketName + \".s3.\" + awsRegion + \".amazonaws.com/\" + folder + '/' + file,\n",
    "                \"global_key\": \"https://\" + bucketName + \".s3.\" + awsRegion + \".amazonaws.com/\" + folder + '/' + file  + str(uuid4()),\n",
    "                \"external_id\": folder + \"/\" + file,\n",
    "                'media_type': 'IMAGE',\n",
    "                \"metadata_fields\": [{\"schema_id\": \"cko8s9r5v0001h2dk9elqdidh\", \"value\": \"tag_string\"}],\n",
    "                \"attachments\": [{\"type\": \"IMAGE_OVERLAY\", \"value\": \"https://storage.googleapis.com/labelbox-sample-datasets/Docs/rgb.jpg\", \"name\": \"RGB\" }],\n",
    "            }\n",
    "            data_rows.append(data_row_dict)\n",
    "\n",
    "task = dataset.create_data_rows(data_rows)\n",
    "task.wait_till_done()\n",
    "print(task.errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bd1412-bcd4-46b3-9409-214833eca088",
   "metadata": {},
   "source": [
    "## Setup a labeling project in Labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16921be5-1b01-4567-8772-f9ee432afc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology = OntologyBuilder()\n",
    "\n",
    "for tool in annotations['categories']:\n",
    "  print(tool['name'])\n",
    "  ontology.add_tool(Tool(tool = Tool.Type.BBOX, name = tool['name']))\n",
    "\n",
    "ontology = lb_client.create_ontology(lbDataSetName + \" ontology\", ontology.asdict())\n",
    "project = lb_client.create_project(name = lbDataSetName)\n",
    "project.setup_editor(ontology)\n",
    "ontology_from_project = OntologyBuilder.from_project(project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2309e9f7-c5d0-4d65-8930-6e9e94b19d55",
   "metadata": {},
   "source": [
    "## Prepare and queue batch of Data Rows to the Labelbox project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb071eff-b48e-4d5d-a8c0-eea139e2716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rows = [dr.uid for dr in list(dataset.export_data_rows())]\n",
    "\n",
    "# Randomly select 200 Data Rows\n",
    "sampled_data_rows = random.sample(data_rows, 200)\n",
    "\n",
    "batch = project.create_batch(\n",
    "  \"Initial batch\", # name of the batch\n",
    "  sampled_data_rows, # list of Data Rows\n",
    "  1 # priority between 1-5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d91d466-070f-4229-9ec1-66437ed808ed",
   "metadata": {},
   "source": [
    "## Process ground truth annotations for import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee365c1b-81fa-4319-8c8f-e4180fcd01c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "queued_data_rows = project.export_queued_data_rows()\n",
    "ground_truth_list = LabelList()\n",
    "\n",
    "for datarow in queued_data_rows:\n",
    "  annotations_list = []\n",
    "  folder = datarow['externalId'].split(\"/\")[0]\n",
    "  id = datarow['externalId'].split(\"/\")[1]\n",
    "  if folder == \"positive_image_set\":\n",
    "    for image in annotations['images']:\n",
    "      if (image['file_name']==id):\n",
    "        for annotation in annotations['annotations']:\n",
    "          if annotation['image_id'] == image['id']:\n",
    "            bbox = annotation['bbox']\n",
    "            id = annotation['category_id'] - 1\n",
    "            class_name = ontology_from_project.tools[id].name\n",
    "            annotations_list.append(ObjectAnnotation(\n",
    "                name = class_name,\n",
    "                value = Rectangle(start = Point(x = bbox[0], y = bbox[1]), end = Point(x = bbox[2]+bbox[0], y = bbox[3]+bbox[1])),\n",
    "            ))\n",
    "  image = ImageData(uid = datarow['id'])\n",
    "  ground_truth_list.append(Label(data = image, annotations = annotations_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb2120f-c5e6-4fec-99f6-021d77410e53",
   "metadata": {},
   "source": [
    "## Import ground truth annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152dcb6-e8a1-4307-a3b7-182fc79a2b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_list.assign_feature_schema_ids(OntologyBuilder.from_project(project))\n",
    "ground_truth_ndjson = list(NDJsonConverter.serialize(ground_truth_list))\n",
    "\n",
    "start_time = time.time()\n",
    "## Upload annotations\n",
    "upload_task = LabelImport.create_from_objects(lb_client, project.uid, \"geospatial-import-job-1\", ground_truth_ndjson)\n",
    "print(upload_task)\n",
    "\n",
    "#Wait for upload to finish (Will take up to five minutes)\n",
    "upload_task.wait_until_done()\n",
    "print(upload_task.errors)\n",
    "print(\"--- Finished in %s mins ---\" % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9067c3af-b96b-40c6-92e0-c6b70ab83044",
   "metadata": {},
   "source": [
    "## Create a new repo in lakeFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570f3b73-6e60-4026-bdee-b9981f1895a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.repositories.create_repository(\n",
    "    repository_creation=models.RepositoryCreation(\n",
    "        name=repo,\n",
    "        storage_namespace=storageNamespace,\n",
    "        default_branch=mainBranch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a33bebc-dc66-45dd-b55d-06b94cf8c64b",
   "metadata": {},
   "source": [
    "## Create an empty branch in lakeFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d16af-4c63-45b9-bd85-10cba8e916d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.branches.create_branch(\n",
    "    repository=repo,\n",
    "    branch_creation=models.BranchCreation(\n",
    "        name=emptyBranch,\n",
    "        source=mainBranch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066cb7d4-bf83-4d22-a58f-bbafeb1074e6",
   "metadata": {},
   "source": [
    "# Project Starts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2c2c77-5161-4e6d-b2a7-c6d307e8fd2b",
   "metadata": {},
   "source": [
    "## Labelbox Slice\n",
    "#### Create a Slice in Labelbox for a particular Annotation e.g. vehicle and save the slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e52283-3a49-4c36-8212-4862f7666f0f",
   "metadata": {},
   "source": [
    "![Vehicle Slice](./Images/Labelbox/VehicleSlice1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578de22c-b31a-4d32-aa33-689f99efa3a0",
   "metadata": {},
   "source": [
    "## Copy the Slice ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c27aa7f-c5de-48ef-9d34-bf1d16b54c36",
   "metadata": {},
   "source": [
    "![Vehicle Slice](./Images/Labelbox/VehicleSlice2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e2d19-8f31-4405-8f80-575bb95baa3d",
   "metadata": {},
   "source": [
    "## Paste Labelbox Slice ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9516d0c4-9111-450e-9ab5-75d387609e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_slice_id = \"<Labelbox slice id>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea20cf2-9d12-4e4d-88bc-efd13260a12a",
   "metadata": {},
   "source": [
    "## Class label and version information\n",
    "#### Class label can be Annotation name e.g. vehicle or any other label you want to use in lakeFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e44fa-07b9-4037-988d-e8a848e9e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "classLabel = \"vehicle\"\n",
    "version = \"v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29ced5d-f532-4f62-aa07-5bffa63f86b3",
   "metadata": {},
   "source": [
    "## Create empty Project v1 branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd1a475-233b-4e77-9c0f-c81001b013e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "projectBranchV1 = \"project_\"+classLabel+\"_\"+version\n",
    "\n",
    "client.branches.create_branch(\n",
    "    repository=repo,\n",
    "    branch_creation=models.BranchCreation(\n",
    "        name=projectBranchV1,\n",
    "        source=emptyBranch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a66971d-70ff-41fc-ace3-547596cc1157",
   "metadata": {},
   "source": [
    "## Read Labelbox slice and stage/import those images to Project v1 branch in lakeFS repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea6267-369a-4140-9306-5e80f7b8cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_slice = lb_client.get_catalog_slice(catalog_slice_id) #-> CatalogSlice\n",
    "\n",
    "# Get data row ids in a slice\n",
    "slice_data_rows_ids = catalog_slice.get_data_row_ids()\n",
    "for data_row_id in slice_data_rows_ids:\n",
    "    datarow = lb_client.get_data_row(data_row_id)\n",
    "    filename = datarow.external_id #.split(\"/\")[1]\n",
    "    filesize = datarow.media_attributes[\"contentLength\"]\n",
    "\n",
    "    # Stage image file\n",
    "    stage_objects(repo, projectBranchV1, \"s3://\"+bucketName+\"/\"+filename, filename, filesize, contentTypeJPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39182e2-6038-41df-b1d4-a7d389e3bc5f",
   "metadata": {},
   "source": [
    "## Commit changes and attach some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7004c-6102-463b-b983-e96a37e2960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.commits.commit(\n",
    "    repository=repo,\n",
    "    branch=projectBranchV1,\n",
    "    commit_creation=models.CommitCreation(\n",
    "        message='Uploaded images for class label '+classLabel+' and version '+version,\n",
    "        metadata={'classLabel': classLabel,\n",
    "            'version': version}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17f6652-331f-40b1-9792-7670cc17b20c",
   "metadata": {},
   "source": [
    "## Add v1 tag for future use. You can also run your model by using this tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf715e-0cbb-4bc1-ac06-c2135ded71c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagV1 = datetime.datetime.now().strftime(\"%Y_%m_%d\")+f\"_{projectBranchV1}\"\n",
    "\n",
    "client.tags.create_tag(\n",
    "    repository=repo,\n",
    "    tag_creation=models.TagCreation(\n",
    "        id=tagV1, \n",
    "        ref=projectBranchV1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97691558-efef-4b84-83b7-b55bc4ad1f55",
   "metadata": {},
   "source": [
    "## Read images using v1 tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83525486-94fe-4d6b-b4e5-b3f08a707d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = f\"s3a://{repo}/{tagV1}/positive_image_set/\"\n",
    "\n",
    "df= spark.read.format(\"image\").load(dataPath)\n",
    "df.select(\"image.origin\", \"image.width\", \"image.height\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c125a08-1b00-4e9c-9e0e-1adcb5c09ead",
   "metadata": {},
   "source": [
    "## Create Project v2 branch sourced from v1 branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e419338-53be-4d65-bc28-bf03297156fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5cd3e8-c545-439e-9eff-1cb56c91310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "projectBranchV2 = \"project_\"+classLabel+\"_\"+version\n",
    "\n",
    "client.branches.create_branch(\n",
    "    repository=repo,\n",
    "    branch_creation=models.BranchCreation(\n",
    "        name=projectBranchV2,\n",
    "        source=projectBranchV1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288cafaa-63fd-4581-89ff-e0793971820d",
   "metadata": {},
   "source": [
    "## Upload changed and new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff233528-699a-4dfe-9f5f-a1873d3312fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.expanduser('~')+'/Images/Labelbox/ChangedImages/positive_image_set/'\n",
    "files = Path(directory).glob('*.jpg')\n",
    "path = 'positive_image_set'\n",
    "\n",
    "upload_files(repo, projectBranchV2, path, files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbffc337-3860-43e3-af71-1dc267eedc25",
   "metadata": {},
   "source": [
    "## Commit changes and attach some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c5615-435f-48e8-b054-a20211b3fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.commits.commit(\n",
    "    repository=repo,\n",
    "    branch=projectBranchV2,\n",
    "    commit_creation=models.CommitCreation(\n",
    "        message='Uploaded changed images for class label '+classLabel+' and version '+version,\n",
    "        metadata={'classLabel': classLabel,\n",
    "            'version': version}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f2ae39-c25b-4edd-b084-fd8e42ad5de9",
   "metadata": {},
   "source": [
    "## Review commit log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033bb195-b9e3-4837-adef-d5cf2691129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = map(\n",
    "    lambda n:[n.message,n.metadata,n.id],\n",
    "    client.refs.log_commits(\n",
    "        repository=repo,\n",
    "        ref=projectBranchV2).results)\n",
    "\n",
    "print(tabulate(\n",
    "    results,\n",
    "    headers=['Message','Metadata','Commit Id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d817972a-aca8-4564-b7b1-95829629fc46",
   "metadata": {},
   "source": [
    "## Add v2 tag for future use. You can also run your model by using this tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b569c30-93ee-4343-a59b-c8058674143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagV2 = datetime.datetime.now().strftime(\"%Y_%m_%d\")+f\"_{projectBranchV2}\"\n",
    "\n",
    "client.tags.create_tag(\n",
    "    repository=repo,\n",
    "    tag_creation=models.TagCreation(\n",
    "        id=tagV2, \n",
    "        ref=projectBranchV2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9d16bd-434a-49c4-9d0f-2c0f97193769",
   "metadata": {},
   "source": [
    "## Read images using v2 tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ec9d7-9c33-424d-b809-c496bb1d3f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = f\"s3a://{repo}/{tagV2}/positive_image_set/\"\n",
    "\n",
    "df= spark.read.format(\"image\").load(dataPath)\n",
    "df.select(\"image.origin\", \"image.width\", \"image.height\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6393f-b95a-4c18-9e13-35e223eeb891",
   "metadata": {},
   "source": [
    "## Diff between v1 and v2 project branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d82ed8-4966-4907-9edf-3fc04c0bc11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = map(\n",
    "    lambda n:[n.path,n.path_type,n.size_bytes,n.type],\n",
    "    client.refs.diff_refs(\n",
    "        repository=repo,\n",
    "        left_ref=projectBranchV1,\n",
    "        right_ref=projectBranchV2).results)\n",
    "\n",
    "print(tabulate(\n",
    "    results,\n",
    "    headers=['Path','Path Type','Size(Bytes)','Type']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05abcb6-5638-41ba-987e-48ff79295729",
   "metadata": {},
   "source": [
    "## If you made mistakes then you can atomically rollback all changes in v2 branch\n",
    "\n",
    "### Rollback changes in v2 branch by using v2 tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7b6a4f-54ef-4d03-812f-10a3d5331ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.branches.revert_branch(\n",
    "    repository=repo,\n",
    "    branch=projectBranchV2, \n",
    "    revert_creation=models.RevertCreation(\n",
    "        ref=tagV2, parent_number=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be41fa65-f29d-40f0-a1cc-224ac426c89d",
   "metadata": {},
   "source": [
    "## Diff between v1 and v2 project branch\n",
    "#### There will be no difference now as you rolled back the changes in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae3658a-fd11-4389-989e-45d84630e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = map(\n",
    "    lambda n:[n.path,n.path_type,n.size_bytes,n.type],\n",
    "    client.refs.diff_refs(\n",
    "        repository=repo,\n",
    "        left_ref=projectBranchV1,\n",
    "        right_ref=projectBranchV2).results)\n",
    "\n",
    "print(tabulate(\n",
    "    results,\n",
    "    headers=['Path','Path Type','Size(Bytes)','Type']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f09ee0d-fbea-42c4-8746-b7e6d907425e",
   "metadata": {},
   "source": [
    "# Project Completes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afece730-4cdb-4dc7-ac43-1187986ba42c",
   "metadata": {},
   "source": [
    "## More Questions?\n",
    "\n",
    "###### Join the lakeFS Slack group - https://lakefs.io/slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d0506-477e-432e-952d-d4762be15463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
