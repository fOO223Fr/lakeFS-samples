{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b2c8fa0-1702-411a-b11c-3190679bf31c",
   "metadata": {},
   "source": [
    "# Data Lineage with lakeFS\n",
    "\n",
    "## Use Case: Understand data transformations by using commits with metadata and \"Blame\" functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1f1244-ba66-4560-9e0c-7b87660aff67",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "###### This Notebook requires connecting to a lakeFS Server. \n",
    "###### To spin up lakeFS quickly - use lakeFS Cloud (https://lakefs.cloud) which provides lakeFS server on-demand with a single click; \n",
    "###### Or, alternatively, refer to lakeFS Quickstart doc (https://docs.lakefs.io/quickstart/installing.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de52058-394b-47b3-9821-872153d88ed3",
   "metadata": {},
   "source": [
    "![lineage](./Images/CommitFlow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f4469-9708-435d-bec9-c943fd87a0bf",
   "metadata": {},
   "source": [
    "## Change your lakeFS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa46799-5f86-4104-9447-d91328edbff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakefsEndPoint = 'https://' # e.g. 'https://username.aws_region_name.lakefscloud.io'\n",
    "lakefsAccessKey = ''\n",
    "lakefsSecretKey = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d1c562-9899-4343-b887-c5c018ea79b0",
   "metadata": {},
   "source": [
    "## Storage Information\n",
    "#### Change the Storage Namespace to a location in the bucket youâ€™ve configured. The storage namespace is a location in the underlying storage where data for this repository will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b151c2-743d-43e1-9f2f-25482967c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageNamespace = '' # e.g. \"s3://username-lakefs-cloud/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c093db8e-68d9-409f-bde7-73ee4ceca5a5",
   "metadata": {},
   "source": [
    "## Versioning Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b839850-5954-4631-8e7e-d0dee6d17dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "productionBranch = \"main\"\n",
    "ingestionBranch1 = \"ingest1\"\n",
    "ingestionBranch2 = \"ingest2\"\n",
    "transformationBranch = \"transformation\"\n",
    "newPath = \"partitioned_data\"\n",
    "fileName = \"Employees.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ede096-1b84-4b59-bdd1-2608ced6be51",
   "metadata": {},
   "source": [
    "## Working with the lakeFS Python client API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468e98e4-7e06-4373-b36b-f1763cc7755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%xmode Minimal\n",
    "import lakefs_client\n",
    "from lakefs_client import models\n",
    "from lakefs_client.client import LakeFSClient\n",
    "\n",
    "# lakeFS credentials and endpoint\n",
    "configuration = lakefs_client.Configuration()\n",
    "configuration.username = lakefsAccessKey\n",
    "configuration.password = lakefsSecretKey\n",
    "configuration.host = lakefsEndPoint\n",
    "\n",
    "client = LakeFSClient(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724cfd8-bda5-4c16-bff6-e05d0ad7f74a",
   "metadata": {},
   "source": [
    "## You can change lakeFS repo name (it can be an existing repo or provide another repo name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da678dc-5a25-4b90-9dea-30052f45e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"iddo-repo-lineage-example\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2422d8af-c714-4d32-aa7b-eddfacbbddb4",
   "metadata": {},
   "source": [
    "## If above mentioned repo already exists on your lakeFS server then you can skip following step otherwise create a new repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a4d613-f76d-497d-844d-21aadf1fc50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.repositories.create_repository(\n",
    "    repository_creation=models.RepositoryCreation(\n",
    "        name=repo,\n",
    "        storage_namespace=storageNamespace,\n",
    "        default_branch=productionBranch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b53725-95e6-4c78-9e17-fa271424a3d4",
   "metadata": {},
   "source": [
    "## S3A Gateway configuration\n",
    "\n",
    "##### Note: lakeFS can be configured to work with Spark in two ways:\n",
    "###### * Access lakeFS using the S3A gateway https://docs.lakefs.io/integrations/spark.html#access-lakefs-using-the-s3a-gateway.\n",
    "###### * Access lakeFS using the lakeFS-specific Hadoop FileSystem https://docs.lakefs.io/integrations/spark.html#access-lakefs-using-the-lakefs-specific-hadoop-filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5886ad4-d97d-4ab8-a158-9c034fa0e293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", lakefsAccessKey)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", lakefsSecretKey)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", lakefsEndPoint)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23408882-333a-413a-be3c-2d799e706a72",
   "metadata": {},
   "source": [
    "## Ingest data into the first ingestion branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb3147-4da8-4e77-98ed-3073ee64bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.branches.create_branch(\n",
    "    repository=repo,\n",
    "    branch_creation=models.BranchCreation(\n",
    "        name=ingestionBranch1,\n",
    "        source=productionBranch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1d011-b1ae-444b-88da-bf79f5eb00b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "contentToUpload = open(os.path.expanduser('~')+'/'+fileName, 'rb') # Only a single file per upload which must be named \\\\\\\"content\\\\\\\"\n",
    "client.objects.upload_object(\n",
    "    repository=repo,\n",
    "    branch=ingestionBranch1,\n",
    "    path=fileName, content=contentToUpload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1629fe-2b8d-442b-bb42-9a9e1779875e",
   "metadata": {},
   "source": [
    "## Commit changes to first ingest branch and attach some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1708e-7d0a-413c-85c9-d5266cde2e20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.commits.commit(\n",
    "    repository=repo,\n",
    "    branch=ingestionBranch1,\n",
    "    commit_creation=models.CommitCreation(\n",
    "        message='Ingesting employees IDs',\n",
    "        metadata={'using': 'python_api',\n",
    "                  'codeVersion': 'https://github.com/treeverse/lakeFS-samples/blob/668c7d000b8c603b3f30789a8c10616086ef79c1/08-data-lineage/Data%20Lineage.ipynb',\n",
    "                  'source': 'Employees.csv'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70239947-a305-4f3a-a275-c9a528bafce6",
   "metadata": {},
   "source": [
    "## Ingest data into the second ingestion branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f32838-5538-4e79-8d33-e548a31b2d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.branches.create_branch(\n",
    "    repository=repo,\n",
    "    branch_creation=models.BranchCreation(\n",
    "        name=ingestionBranch2,\n",
    "        source=productionBranch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d929967-2930-4d4c-8116-d0743572c88c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fileName = \"Salaries.csv\"\n",
    "\n",
    "import os\n",
    "contentToUpload = open(os.path.expanduser('~')+'/'+fileName, 'rb') # Only a single file per upload which must be named \\\\\\\"content\\\\\\\"\n",
    "client.objects.upload_object(\n",
    "    repository=repo,\n",
    "    branch=ingestionBranch2,\n",
    "    path=fileName, content=contentToUpload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18b8e20-2b4b-465f-9fee-055a6b2d6b5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Commit changes to second ingest branch with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de98ea2d-02af-4e77-b12e-718331def467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.commits.commit(\n",
    "    repository=repo,\n",
    "    branch=ingestionBranch2,\n",
    "    commit_creation=models.CommitCreation(\n",
    "        message='Ingesting Salaries',\n",
    "        metadata={'using': 'python_api',\n",
    "                  'codeVersion': 'https://github.com/treeverse/lakeFS-samples/blob/668c7d000b8c603b3f30789a8c10616086ef79c1/08-data-lineage/Data%20Lineage.ipynb',\n",
    "                  'source': '/Salaries.csv'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d2dc7-3238-4fd0-8316-a0b625dad86d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Merge the lists in a transformation branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae2e52c-9346-4db6-86b7-444e671a92c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.branches.create_branch(\n",
    "    repository=repo,\n",
    "    branch_creation=models.BranchCreation(\n",
    "        name=transformationBranch,\n",
    "        source=productionBranch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeccd29-542e-428b-90e2-e8dcc2300389",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.refs.merge_into_branch(\n",
    "    repository=repo,\n",
    "    source_ref=ingestionBranch1, \n",
    "    destination_branch=transformationBranch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51963bf1-bfe4-4d48-9f74-d81340b0467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.refs.merge_into_branch(\n",
    "    repository=repo,\n",
    "    source_ref=ingestionBranch2, \n",
    "    destination_branch=transformationBranch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73862f53-86bc-4832-962d-e25515eac1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "employeeFile=\"Employees.csv\"\n",
    "SalariesFile=\"Salaries.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192534ef-122c-43b7-9265-1e789b59e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = f\"s3a://{repo}/{transformationBranch}/{employeeFile}\"\n",
    "\n",
    "df1 = spark.read.option(\"header\", \"true\").csv(dataPath)\n",
    "df1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc7b024-8047-405e-bc33-bb628c11ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = f\"s3a://{repo}/{transformationBranch}/{SalariesFile}\"\n",
    "\n",
    "df2 = spark.read.option(\"header\", \"true\").csv(dataPath)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd447d6-0285-4ccd-8c8d-ea4537d704af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDataset = df1.join(df2,[\"id\"])\n",
    "mergedDataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e879bc6f-778d-479f-b174-5ac74c2ddb7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Partition by department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dde293-232a-4ed6-8d50-10d755b462ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDataPath = f\"s3a://{repo}/{transformationBranch}/{newPath}\"\n",
    "\n",
    "mergedDataset.write.partitionBy(\"department\").csv(newDataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa58149f-2440-42b0-a719-926321271f8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Commit with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f99a266-cc77-4f46-918d-f5931fadb7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.commits.commit(\n",
    "    repository=repo,\n",
    "    branch=transformationBranch,\n",
    "    commit_creation=models.CommitCreation(\n",
    "        message='Repartitioned by departments',\n",
    "        metadata={'using': 'python_api',\n",
    "                  'codeVersion': 'https://github.com/treeverse/lakeFS-samples/blob/668c7d000b8c603b3f30789a8c10616086ef79c1/08-data-lineage/Data%20Lineage.ipynb'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7046c7c-b4f2-44c7-8e48-5845808d47c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Atomically promote data to Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ec3ec-46a0-45f5-a811-8c4fe1776fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.refs.merge_into_branch(\n",
    "    repository=repo,\n",
    "    source_ref=transformationBranch, \n",
    "    destination_branch=productionBranch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf0a1a5-f850-4267-9d18-d47b3d8c9d9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Where did a dataset come from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a75f3f-fd76-4d9c-a3ea-55260787103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "commits = client.refs.log_commits(repository=repo, ref='main', amount=1, limit=True, prefixes=['partitioned_data/department=Engineering/'])\n",
    "print(commits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bdd86e-1dad-4816-bc33-4674212443fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "commits = client.refs.log_commits(repository=repo, ref='main', amount=1, objects=['Employees.csv'])\n",
    "print(commits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee85512-9b10-4fb1-9a13-95be81f4d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakefs_client.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681538a9-5146-4201-99c8-148222aa7a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a290f98f-6169-470a-834d-4c22115a0877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
