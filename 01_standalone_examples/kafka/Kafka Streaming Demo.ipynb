{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ccf8b6a-7076-43b9-82ee-d84fdfd75522",
   "metadata": {},
   "source": [
    "<img src=\"https://lakefs.io/wp-content/uploads/2022/09/lakeFS-Logo.svg\" alt=\"lakeFS logo\" width=250/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src=\"https://www.apache.org/logos/res/kafka/default.png\" alt=\"Apache Kafka\" width=200/>  \n",
    "\n",
    "## lakeFS ‚ù§Ô∏è Apache Kafka - an example using streaming data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9ba792-9948-4d21-8346-8dac596063ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Config\n",
    "\n",
    "**_If you're not using the provided lakeFS server and MinIO storage then change these values to match your environment_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6cb169-f6ad-4927-abbc-cc740d7e1a82",
   "metadata": {},
   "source": [
    "### lakeFS endpoint and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e64da-c208-49f3-963d-9bf9c488b52a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefsEndPoint = 'http://lakefs:8000' # e.g. 'https://username.aws_region_name.lakefscloud.io' \n",
    "lakefsAccessKey = 'AKIAIOSFOLKFSSAMPLES'\n",
    "lakefsSecretKey = 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f01e2d-b8a5-4820-bed0-efa56d784b80",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Storage Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce9539c-ca43-466c-a820-ee8f3f6fa312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storageNamespace = 's3://example' # e.g. \"s3://bucket\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9f0c9-e77f-4d4f-a5d5-4b3fcff9bf65",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b052ac3-055a-4b05-8f6a-cc39747ae5d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup\n",
    "\n",
    "**(you shouldn't need to change anything in this section, just run it)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d51253-2d89-4dc0-9879-1104a5228b60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_name = \"kafka-stream-demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c8b88-3a7c-404d-949a-6a7f5f6932a8",
   "metadata": {},
   "source": [
    "## Versioning Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe89d96-c849-4280-9521-43b91630844e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sourceBranch = \"main\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04178b27-8501-40e0-a7dc-755d522c9533",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e411dd50-c513-4576-91a9-d3958ec29b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import lakefs\n",
    "import datetime\n",
    "from assets.lakefs_demo import print_commit, print_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076ebdf7-f823-4ebc-b1c5-37541c013458",
   "metadata": {},
   "source": [
    "### Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed4dc2-8592-4981-9ae3-eeca5002b94c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"LAKECTL_SERVER_ENDPOINT_URL\"] = lakefsEndPoint\n",
    "os.environ[\"LAKECTL_CREDENTIALS_ACCESS_KEY_ID\"] = lakefsAccessKey\n",
    "os.environ[\"LAKECTL_CREDENTIALS_SECRET_ACCESS_KEY\"] = lakefsSecretKey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d1ff89-480c-4421-8ed5-1b2e33a1fda9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Verify lakeFS credentials by getting lakeFS version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde3e9b6-2da3-4ae2-968a-acf874867a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Verifying lakeFS credentials‚Ä¶\")\n",
    "try:\n",
    "    v=lakefs.client.Client().version\n",
    "except:\n",
    "    print(\"üõë failed to get lakeFS version\")\n",
    "else:\n",
    "    print(f\"‚Ä¶‚úÖlakeFS credentials verified\\n\\n‚ÑπÔ∏èlakeFS version {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a2ebb0-b842-4584-8776-ef89976feb9a",
   "metadata": {},
   "source": [
    "### Define lakeFS Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf73bf83-546b-4cc0-a920-cfcb16d87a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo = lakefs.Repository(repo_name).create(storage_namespace=f\"{storageNamespace}/{repo_name}\", default_branch=sourceBranch, exist_ok=True)\n",
    "branchMain = repo.branch(sourceBranch)\n",
    "print(repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7403de6-88df-4aed-a8eb-61e6d5899859",
   "metadata": {},
   "source": [
    "### Set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098faed5-149a-4c4d-a52a-3c8e3f98c36b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Kafka / Jupyter\") \\\n",
    "        .config(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", lakefsEndPoint) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", lakefsAccessKey) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", lakefsSecretKey) \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde7fed8-6435-4737-a520-40c4c3820e29",
   "metadata": {},
   "source": [
    "### Initialize a new Kafka producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e8360-0da4-429d-af47-2e2a78d2d56d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "from time import sleep\n",
    "producer = KafkaProducer(bootstrap_servers=['lakefs-broker:29092'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae4b709-7631-4fec-b75b-0fc4a4c417f9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a226c33f-5a90-4b19-a037-56966130aa6c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a827676-a2bc-48f2-9f4b-c4b2d4ba8ff3",
   "metadata": {},
   "source": [
    "# Main demo starts here üö¶ üëáüèª"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b1b885-c55c-4044-90e7-6a0ca373f8dc",
   "metadata": {},
   "source": [
    "# Ingest Streaming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783c74c8-1888-442b-a2cf-4210a93ffe60",
   "metadata": {},
   "source": [
    "### Create a dirty branch for streaming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c10801-bb14-4e5e-902d-7bfb49d090d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "streaming_branch = \"streaming\" + datetime.datetime.now().strftime(\"_%Y%m%dT%H%M%S\")\n",
    "branchStreaming = repo.branch(streaming_branch).create(source_reference=sourceBranch)\n",
    "print(f\"Created {streaming_branch} branch from main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffdab57-1c89-4860-9df7-7b0c9225e9e4",
   "metadata": {},
   "source": [
    "### Configure Kafka S3 Sink Connector to sink data to streaming branch in lakeFS repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5afcc9-bf51-4414-ad11-92a2bab8e7d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "command = 'curl -s -X PUT -H  \"Content-Type:application/json\" http://connect:8083/connectors/test_connector/config \\\n",
    "    -d \\'{ \\\n",
    "    \"connector.class\": \"io.confluent.connect.s3.S3SinkConnector\", \\\n",
    "    \"tasks.max\": \"1\", \\\n",
    "    \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\", \\\n",
    "    \"value.converter\": \"org.apache.kafka.connect.storage.StringConverter\", \\\n",
    "    \"topics\": \"quickstart\", \\\n",
    "    \"topics.dir\": \"' + streaming_branch + '/ingest\", \\\n",
    "    \"format.class\": \"io.confluent.connect.s3.format.json.JsonFormat\", \\\n",
    "    \"flush.size\": \"100\", \\\n",
    "    \"schema.compatibility\": \"NONE\", \\\n",
    "    \"s3.bucket.name\": \"' + repo_name + '\", \\\n",
    "    \"s3.region\": \"us-east-1\", \\\n",
    "    \"storage.class\": \"io.confluent.connect.s3.storage.S3Storage\", \\\n",
    "    \"store.url\": \"' + lakefsEndPoint + '\", \\\n",
    "    \"aws.access.key.id\": \"' + lakefsAccessKey + '\", \\\n",
    "    \"aws.secret.access.key\": \"' + lakefsSecretKey + '\", \\\n",
    "    \"partitioner.class\": \"io.confluent.connect.storage.partitioner.DefaultPartitioner\" \\\n",
    "    }\\''\n",
    "\n",
    "! $command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afc0a13-d798-4b77-8b39-4e572361e0be",
   "metadata": {},
   "source": [
    "### Produce some streaming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c2e69-cf2e-4bdb-8d68-3a252fc59382",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for e in range(100):\n",
    "    producer.send('quickstart', bytes(f\"message-{e}\", 'utf-8'))\n",
    "\n",
    "sleep(3)\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b0f0c1-e3c8-4300-b9cd-29340dae2101",
   "metadata": {},
   "source": [
    "### Read streaming data sinked to lakeFS repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a83ce7-94fd-4f54-a310-309ff81a3184",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataPath = f\"s3a://{repo_name}/{streaming_branch}/ingest/quickstart/partition=0/\"\n",
    "print(f\"Reading ingested data from {dataPath}\")\n",
    "df = spark.read.csv(dataPath).withColumnRenamed(\"_c0\",\"data\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda34365-f4dc-4cda-9a8b-54b1539e7137",
   "metadata": {},
   "source": [
    "### Create a ingestion branch to process and load streaming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdb474c-d4a2-457d-8519-8fc97f25d690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingest_time = datetime.datetime.now().strftime(\"_%Y%m%dT%H%M%S\")\n",
    "ingest_branch = \"ingest\" + ingest_time\n",
    "\n",
    "branchIngest = repo.branch(ingest_branch).create(source_reference=sourceBranch)\n",
    "print(f\"Created {ingest_branch} branch from main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61adbb0d-10f2-4de5-a2f0-9b183f75e672",
   "metadata": {},
   "source": [
    "### Append streaming data to ingestion branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320dbb9c-777f-4615-b261-ea1290a1ea48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.write.csv(f\"s3a://{repo.id}/{ingest_branch}/stream/quickstart{ingest_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f1ab2e-ad6c-48a1-a213-bf0951e337bc",
   "metadata": {},
   "source": [
    "### Commit streaming data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8712401-9087-477d-a7b3-7067435ebac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = branchIngest.commit(message='Streaming data load',\n",
    "                       metadata={'author': 'demo user',\n",
    "                                 'data source': 'Kafka',\n",
    "                                 'Kafka topic': 'quickstart'})\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f2b42a-c1d5-4042-a339-39cd194d3a00",
   "metadata": {},
   "source": [
    "### Merge ingestion branch to main branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b10582f-07aa-4f0c-8c9a-f718fb084e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = branchIngest.merge_into(branchMain)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea713c-8489-43e0-9968-9f4fd16e2d49",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380d2d46-d9f8-4880-a924-aaeb7312ed42",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a77a15-7f39-4707-a364-99451c6fe0f6",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
