{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c053f0c-88da-4972-bdbe-686a37af7325",
   "metadata": {},
   "source": [
    "<img src=\"./images/logo.svg\" alt=\"lakeFS logo\" width=300/> \n",
    "\n",
    "# Integration of lakeFS with Spark and Python\n",
    "\n",
    "Use Case: Isolated Testing Environment\n",
    "\n",
    "Access lakeFS using the S3A gateway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea8ed1f-74f0-40fe-aa8f-f4548a108c28",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4b5229-ed90-4ff0-893b-dcfdddec161f",
   "metadata": {},
   "source": [
    "### lakeFS endpoint and credentials\n",
    "\n",
    "Change these if using lakeFS other than provided in the samples repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dcc05f-238c-4e30-b585-47fb5b2bd25f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefsEndPoint = 'http://lakefs:8000' # e.g. 'https://username.aws_region_name.lakefscloud.io' \n",
    "lakefsAccessKey = 'AKIAIOSFOLKFSSAMPLES'\n",
    "lakefsSecretKey = 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c151e3-c469-4258-a7e3-9d25c00a9cc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Storage Information\n",
    "\n",
    "If you're not using sample repo lakeFS, then change the Storage Namespace to a location in the bucket you‚Äôve configured. The storage namespace is a location in the underlying storage where data for this repository will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad15e82e-f176-4aaf-8520-a366d8c52a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storageNamespace = 's3://example/' # e.g. \"s3://bucket\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e61a4-052c-4992-92c4-103fd68552ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "**(you shouldn't need to change anything in this section, just run it)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213e05b-03d4-4065-b92d-b189eec16206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_name = \"spark-demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e898140-531c-45ce-964b-47bbc56718f2",
   "metadata": {},
   "source": [
    "## Versioning Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4472c870-8034-47da-9f7a-7b814b77f63e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sourceBranch = \"main\"\n",
    "newBranch = \"experiment01\"\n",
    "newPath = \"partitioned_data\"\n",
    "fileName = \"userdata/userdata1.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f18f02c-03fd-4781-a274-760627fe9c27",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c74d0-5c09-4a27-af1d-a37b1981eada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import lakefs\n",
    "from assets.lakefs_demo import print_commit, print_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71578731-133a-4af8-a6d7-db1f29f12de3",
   "metadata": {},
   "source": [
    "### Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209195d6-7335-4c8f-8ea1-e1cad09e4310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"LAKECTL_SERVER_ENDPOINT_URL\"] = lakefsEndPoint\n",
    "os.environ[\"LAKECTL_CREDENTIALS_ACCESS_KEY_ID\"] = lakefsAccessKey\n",
    "os.environ[\"LAKECTL_CREDENTIALS_SECRET_ACCESS_KEY\"] = lakefsSecretKey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cd1b6e-e080-425f-a99b-d85212ae0a44",
   "metadata": {},
   "source": [
    "### Verify lakeFS credentials by getting lakeFS version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7e745c-a001-4ef9-aab3-53639174e5e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Verifying lakeFS credentials‚Ä¶\")\n",
    "try:\n",
    "    v=lakefs.client.Client().version\n",
    "except:\n",
    "    print(\"üõë failed to get lakeFS version\")\n",
    "else:\n",
    "    print(f\"‚Ä¶‚úÖlakeFS credentials verified\\n\\n‚ÑπÔ∏èlakeFS version {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07041af8-fae2-4064-94c5-afc758695903",
   "metadata": {},
   "source": [
    "### Define lakeFS Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4cf7b6-b01b-4d79-bca1-4d30bd3ba7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo = lakefs.Repository(repo_name).create(storage_namespace=f\"{storageNamespace}/{repo_name}\", default_branch=sourceBranch, exist_ok=True)\n",
    "branchMain = repo.branch(sourceBranch)\n",
    "print(repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dcd743-1cad-4a01-9c28-6adfda24bbb4",
   "metadata": {},
   "source": [
    "### Start Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ca013-2915-4d0d-b625-4e87b9ff3586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"lakeFS / Jupyter\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051af1c6-be68-416b-888d-b88766a5d966",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8763aa4-a4d4-4df5-a241-e7b1fd11d54a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = branchMain.object(path=fileName)\n",
    "\n",
    "with open(f\"./data/{fileName}\", mode='rb') as reader, obj.writer(mode='wb', metadata={'using': 'python_wrapper', 'source':'Spark Demo'}) as writer:\n",
    "    writer.write(reader.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f11730f",
   "metadata": {},
   "source": [
    "## Commit changes and attach some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc6db1-11cb-41f6-93fc-432e6cc97386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = branchMain.commit(message='Added my first file!', metadata={'using': 'python_sdk'})\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e234b50",
   "metadata": {},
   "source": [
    "## Reading data by using lakeFS File System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f7c95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataPath = f\"lakefs://{repo_name}/{sourceBranch}/{fileName}\"\n",
    "print(f\"Reading Parquet file from {dataPath}\")\n",
    "df = spark.read.parquet(dataPath)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29fc32",
   "metadata": {},
   "source": [
    "# Experimentation Starts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6485c9b",
   "metadata": {},
   "source": [
    "## List the repository branches by using lakeFS Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8661d78-37c6-47e9-b236-8dbb3e573ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for branch in repo.branches():\n",
    "    print(branch.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d72d92",
   "metadata": {},
   "source": [
    "## Create a new branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decfcb86-60ab-41f2-aaf0-53c9fbb7243c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "branchNew = repo.branch(newBranch).create(source_reference=sourceBranch)\n",
    "print(f\"{newBranch} ref:\", branchNew.get_commit().id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8c7c0",
   "metadata": {},
   "source": [
    "## Partition the data and write to new branch by using lakeFS File System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8117b502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newDataPath = f\"lakefs://{repo_name}/{newBranch}/{newPath}\"\n",
    "\n",
    "df.write.partitionBy(\"gender\").parquet(newDataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f0d636",
   "metadata": {},
   "source": [
    "## Commit changes and attach some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e7177-e601-4c0c-94ba-bc4ff2622970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = branchNew.commit(message='Partitioned Parquet file!', metadata={'using': 'python_sdk'})\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f5e995",
   "metadata": {},
   "source": [
    "## Diff between the new branch and the source branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a88bd-39f9-4c84-be9d-ffcf2135233d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff = branchMain.diff(other_ref=branchNew)\n",
    "print_diff(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4749992",
   "metadata": {},
   "source": [
    "# Experimentation Completes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63704bc3",
   "metadata": {},
   "source": [
    "## Option A: Experimentation succeeds, so merge new branch to the main branch (atomic promotion to production)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a5f10-3d9d-4e09-a618-eb54bc6cc592",
   "metadata": {},
   "source": [
    "### Do the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f50ff44-26bc-404e-a59f-3c29f7f6ef57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = branchNew.merge_into(branchMain)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38f0594-731f-4dbc-98ee-a81bf8c22edf",
   "metadata": {},
   "source": [
    "### If you merged new branch to the main branch then you can atomically rollback all changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a260fc7-e8f2-43ad-a8e3-96c68f2c5727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "branchMain.revert(parent_number=1, reference=sourceBranch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc41eddd-5e09-404c-bd2b-70a62080a141",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Option B: Experimentation fails, so just delete the new branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6f3460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment if you want to run this\n",
    "\n",
    "#branchNew.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873b7142",
   "metadata": {},
   "source": [
    "## More Questions?\n",
    "\n",
    "###### Join the lakeFS Slack group - https://lakefs.io/slack"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
