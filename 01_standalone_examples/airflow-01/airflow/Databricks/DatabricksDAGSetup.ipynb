{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b2c8fa0-1702-411a-b11c-3190679bf31c",
   "metadata": {},
   "source": [
    "# [Integration of lakeFS with Airflow and Databricks](https://docs.lakefs.io/integrations/airflow.html)\n",
    "\n",
    "## Use Case: Isolating Databricks job run and atomic promotion to production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70590647-bf34-4056-bb6e-895ebd3ed167",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"airflow-databricks-dag-repo\"\n",
    "sourceBranch = \"main\"\n",
    "newBranch = \"airflow_demo_databricks_dag\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a129e87-56c4-401f-9b4b-cc4e7587cf1e",
   "metadata": {},
   "source": [
    "## Run [Common Setup](../Common/CommonSetup.ipynb) tasks here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfe84c-fce2-4be0-8314-073c6b9aa1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./airflow/Common/CommonSetup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7fbb8f-38a7-414e-ac9a-35d18b6ffdd7",
   "metadata": {},
   "source": [
    "## Create Airflow connections for Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd43a31-6273-44d0-980a-c94a4d3377ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "! airflow connections delete conn_databricks\n",
    "databricksConnectionCommand = 'airflow connections add conn_databricks --conn-type=databricks --conn-host=' + databricksHost + ' --conn-password=' + databricksAccessToken\n",
    "! $databricksConnectionCommand > ./airflow/airflow-connection.txt\n",
    "with open(\"./airflow/airflow-connection.txt\", \"r\") as file:\n",
    "    last_line = file.readlines()[-1]\n",
    "print(last_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c26dcb-aa01-4dbd-99d0-388aeed0577b",
   "metadata": {},
   "source": [
    "## Set Airflow variables which are used by the demo DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c575b397-a3f0-4119-a8d0-9aaf0add41ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "! airflow variables set databricksNotebookPath $databricksNotebookPath\n",
    "! airflow variables set databricksClusterName $databricksClusterName\n",
    "! airflow variables set databricksSparkVersion $databricksSparkVersion\n",
    "! airflow variables set databricksNodeType $databricksNodeType\n",
    "! airflow variables set databricksNumberOfWorkers $databricksNumberOfWorkers\n",
    "! airflow variables set databricksJobName $databricksJobName\n",
    "! airflow variables set databricksTaskName $databricksTaskName\n",
    "! airflow variables set conn_databricks 'conn_databricks'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b6792e-b1be-4c26-90cd-e9d54924354f",
   "metadata": {},
   "source": [
    "## Copy DAG programs to Airflow DAGs directory and sync to Airflow database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f31409a-f75c-4b2d-97ad-f82eb18dd776",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp ./airflow/Databricks/lakefs_databricks_dag.py ./airflow/dags\n",
    "\n",
    "dagbag = DagBag(include_examples=False)\n",
    "dagbag.sync_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65363636-fb29-4733-a7c8-7372d4c81042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
