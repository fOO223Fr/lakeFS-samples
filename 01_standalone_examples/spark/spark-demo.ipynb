{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c053f0c-88da-4972-bdbe-686a37af7325",
   "metadata": {},
   "source": [
    "<img src=\"./images/logo.png\" alt=\"lakeFS logo\" width=300/> \n",
    "\n",
    "# Integration of lakeFS with Spark and Python\n",
    "\n",
    "Use Case: Isolated Testing Environment\n",
    "\n",
    "Access lakeFS using the S3A gateway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea8ed1f-74f0-40fe-aa8f-f4548a108c28",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4b5229-ed90-4ff0-893b-dcfdddec161f",
   "metadata": {},
   "source": [
    "### lakeFS endpoint and credentials\n",
    "\n",
    "Change these if using lakeFS other than provided in the samples repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1b96f-a734-4cf4-953e-97c2e4315e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefsEndPoint = 'http://lakefs:8000' # e.g. 'https://username.aws_region_name.lakefscloud.io' \n",
    "lakefsAccessKey = 'AKIAIOSFOLKFSSAMPLES'\n",
    "lakefsSecretKey = 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c151e3-c469-4258-a7e3-9d25c00a9cc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Storage Information\n",
    "\n",
    "If you're not using sample repo lakeFS, then change the Storage Namespace to a location in the bucket youâ€™ve configured. The storage namespace is a location in the underlying storage where data for this repository will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c64b30-4e57-40bd-aa76-fdaf6000f7c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storageNamespace = 's3://example' # e.g. \"s3://bucket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213e05b-03d4-4065-b92d-b189eec16206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_name = \"spark-demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e61a4-052c-4992-92c4-103fd68552ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71578731-133a-4af8-a6d7-db1f29f12de3",
   "metadata": {},
   "source": [
    "## Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209195d6-7335-4c8f-8ea1-e1cad09e4310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LAKECTL_SERVER_ENDPOINT_URL\"] = lakefsEndPoint\n",
    "os.environ[\"LAKECTL_CREDENTIALS_ACCESS_KEY_ID\"] = lakefsAccessKey\n",
    "os.environ[\"LAKECTL_CREDENTIALS_SECRET_ACCESS_KEY\"] = lakefsSecretKey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07041af8-fae2-4064-94c5-afc758695903",
   "metadata": {},
   "source": [
    "### Define lakeFS Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e56a66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lakefs\n",
    "\n",
    "try:\n",
    "    repo=lakefs.repository(repo_name)\n",
    "    print(f\"Found existing repo {repo.id} using storage namespace {repo.properties.storage_namespace}\")\n",
    "except lakefs.exceptions.NotFoundException as f:\n",
    "    print(f\"Repository {repo_name} does not exist, so going to try and create it now.\")\n",
    "    try:\n",
    "        repo=lakefs.repository(repo_name).create(storage_namespace=f\"{storageNamespace}/{repo_name}\")\n",
    "        print(f\"Created new repo {repo.id} using storage namespace {repo.properties.storage_namespace}\")\n",
    "    except lakefs.exceptions.LakeFSException as e:\n",
    "        print(f\"Error creating repo {repo_name}. Error is {e}\")\n",
    "except lakefs.exceptions.LakeFSException as e:\n",
    "    print(f\"Error getting repo {repo_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dcd743-1cad-4a01-9c28-6adfda24bbb4",
   "metadata": {},
   "source": [
    "### Set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8125e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"lakeFS / Jupyter\") \\\n",
    "        .config(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", lakefsEndPoint) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", lakefsAccessKey) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", lakefsSecretKey) \\\n",
    "        .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c663f-8c94-4cd9-a49f-6ab5a8cb80db",
   "metadata": {},
   "source": [
    "## Versioning Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fdcc13-19bc-4aee-a833-9d645d2d7b38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sourceBranch = \"main\"\n",
    "newBranch = \"experiment01\"\n",
    "newPath = \"partitioned_data\"\n",
    "fileName = \"userdata/userdata1.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051af1c6-be68-416b-888d-b88766a5d966",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8763aa4-a4d4-4df5-a241-e7b1fd11d54a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main = repo.branch(sourceBranch)\n",
    "obj = main.object(path=fileName)\n",
    "\n",
    "with open(f\"/data/{fileName}\", mode='rb') as reader, obj.writer(mode='wb', metadata={'using': 'python_wrapper', 'source':'Spark Demo'}) as writer:\n",
    "    writer.write(reader.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f11730f",
   "metadata": {},
   "source": [
    "## Commit changes and attach some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc6db1-11cb-41f6-93fc-432e6cc97386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = main.commit(message='Added my first file!', metadata={'using': 'python_sdk'})\n",
    "print(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e234b50",
   "metadata": {},
   "source": [
    "## Reading data by using S3A Gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f7c95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataPath = f\"s3a://{repo.id}/{sourceBranch}/{fileName}\"\n",
    "print(f\"Reading Parquet file from {dataPath}\")\n",
    "df = spark.read.parquet(dataPath)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29fc32",
   "metadata": {},
   "source": [
    "# Experimentation Starts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6485c9b",
   "metadata": {},
   "source": [
    "## List the repository branches by using lakeFS Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8661d78-37c6-47e9-b236-8dbb3e573ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for branch in repo.branches():\n",
    "    print(branch.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d72d92",
   "metadata": {},
   "source": [
    "## Create a new branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decfcb86-60ab-41f2-aaf0-53c9fbb7243c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "branch1 = repo.branch(newBranch).create(source_reference=sourceBranch)\n",
    "print(f\"{newBranch} ref:\", branch1.get_commit().id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8c7c0",
   "metadata": {},
   "source": [
    "## Partition the data and write to new branch by using S3A Gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8117b502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newDataPath = f\"s3a://{repo.id}/{newBranch}/{newPath}\"\n",
    "\n",
    "df.write.partitionBy(\"gender\").parquet(newDataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f0d636",
   "metadata": {},
   "source": [
    "## Commit changes and attach some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e7177-e601-4c0c-94ba-bc4ff2622970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = branch1.commit(message='Partitioned Parquet file!', metadata={'using': 'python_sdk'})\n",
    "print(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f5e995",
   "metadata": {},
   "source": [
    "## Diff between the new branch and the source branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1ec55-fbab-4699-b773-ecc545c999d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for diff in main.diff(other_ref=branch1):\n",
    "    print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4749992",
   "metadata": {},
   "source": [
    "# Experimentation Completes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63704bc3",
   "metadata": {},
   "source": [
    "## Option A: Experimentation succeeds, so merge new branch to the main branch (atomic promotion to production)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a5f10-3d9d-4e09-a618-eb54bc6cc592",
   "metadata": {},
   "source": [
    "### Do the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f50ff44-26bc-404e-a59f-3c29f7f6ef57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = branch1.merge_into(main)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38f0594-731f-4dbc-98ee-a81bf8c22edf",
   "metadata": {},
   "source": [
    "### If you merged new branch to the main branch then you can atomically rollback all changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a260fc7-e8f2-43ad-a8e3-96c68f2c5727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main.revert(parent_number=1, reference_id=sourceBranch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc41eddd-5e09-404c-bd2b-70a62080a141",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Option B: Experimentation fails, so just delete the new branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6f3460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment if you want to run this\n",
    "\n",
    "#branch1.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873b7142",
   "metadata": {},
   "source": [
    "## More Questions?\n",
    "\n",
    "###### Join the lakeFS Slack group - https://lakefs.io/slack"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
