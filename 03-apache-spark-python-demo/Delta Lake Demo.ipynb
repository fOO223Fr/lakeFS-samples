{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbbe0a71-a38c-47d6-a5d6-fad33198407c",
   "metadata": {},
   "source": [
    "# [Integration of lakeFS with Delta Lake](https://docs.lakefs.io/integrations/delta.html)\n",
    "\n",
    "## Use Case: Isolated Testing Environment & Rollback of multi-table transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3ae1eb-2aa7-4ce8-bed2-272b7b089d3c",
   "metadata": {},
   "source": [
    "## Change your lakeFS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bd1515-f772-46be-851f-ab11a15bb60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakefsAccessKey = '<lakeFS Access Key>'\n",
    "lakefsSecretKey = '<lakeFS Secret Key>'\n",
    "lakefsEndPoint = '<lakeFS Endpoint URL>' # e.g. 'https://username.aws_region_name.lakefscloud.io'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d3581f-91cf-407a-8bdf-831986839f2e",
   "metadata": {},
   "source": [
    "## Storage Information\n",
    "#### Change the Storage Namespace to a location in the bucket youâ€™ve configured. The storage namespace is a location in the underlying storage where data for this repository will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae1382-c5ca-464a-8519-5efacf7a8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageNamespace = 's3://<S3 Bucket Name>/' # e.g. \"s3://username-lakefs-cloud/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843fd92b-bb0b-462c-b1c7-0eea5e403396",
   "metadata": {},
   "source": [
    "## Versioning Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e4076-0019-4c67-bb35-e08aa3467e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceBranch = \"main\"\n",
    "newBranch = \"experiment2\"\n",
    "DeltaTable1 = \"delta-table1\"\n",
    "DeltaTable2 = \"delta-table2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd625eea-e738-495f-9f9e-ec268bcd385f",
   "metadata": {},
   "source": [
    "## Working with the lakeFS Python client API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0bf33b-7778-43e6-bc05-4731b60e2e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lakefs_client\n",
    "from lakefs_client import models\n",
    "from lakefs_client.client import LakeFSClient\n",
    "\n",
    "# lakeFS credentials and endpoint\n",
    "configuration = lakefs_client.Configuration()\n",
    "configuration.username = lakefsAccessKey\n",
    "configuration.password = lakefsSecretKey\n",
    "configuration.host = lakefsEndPoint\n",
    "\n",
    "client = LakeFSClient(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df89e83f-73f2-404b-a5ce-f0bb707b7733",
   "metadata": {},
   "source": [
    "## You can change lakeFS repo name (it can be an existing repo or provide another repo name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce13c51-c91b-4c05-894e-5a1392b969f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"my-repo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88db614-4f3a-4afa-95b6-e14ff8b6a006",
   "metadata": {},
   "source": [
    "## If above mentioned repo already exists on your lakeFS server then you can skip following step otherwise create a new repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7bea54-1e7d-4781-820b-2b983d5598a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.repositories.create_repository(repository_creation=models.RepositoryCreation(name=repo, storage_namespace=storageNamespace, default_branch=sourceBranch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab5945a-1dd0-49c0-a94b-072aca3a5322",
   "metadata": {},
   "source": [
    "## Run PySpark with the Delta Lake package and additional configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd7ca93-67ed-4bc6-aa29-b99e7e96f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages io.delta:delta-core_2.12:2.0.0 --conf \"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension\" --conf \"spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\" pyspark-shell'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71978610-68ce-41a8-be02-03580f9520b6",
   "metadata": {},
   "source": [
    "## S3A Gateway configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc7f06d-9542-45aa-a484-2c48296566b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", lakefsAccessKey)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", lakefsSecretKey)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", lakefsEndPoint)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1577257-81b2-4971-bafb-5aabfd1e603e",
   "metadata": {},
   "source": [
    "## Create a Delta Table in source branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7229f90d-accb-4f8f-9713-50cd7c8044b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath1 = \"s3a://{0}/{1}/{2}\".format(repo,sourceBranch,DeltaTable1)\n",
    "data = spark.range(0, 5)\n",
    "data.write.format(\"delta\").mode(\"overwrite\").save(dataPath1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e404d3-982f-48d3-a96c-b8bf566dab68",
   "metadata": {},
   "source": [
    "## Create another Delta Table in source branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69782fc9-572b-45ef-a58b-813b4b99b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath2 = \"s3a://{0}/{1}/{2}\".format(repo,sourceBranch,DeltaTable2)\n",
    "data = spark.range(10, 20)\n",
    "data.write.format(\"delta\").mode(\"overwrite\").save(dataPath2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c255b4-c89e-4feb-9dc7-669a46cb2239",
   "metadata": {},
   "source": [
    "## Read from Delta Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06127c71-d5c4-4d55-9579-df903e7c2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").load(dataPath1)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264fddd6-9d48-4c71-aa8e-d1a9c87e2c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").load(dataPath2)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b763c2a9-561c-447c-ae2b-0b8fa13fedb0",
   "metadata": {},
   "source": [
    "## Commit changes and attach some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87a83ee-8547-4ed0-81a6-637f6f01838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.commits.commit(\n",
    "    repository=repo,\n",
    "    branch=sourceBranch,\n",
    "    commit_creation=models.CommitCreation(message='Added delta tables!', metadata={'using': 'python_api'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec287f-b340-43be-983f-fad43b024ac5",
   "metadata": {},
   "source": [
    "# Experimentation Starts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e75ca-12c6-4aa9-81f2-e7e3e092a56b",
   "metadata": {},
   "source": [
    "## List the repository branches by using lakeFS Python client API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e3c2b-ab39-4217-b248-8dbafb25a5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.branches.list_branches(repository=repo).results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa6a1a9-70c2-4416-b860-97aa1c2a6dfa",
   "metadata": {},
   "source": [
    "## Create a new branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7daab4-0479-4635-9d8b-9985298a9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.branches.create_branch(repository=repo, branch_creation=models.BranchCreation(name=newBranch, source=sourceBranch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2c7463-b3dd-43da-894b-25dbe92f8af6",
   "metadata": {},
   "source": [
    "## Update 1st Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47574719-a451-4a8e-b734-80fe060e2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "dataPath1 = \"s3a://{0}/{1}/{2}\".format(repo,newBranch,DeltaTable1)\n",
    "deltaTable = DeltaTable.forPath(spark, dataPath1)\n",
    "\n",
    "# Update every even value by adding 100 to it\n",
    "deltaTable.update(\n",
    "  condition = expr(\"id % 2 == 0\"),\n",
    "  set = { \"id\": expr(\"id + 100\") })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc680560-d204-419d-b58b-5d72cac971a9",
   "metadata": {},
   "source": [
    "## Read from updated Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc3a722-c3c7-428e-9ff5-fc8fdee258bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").load(dataPath1)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d222dae-fa08-4dec-8905-9d21c4545b08",
   "metadata": {},
   "source": [
    "## Update 2nd Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cf02e0-610e-4b7b-aa7e-ed89692f97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath2 = \"s3a://{0}/{1}/{2}\".format(repo,newBranch,DeltaTable2)\n",
    "deltaTable = DeltaTable.forPath(spark, dataPath2)\n",
    "\n",
    "# Update every odd value by adding 200 to it\n",
    "deltaTable.update(\n",
    "  condition = expr(\"id % 2 == 1\"),\n",
    "  set = { \"id\": expr(\"id + 200\") })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22710614-fda1-415b-a451-ec517d98ba3f",
   "metadata": {},
   "source": [
    "## Read from updated Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62282d9-35e4-4c48-b743-2f5076d46ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").load(dataPath2)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af4ccfe-823a-4f8c-9a6b-3f2bf520787c",
   "metadata": {},
   "source": [
    "## Commit changes and attach some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d0eef2-e7fd-4c4f-a8db-d5cb5f12fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.commits.commit(\n",
    "    repository=repo,\n",
    "    branch=newBranch,\n",
    "    commit_creation=models.CommitCreation(message='Updated multiple Delta Tables', metadata={'using': 'python_api'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20e4afb-88c7-4a08-9ce8-c991be6f632d",
   "metadata": {},
   "source": [
    "## Diff between the new branch and the source branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cb83e9-7ec3-43cd-810f-e7f17a428df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.refs.diff_refs(repository=repo, left_ref=sourceBranch, right_ref=newBranch).results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2d0f89-44c8-47bb-bcd9-39be49216b63",
   "metadata": {},
   "source": [
    "# Experimentation Completes\n",
    "\n",
    "## Delete new branch or merge new branch to source branch\n",
    "\n",
    "## Delete new branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23445ec-65a1-4d32-ad2b-9a486f89d752",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.branches.delete_branch(repository=repo, branch=newBranch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a28f7a-bd23-4bfc-b3e7-12c35691f942",
   "metadata": {},
   "source": [
    "## Or merge new branch to source branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cba1bc-0e02-4131-b7b7-6ccda7b442ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.refs.merge_into_branch(repository=repo, source_ref=newBranch, destination_branch=sourceBranch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc0f5c7-4eaf-4797-995d-e823e36e2654",
   "metadata": {},
   "source": [
    "## Read Delta Tables from source branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f021073a-3602-47f6-b538-022902dbbb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath1 = \"s3a://{0}/{1}/{2}\".format(repo,sourceBranch,DeltaTable1)\n",
    "df = spark.read.format(\"delta\").load(dataPath1)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b11191-ea4b-4ad5-97b9-0b5693812583",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath2 = \"s3a://{0}/{1}/{2}\".format(repo,sourceBranch,DeltaTable2)\n",
    "df = spark.read.format(\"delta\").load(dataPath2)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60260a17-0d22-4b33-a9fe-2bc8d4d0f6c1",
   "metadata": {},
   "source": [
    "## If you merged new branch to source branch then you can revert committed changes for all Delta Tables from the source branch\n",
    "\n",
    "### Go to lakeFS UI and get the commit ID or copy the 'reference' from the previous merge statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b46c2-66ca-411c-930b-1f7b513043a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "commit_id = \"<lakeFS Commit Id>\"\n",
    "client.branches.revert_branch(repository=repo, branch=sourceBranch, revert_creation=models.RevertCreation(ref=commit_id, parent_number=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a889314f-3e63-4a83-bb8e-af5f5f038129",
   "metadata": {},
   "source": [
    "## Read Delta Tables again from source branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e58e3b-d036-4ec9-9f5a-9058379e03ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath1 = \"s3a://{0}/{1}/{2}\".format(repo,sourceBranch,DeltaTable1)\n",
    "df = spark.read.format(\"delta\").load(dataPath1)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5919e4-360c-4c48-8d29-8929640f4d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath2 = \"s3a://{0}/{1}/{2}\".format(repo,sourceBranch,DeltaTable2)\n",
    "df = spark.read.format(\"delta\").load(dataPath2)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d454c2f-e001-4113-bfa9-c1ad6c8afe18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
