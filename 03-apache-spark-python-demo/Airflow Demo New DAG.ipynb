{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1674ec1-9227-4159-a9bc-5000b31f6e12",
   "metadata": {},
   "source": [
    "# [Integration of lakeFS with Airflow](https://docs.lakefs.io/integrations/airflow.html)\n",
    "\n",
    "## Use Case: Troubleshooting production issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b8005e-1ce3-496b-9725-3a131c6da97a",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "###### This Notebook requires connecting to a lakeFS Server.\n",
    "###### To spin up lakeFS quickly - use the Playground (https://demo.lakefs.io) which provides lakeFS server on-demand with a single click;\n",
    "###### Or, alternatively, refer to lakeFS Quickstart doc (https://docs.lakefs.io/quickstart/installing.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ddc884-bdf5-4fc5-97b1-38662358268c",
   "metadata": {},
   "source": [
    "## Setup Task: Change your lakeFS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a905b0-ab02-426d-8049-7138de6efc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakefsEndPoint = '<lakeFS Endpoint URL>' # e.g. 'https://username.aws_region_name.lakefscloud.io'\n",
    "lakefsAccessKey = '<lakeFS Access Key>'\n",
    "lakefsSecretKey = '<lakeFS Secret Key>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b5ae63-dc9b-43b3-a883-0a3865ad5dc6",
   "metadata": {},
   "source": [
    "## Setup Task: You can change lakeFS repo name (it can be an existing repo or provide another repo name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1f393-3346-440f-8083-99aeb6013443",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"new-dag-repo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f793f5-22f2-43f7-8e5f-f39149703314",
   "metadata": {},
   "source": [
    "## Setup Task: Versioning Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f3e3d3-df16-4899-a52e-4cbb2892e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceBranch = \"main\"\n",
    "newBranch = \"airflow_demo_new_dag\"\n",
    "newPath = \"partitioned_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcdeffb-d15f-4d84-87ae-bd2af291758a",
   "metadata": {},
   "source": [
    "## Setup Task: Storage Information - Optional on Playground\n",
    "#### Change the Storage Namespace to a location in the bucket youâ€™ve configured. The storage namespace is a location in the underlying storage where data for this repository will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd6aef-59a5-4253-ab67-70582a579925",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageNamespace = 's3://<S3 Bucket Name>/' # e.g. \"s3://username-lakefs-cloud/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc69394-47d2-464e-b9ec-ebbd0383422b",
   "metadata": {},
   "source": [
    "## Setup Task: Run additional [Setup](./Airflow/New_DAG/Setup.ipynb) tasks here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43315a02-5e0d-4480-bd35-1dcb82e0e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./airflow/New_DAG/Setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4ac852-ac82-45bf-b49a-1323aa673f2d",
   "metadata": {},
   "source": [
    "## Create Repository - Optional on Playground or if repository exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc44f5c3-6648-4f6b-b639-7ac871734698",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.repositories.create_repository(\n",
    "    repository_creation=models.RepositoryCreation(\n",
    "        name=repo,\n",
    "        storage_namespace=storageNamespace,\n",
    "        default_branch=sourceBranch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba46998-3a3d-4b52-ba59-6ee5c1893634",
   "metadata": {},
   "source": [
    "## You can review [lakeFS New DAG](./airflow/dags/lakefs_new_dag.py) program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbc058c-494e-4bbe-811d-9b488abdf5fb",
   "metadata": {},
   "source": [
    "## Set the fileName Airflow variable. This file is used by the [lakeFS New DAG](./airflow/dags/lakefs_new_dag.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9e0f4-f3b4-4e4f-9a0e-44f1f9f30bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"lakefs_test.csv\"\n",
    "! airflow variables set fileName $fileName"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a6b5c-c3d4-4bbf-bfb3-89309f813b4f",
   "metadata": {},
   "source": [
    "## Find Airflow admin password and copy the password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b107bdca-5e26-41f3-b223-c9c0b7bb843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat ./airflow/standalone_admin_password.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bf42ac-9e4a-46a6-a615-16825da83598",
   "metadata": {},
   "source": [
    "## Visualize [lakeFS New DAG Graph](http://127.0.0.1:8080/dags/lakefs_new_dag/graph) in Airflow UI. Login by using username admin and password received in the previous command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b230ad3d-420b-491a-9129-51f99c5e95b2",
   "metadata": {},
   "source": [
    "## Trigger lakeFS New DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c89a0-d8e7-4689-80a4-9dee7aa0fac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! airflow dags unpause lakefs_new_dag\n",
    "! airflow dags trigger lakefs_new_dag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d0e77-8cb9-47fb-81b2-74c96fae10b9",
   "metadata": {},
   "source": [
    "## Visualize [lakeFS New DAG Graph](http://127.0.0.1:8080/dags/lakefs_new_dag/graph).\n",
    "### Toggle Auto Refresh switch in DAG Graph to see the continuous progress of the workflow.\n",
    "### Click on any task box, then click on Log button and search for \"lakeFS URL\" (this URL will take you to applicable branch/commit/data file)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a440b100-98a9-4ef2-b622-4e7bbd9d2862",
   "metadata": {},
   "source": [
    "## Once the lakeFS New DAG finishes in around 5 minutes, you can use the latest or new file. This file has bad data, and it will cause workflow to fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597d825b-f4e6-4527-b7ca-48079a0a4490",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"lakefs_test_latest_file.csv\"\n",
    "! airflow variables set fileName $fileName"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bae53d-16d2-4a6e-b05f-66e0854db56e",
   "metadata": {},
   "source": [
    "## Trigger demo workflow again by using the latest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecafe94-4c8c-483e-95ec-3e5d81cae5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "! airflow dags trigger lakefs_new_dag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101b97f-0fc9-4831-9fe3-834fca1f7c2a",
   "metadata": {},
   "source": [
    "## Visualize [lakeFS New DAG Graph](http://127.0.0.1:8080/dags/lakefs_new_dag/graph) for the new run with the latest file.\n",
    "\n",
    "### Task \"etl_task3\" will fail in this case. Click on \"etl_task3\" task box, then click on Log button and search for \"Exception\". You will notice following exception:\n",
    "### \"Partition column _c4 not found in schema struct<_c0:string,_c1:string,_c2:string,_c3:string>\"\n",
    "\n",
    "### This exception happens because column \"_c4\" (or 5th column) is missing in the latest file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2999fb1-afe0-46ec-8eab-e8252519d6a6",
   "metadata": {},
   "source": [
    "## More Questions?\n",
    "\n",
    "###### Join the lakeFS Slack group - https://lakefs.io/slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aa06b2-ee54-4a35-817d-31809754aa99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
