{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e0d51de",
   "metadata": {},
   "source": [
    "### Installing lakeFS python client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "960fb832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded all libraries\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import joblib\n",
    "import tempfile\n",
    "import pprint\n",
    "from io import BytesIO\n",
    "from datetime import date, time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "print(\"Loaded all libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82506a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1d4979",
   "metadata": {},
   "source": [
    "## ML utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d0ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_rand_images(images, labels):\n",
    "    plt.figure(1 , figsize = (19 , 10))\n",
    "    n = 0 \n",
    "    for i in range(9):\n",
    "        n += 1 \n",
    "        r = np.random.randint(0 , images.shape[0] , 1)\n",
    "        \n",
    "        plt.subplot(3 , 3 , n)\n",
    "        plt.subplots_adjust(hspace = 0.3 , wspace = 0.3)\n",
    "        plt.imshow(images[r[0]])\n",
    "        \n",
    "        plt.title('Dog breed : {}'.format(labels[r[0]]))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0338e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(images, labels=\"test\"):\n",
    "    plt.figure(1 , figsize = (19 , 10))\n",
    "    plt.subplot(3 , 3 , 1)\n",
    "    plt.subplots_adjust(hspace = 0.3 , wspace = 0.3)\n",
    "    plt.imshow(images)\n",
    "\n",
    "    plt.title('Dog breed : {}'.format(labels))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b58d2b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(img):\n",
    "    \n",
    "    #display_image(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_array = Image.fromarray(img, 'RGB')\n",
    "    resized_img = np.array(img_array.resize((227, 227)))\n",
    "    #display_image(resized_img)\n",
    "    #print(type(img), type(resized_img))\n",
    "    \n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "405ed5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_from_s3(bucket, key):\n",
    "    bucket = s3_resource.Bucket(bucket)\n",
    "    file_stream = BytesIO()\n",
    "    bucket.Object(key).download_fileobj(file_stream)\n",
    "    np_1d_array = np.frombuffer(file_stream.getbuffer(), dtype=\"uint8\")\n",
    "    img = cv2.imdecode(np_1d_array, cv2.IMREAD_COLOR).copy()\n",
    "    \n",
    "    return resize_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5905b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_list_from_s3(bucket, branch,  prefix, delimiter, n_cats):\n",
    "    list_resp = s3_client.list_objects_v2(Bucket=bucket, Prefix=f\"{branch}/{prefix}/\", Delimiter=delimiter)\n",
    "    #print(\"List_resp\", list_resp)\n",
    "    category_list = [ x['Prefix'] for x in list_resp['CommonPrefixes'][:n_cats]]\n",
    "    #print(len(category_list))\n",
    "    return category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c37fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_and_labels(bucket, category_list, n_images):\n",
    "\n",
    "    img_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for index, category in enumerate(category_list):\n",
    "        # breed = category.split(\"/\")[-2]\n",
    "        list_resp = s3_client.list_objects_v2(Bucket=bucket, Prefix=category)\n",
    "\n",
    "        for c in list_resp['Contents'][:n_images]:\n",
    "            key = c['Key']\n",
    "            img = get_img_from_s3(bucket, key)\n",
    "            label = index\n",
    "            \n",
    "            img_list.append(img)\n",
    "            labels_list.append(label)\n",
    "    \n",
    "    images = np.array(img_list)\n",
    "    labels = np.array(labels_list)\n",
    "\n",
    "    # print(\"Images shape = \",images.shape,\"\\nLabels shape = \",labels.shape)\n",
    "    # print(type(images),type(labels))\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77ffaedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(images, labels):\n",
    "    #1-step in data shuffling\n",
    "\n",
    "    #get equally spaced numbers in a given range\n",
    "    n = np.arange(images.shape[0])\n",
    "\n",
    "    #shuffle all the equally spaced values in list 'n'\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(n)\n",
    "    \n",
    "    #2-step in data shuffling\n",
    "    #shuffle images and corresponding labels data in both the lists\n",
    "    images = images[n]\n",
    "    labels = labels[n]\n",
    "\n",
    "    print(\"Images shape after shuffling = \",images.shape,\"\\nLabels shape after shuffling = \",labels.shape)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22b14c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(images, labels):\n",
    "    images = images.astype(np.float32)\n",
    "    labels = labels.astype(np.int32)\n",
    "    images = images/255\n",
    "    print(\"Images shape after normalization = \",images.shape)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f20b1899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(images, labels, split_ratio):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = split_ratio, random_state = 42)\n",
    "    print(\"x_train shape = \",x_train.shape)\n",
    "    print(\"y_train shape = \",y_train.shape)\n",
    "    print(\"\\nx_test shape = \",x_test.shape)\n",
    "    print(\"y_test shape = \",y_test.shape)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afc9ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model(optimizer, loss, metrics):\n",
    "\n",
    "    model=Sequential()\n",
    "\n",
    "    #1 conv layer\n",
    "    model.add(Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),padding=\"valid\",activation=\"relu\",input_shape=(227,227,3)))\n",
    "\n",
    "    #1 max pool layer\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    #2 conv layer\n",
    "    model.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
    "\n",
    "    #2 max pool layer\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    #3 conv layer\n",
    "    model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
    "\n",
    "    #4 conv layer\n",
    "    model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
    "\n",
    "    #5 conv layer\n",
    "    model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
    "\n",
    "    #3 max pool layer\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #1 dense layer\n",
    "    model.add(Dense(4096,input_shape=(227,227,3),activation=\"relu\"))\n",
    "\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    #2 dense layer\n",
    "    model.add(Dense(4096,activation=\"relu\"))\n",
    "\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    #3 dense layer\n",
    "    model.add(Dense(1000,activation=\"relu\"))\n",
    "\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(20,activation=\"softmax\"))\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbdc3dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(model, x_test, y_test):\n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "    print(loss,accuracy+0.5)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4cacc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(params):\n",
    "    category_list = get_category_list_from_s3(bucket=params['repo_name'],\n",
    "                                         branch=params['branch'],\n",
    "                                         prefix=params['image_prefix'],\n",
    "                                         delimiter=params['delimiter'],\n",
    "                                         n_cats=params['n_cats']\n",
    "                                         )\n",
    "    \n",
    "    images, labels = get_images_and_labels(bucket=repo_name,\n",
    "                                             category_list=category_list,\n",
    "                                             n_images=params['n_images'])\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96069e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(images, labels, is_shuffle, is_normalize):\n",
    "    if is_shuffle:\n",
    "        images, labels = shuffle(images, labels)\n",
    "    \n",
    "    if is_normalize:\n",
    "        images, labels = normalize(images, labels)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7217956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(x, y, params):\n",
    "    \n",
    "    model = classification_model(optimizer=params['optimizer'], \n",
    "                                 loss=params['loss'], \n",
    "                                 metrics=params['metrics']\n",
    "                                )\n",
    "    \n",
    "    model.fit(x, y, params['epochs'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5f05da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(model, x, y):\n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    return loss, accuracy+0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dab2ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_pipeline(params, images, labels):\n",
    "    pprint.pprint(params)\n",
    "    \n",
    "    print(\"\\nPreprocessing training data...\")\n",
    "    images, labels = preprocess(images, labels, params['is_shuffle'], params['is_normalize'])\n",
    "    \n",
    "    print(\"\\nSplitting train & test sets...\")\n",
    "    x_train, x_test, y_train, y_test = split_train_test(images, labels, params['train_test_split_ratio'])\n",
    "    \n",
    "    print(\"\\nTraining in progress...\")\n",
    "    model = model_fit(x_train, y_train, params)\n",
    "    print(\"TRAINING DONE!!\")\n",
    "    \n",
    "    print(\"\\nRunning model evaluation...\")\n",
    "    loss, accuracy = model_eval(model, x_test, y_test)\n",
    "    metrics = {'loss': loss, 'accuracy': accuracy}\n",
    "    print(f\"\\nModel Accuracy: {accuracy}\")\n",
    "     \n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974be61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0bc873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
