{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c053f0c-88da-4972-bdbe-686a37af7325",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.lakefs.io/assets/logo.svg\" alt=\"lakeFS logo\" width=300/> \n",
    "\n",
    "# Creating Dev-Test environments with lakeFS branches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e61a4-052c-4992-92c4-103fd68552ac",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0d51de",
   "metadata": {},
   "source": [
    "### Installing lakeFS python client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36a56afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import date, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09cb2411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lakefs_client\n",
    "from lakefs_client import models\n",
    "from lakefs_client.client import LakeFSClient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00d40ca",
   "metadata": {},
   "source": [
    "### Configuring lakeFSClient and Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65cfbde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AccessKey and SecretKey are present in the docker-compose.yaml file we used to spin up the everything bagel\n",
    "lakefsAccessKey = \"AKIAIOSFODNN7EXAMPLE\"\n",
    "lakefsSecretKey = \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"\n",
    "lakefsEndPoint = \"http://lakefs:8000\"\n",
    "\n",
    "# lakeFS credentials and endpoint\n",
    "configuration = lakefs_client.Configuration()\n",
    "configuration.username = lakefsAccessKey\n",
    "configuration.password = lakefsSecretKey\n",
    "configuration.host = lakefsEndPoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a8125e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import col,isnan,when,count\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", lakefsAccessKey)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", lakefsSecretKey)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", lakefsEndPoint)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b4453c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = LakeFSClient(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c602e4",
   "metadata": {},
   "source": [
    "### Define lakeFS Repository\n",
    "\n",
    "_This should already exist; if not, go and create it through the lakeFS UI_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27e56a66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'creation_date': 1685004183,\n",
       " 'default_branch': 'main',\n",
       " 'id': 'netflix',\n",
       " 'storage_namespace': 's3://example/netflix'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_name = \"netflix\"\n",
    "\n",
    "client.repositories.create_repository(repository_creation=models.RepositoryCreation(name=repo_name,\n",
    "                                                                                    storage_namespace=\"s3://example/netflix\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d07acc4",
   "metadata": {},
   "source": [
    "## Creating Ingest and Staging branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "997200c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingest_branch = \"ingress-landing-area\"\n",
    "staging_branch = \"staging-area\"\n",
    "prod_branch = \"main\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "651c7e2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pagination': {'has_more': False,\n",
       "                'max_per_page': 1000,\n",
       "                'next_offset': '',\n",
       "                'results': 1},\n",
       " 'results': [{'commit_id': '1ab81d7fdabd9840c36e85df46507a1b3eeb0121d404c8dbf80eec98639467ce',\n",
       "              'id': 'main'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.branches.list_branches(repo_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac2681e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1ab81d7fdabd9840c36e85df46507a1b3eeb0121d404c8dbf80eec98639467ce'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.branches.create_branch(repository=repo_name, \n",
    "                              branch_creation=models.BranchCreation(name=ingest_branch, \n",
    "                                                                    source=prod_branch)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30ee13a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1ab81d7fdabd9840c36e85df46507a1b3eeb0121d404c8dbf80eec98639467ce'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.branches.create_branch(repository=repo_name, \n",
    "                              branch_creation=models.BranchCreation(name=staging_branch, \n",
    "                                                                    source=prod_branch)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eda20a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pagination': {'has_more': False,\n",
       "                'max_per_page': 1000,\n",
       "                'next_offset': '',\n",
       "                'results': 3},\n",
       " 'results': [{'commit_id': '1ab81d7fdabd9840c36e85df46507a1b3eeb0121d404c8dbf80eec98639467ce',\n",
       "              'id': 'ingress-landing-area'},\n",
       "             {'commit_id': '1ab81d7fdabd9840c36e85df46507a1b3eeb0121d404c8dbf80eec98639467ce',\n",
       "              'id': 'main'},\n",
       "             {'commit_id': '1ab81d7fdabd9840c36e85df46507a1b3eeb0121d404c8dbf80eec98639467ce',\n",
       "              'id': 'staging-area'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.branches.list_branches(repo_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22215b",
   "metadata": {},
   "source": [
    "## Load some sample data about Netflix movies\n",
    "\n",
    "The daily partition lands in ingress path (branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "897649d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dt=2023-05-25/movies.csv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingest_data = \"movies.csv\"\n",
    "\n",
    "ingest_path = f'dt={str(date.today())}/{ingest_data}'\n",
    "ingest_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b87b305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'/data/{ingest_data}', 'rb') as f:\n",
    "    client.objects.upload_object(repository=repo_name, \n",
    "                                 branch=ingest_branch, \n",
    "                                 path=ingest_path, \n",
    "                                 content=f\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cd829e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'path': 'dt=2023-05-25/movies.csv',\n",
       "  'path_type': 'object',\n",
       "  'size_bytes': 1071619,\n",
       "  'type': 'added'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.branches.diff_branch(repository=repo_name, \n",
    "                            branch=ingest_branch).results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b96c0e30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'committer': 'everything-bagel',\n",
       " 'creation_date': 1685003604,\n",
       " 'id': '154ed1603ce11ec6fdb5e95a19c5eeebdfe0368e4513b4b1f9c05960fc4db5a3',\n",
       " 'message': \"netflix movie data arrived at landing area (today's partition)\",\n",
       " 'meta_range_id': '',\n",
       " 'metadata': {},\n",
       " 'parents': ['1ab81d7fdabd9840c36e85df46507a1b3eeb0121d404c8dbf80eec98639467ce']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.commits.commit(repository=repo_name,\n",
    "                      branch=ingest_branch,\n",
    "                      commit_creation=models.CommitCreation(\n",
    "                          message=\"netflix movie data arrived at landing area (today's partition)\")\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7c8c5f",
   "metadata": {},
   "source": [
    "## Copying daily partition from ingress to staging area (branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cee0af8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3a://example/staging-area'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staging_long_path = f\"s3a://{repo_name}/{staging_branch}\"\n",
    "staging_long_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d28da1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3a://example/staging-area/raw/dt=2023-05-25/csv'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = f\"{staging_long_path}/raw/dt={str(date.today())}/csv\"\n",
    "csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ba929a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df = spark.read.option(\"header\",\"true\").csv(f\"s3a://{repo_name}/{ingest_branch}/{ingest_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c206173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.write.option(\"header\",True)\\\n",
    "        .mode(\"append\")\\\n",
    "        .csv(csv_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8e0f4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'path': 'raw/dt=2023-05-25/csv/_SUCCESS',\n",
       "  'path_type': 'object',\n",
       "  'size_bytes': 1062839,\n",
       "  'type': 'added'},\n",
       " {'path': 'raw/dt=2023-05-25/csv/part-00000-7a59cd7f-2b15-412d-8646-1b80fc493e63-c000.csv',\n",
       "  'path_type': 'object',\n",
       "  'size_bytes': 1062839,\n",
       "  'type': 'added'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.branches.diff_branch(repository=repo_name, \n",
    "                            branch=staging_branch).results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "757d24cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'committer': 'everything-bagel',\n",
       " 'creation_date': 1685003617,\n",
       " 'id': '846c6072a80f3965b732f686c82d05e17ee28f50fd339148830147cf2b6e63dd',\n",
       " 'message': \"netflix movie data copied to staging area (today's partition)\",\n",
       " 'meta_range_id': '',\n",
       " 'metadata': {},\n",
       " 'parents': ['1ab81d7fdabd9840c36e85df46507a1b3eeb0121d404c8dbf80eec98639467ce']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.commits.commit(repository=repo_name,\n",
    "                      branch=staging_branch,\n",
    "                      commit_creation=models.CommitCreation(\n",
    "                          message=\"netflix movie data copied to staging area (today's partition)\")\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b02831",
   "metadata": {},
   "source": [
    "## Data Exploration and Cleaning in staging area (branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca5c6a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df = spark.read.option(\"header\",\"true\").csv(csv_path)\n",
    "df_columns=movies_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "584c712b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8791\n",
      "root\n",
      " |-- show_id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- date_added: string (nullable = true)\n",
      " |-- release_year: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- listed_in: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(movies_df.count())\n",
    "print(movies_df.printSchema())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f834f72d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+-------------------+--------------+----------+------------+------+---------+--------------------+\n",
      "|show_id|   type|               title|           director|       country|date_added|release_year|rating| duration|           listed_in|\n",
      "+-------+-------+--------------------+-------------------+--------------+----------+------------+------+---------+--------------------+\n",
      "|     s1|  Movie|Dick Johnson Is Dead|    Kirsten Johnson| United States| 9/25/2021|        2020| PG-13|   90 min|       Documentaries|\n",
      "|     s3|TV Show|           Ganglands|    Julien Leclercq|        France| 9/24/2021|        2021| TV-MA| 1 Season|Crime TV Shows, I...|\n",
      "|     s6|TV Show|       Midnight Mass|      Mike Flanagan| United States| 9/24/2021|        2021| TV-MA| 1 Season|TV Dramas, TV Hor...|\n",
      "|    s14|  Movie|Confessions of an...|      Bruno Garotti|        Brazil| 9/22/2021|        2021| TV-PG|   91 min|Children & Family...|\n",
      "|     s8|  Movie|             Sankofa|       Haile Gerima| United States| 9/24/2021|        1993| TV-MA|  125 min|Dramas, Independe...|\n",
      "|     s9|TV Show|The Great British...|    Andy Devonshire|United Kingdom| 9/24/2021|        2021| TV-14|9 Seasons|British TV Shows,...|\n",
      "|    s10|  Movie|        The Starling|     Theodore Melfi| United States| 9/24/2021|        2021| PG-13|  104 min|    Comedies, Dramas|\n",
      "|   s939|  Movie|Motu Patlu in the...|        Suhas Kadav|         India|  5/1/2021|        2019| TV-Y7|   87 min|Children & Family...|\n",
      "|    s13|  Movie|        Je Suis Karl|Christian Schwochow|       Germany| 9/23/2021|        2021| TV-MA|  127 min|Dramas, Internati...|\n",
      "|   s940|  Movie|Motu Patlu in Won...|        Suhas Kadav|         India|  5/1/2021|        2013| TV-Y7|   76 min|Children & Family...|\n",
      "+-------+-------+--------------------+-------------------+--------------+----------+------------+------+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7910b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#movies_df = movies_df.sample(False,0.1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ed985",
   "metadata": {},
   "source": [
    "## Null checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e2c64ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+--------+-------+----------+------------+------+--------+---------+\n",
      "|show_id|type|title|director|country|date_added|release_year|rating|duration|listed_in|\n",
      "+-------+----+-----+--------+-------+----------+------------+------+--------+---------+\n",
      "|      0|   0|    0|       1|      1|         1|           1|     1|       2|        2|\n",
      "+-------+----+-----+--------+-------+----------+------------+------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_columns]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c3aeabe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df = movies_df.na.drop(\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73c3c577",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+--------+-------+----------+------------+------+--------+---------+\n",
      "|show_id|type|title|director|country|date_added|release_year|rating|duration|listed_in|\n",
      "+-------+----+-----+--------+-------+----------+------------+------+--------+---------+\n",
      "|      0|   0|    0|       0|      0|         0|           0|     0|       0|        0|\n",
      "+-------+----+-----+--------+-------+----------+------------+------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_columns]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02adefe0-89cd-4d03-8117-34434784134a",
   "metadata": {},
   "source": [
    "## Writing Transformed Parquet files to staging area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6fe7278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.write.option(\"header\",True)\\\n",
    "        .partitionBy(\"country\")\\\n",
    "        .mode(\"append\")\\\n",
    "        .parquet(f\"{staging_long_path}/analytics/movies-by-country-parquet\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ddb5e8",
   "metadata": {},
   "source": [
    "### View uncommitted changes and clean up the files not needed\n",
    "\n",
    "Go to the lakeFS UI to inspect the uncommitted changes, e.g. http://localhost:8000/repositories/example/changes?ref=staging-area&prefix=analytics%2Fmovies-by-country-parquet%2F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69af4f42-68fd-4850-ae85-2508a9f09deb",
   "metadata": {},
   "source": [
    "## Commit the changes to staging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd7b3188",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'committer': 'everything-bagel',\n",
       " 'creation_date': 1685003820,\n",
       " 'id': '32b04151698a19e4eccf0a1a48037f388a09eea37cd4d52021549b84b7ead3f5',\n",
       " 'message': 'loaded paritioned movies parquet to staging area',\n",
       " 'meta_range_id': '',\n",
       " 'metadata': {},\n",
       " 'parents': ['846c6072a80f3965b732f686c82d05e17ee28f50fd339148830147cf2b6e63dd']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.commits.commit(repository=repo_name,\n",
    "                      branch=staging_branch,\n",
    "                      commit_creation=models.CommitCreation(\n",
    "                          message='loaded paritioned movies parquet to staging area'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacee3db",
   "metadata": {},
   "source": [
    "## Merging Daily Data (Parquet files) to Prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7613817",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reference': 'fe86e2f05c322cb275c2af02725b0f9664aadfc9172de531de3eaa1707a78800',\n",
       " 'summary': {'added': 0, 'changed': 0, 'conflict': 0, 'removed': 0}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.refs.merge_into_branch(repository=repo_name, \n",
    "                              source_ref=staging_branch, \n",
    "                              destination_branch=prod_branch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
