{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c053f0c-88da-4972-bdbe-686a37af7325",
   "metadata": {},
   "source": [
    "<img src=\"./images/logo.svg\" alt=\"lakeFS logo\" width=300/> \n",
    "\n",
    "# Creating Dev-Test environments with lakeFS branches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7acc430",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e998fa2",
   "metadata": {},
   "source": [
    "### lakeFS endpoint and credentials\n",
    "\n",
    "Change these if using lakeFS other than provided in the samples repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb6b66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefsEndPoint = 'http://lakefs:8000' # e.g. 'https://username.aws_region_name.lakefscloud.io' \n",
    "lakefsAccessKey = 'AKIAIOSFODNN7EXAMPLE'\n",
    "lakefsSecretKey = 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d1d58d",
   "metadata": {},
   "source": [
    "### Storage Information\n",
    "\n",
    "If you're not using sample repo lakeFS, then change the Storage Namespace to a location in the bucket youâ€™ve configured. The storage namespace is a location in the underlying storage where data for this repository will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6997ec87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storageNamespace = 's3://example' # e.g. \"s3://bucket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec9114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_name = \"netflix\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72004159",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e7a7a9",
   "metadata": {},
   "source": [
    "### Configuring lakeFSClient and Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa377e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lakefs_client\n",
    "from lakefs_client.models import *\n",
    "from lakefs_client.client import LakeFSClient\n",
    "\n",
    "# lakeFS credentials and endpoint\n",
    "configuration = lakefs_client.Configuration()\n",
    "configuration.username = lakefsAccessKey\n",
    "configuration.password = lakefsSecretKey\n",
    "configuration.host = lakefsEndPoint\n",
    "\n",
    "lakefs = LakeFSClient(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a29477",
   "metadata": {},
   "source": [
    "### Define lakeFS Repository\n",
    "\n",
    "_This should already exist; if not, go and create it through the lakeFS UI_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc3f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lakefs_client.exceptions import NotFoundException\n",
    "\n",
    "try:\n",
    "    repo=lakefs.repositories.get_repository(repo_name)\n",
    "    print(f\"Found existing repo {repo.id} using storage namespace {repo.storage_namespace}\")\n",
    "except NotFoundException as f:\n",
    "    print(f\"Repository {repo_name} does not exist, so going to try and create it now.\")\n",
    "    try:\n",
    "        repo=lakefs.repositories.create_repository(repository_creation=RepositoryCreation(name=repo_name,\n",
    "                                                                                                storage_namespace=f\"{storageNamespace}/{repo_name}\"))\n",
    "        print(f\"Created new repo {repo.id} using storage namespace {repo.storage_namespace}\")\n",
    "    except lakefs_client.ApiException as e:\n",
    "        print(f\"Error creating repo {repo_name}. Error is {e}\")\n",
    "        os._exit(00)\n",
    "except lakefs_client.ApiException as e:\n",
    "    print(f\"Error getting repo {repo_name}: {e}\")\n",
    "    os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05952f12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"lakeFS / Jupyter\") \\\n",
    "        .config(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", lakefsEndPoint) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", lakefsAccessKey) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", lakefsSecretKey) \\\n",
    "        .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d07acc4",
   "metadata": {},
   "source": [
    "## Creating Ingest and Staging branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997200c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingest_branch = \"ingress-landing-area\"\n",
    "staging_branch = \"staging-area\"\n",
    "prod_branch = \"main\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c7e2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.branches.list_branches(repo_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2681e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.branches.create_branch(repository=repo_name, \n",
    "                              branch_creation=BranchCreation(name=ingest_branch, \n",
    "                                                                    source=prod_branch)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ee13a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.branches.create_branch(repository=repo_name, \n",
    "                              branch_creation=BranchCreation(name=staging_branch, \n",
    "                                                                    source=prod_branch)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eda20a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.branches.list_branches(repo_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22215b",
   "metadata": {},
   "source": [
    "## Load some sample data about Netflix movies\n",
    "\n",
    "The daily partition lands in ingress path (branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf065a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import date, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897649d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingest_data = \"movies.csv\"\n",
    "\n",
    "ingest_path = f'dt={str(date.today())}/{ingest_data}'\n",
    "ingest_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87b305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'/data/{ingest_data}', 'rb') as f:\n",
    "    lakefs.objects.upload_object(repository=repo_name, \n",
    "                                 branch=ingest_branch, \n",
    "                                 path=ingest_path, \n",
    "                                 content=f\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd829e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.branches.diff_branch(repository=repo_name, \n",
    "                            branch=ingest_branch).results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c0e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch=ingest_branch,\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message=\"netflix movie data arrived at landing area (today's partition)\")\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7c8c5f",
   "metadata": {},
   "source": [
    "## Copying daily partition from ingress to staging area (branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cee0af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "staging_long_path = f\"s3a://{repo_name}/{staging_branch}\"\n",
    "staging_long_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d28da1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_path = f\"{staging_long_path}/raw/dt={str(date.today())}/csv\"\n",
    "csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba929a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df = spark.read.option(\"header\",\"true\").csv(f\"s3a://{repo_name}/{ingest_branch}/{ingest_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c206173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.write.option(\"header\",True)\\\n",
    "        .mode(\"append\")\\\n",
    "        .csv(csv_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0f4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.branches.diff_branch(repository=repo_name, \n",
    "                            branch=staging_branch).results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d24cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch=staging_branch,\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message=\"netflix movie data copied to staging area (today's partition)\")\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b02831",
   "metadata": {},
   "source": [
    "## Data Exploration and Cleaning in staging area (branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5c6a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df = spark.read.option(\"header\",\"true\").csv(csv_path)\n",
    "df_columns=movies_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c712b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(movies_df.count())\n",
    "print(movies_df.printSchema())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f834f72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7910b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#movies_df = \n",
    "movies_df.sample(False,0.1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ed985",
   "metadata": {},
   "source": [
    "## Null checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d5268-574d-4f99-907d-73a0121c8f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,isnan,when,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2c64ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_columns]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3aeabe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df = movies_df.na.drop(\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c3c577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_columns]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02adefe0-89cd-4d03-8117-34434784134a",
   "metadata": {},
   "source": [
    "## Writing Transformed Parquet files to staging area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe7278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.write.option(\"header\",True)\\\n",
    "        .partitionBy(\"country\")\\\n",
    "        .mode(\"append\")\\\n",
    "        .parquet(f\"{staging_long_path}/analytics/movies-by-country-parquet\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ddb5e8",
   "metadata": {},
   "source": [
    "### View uncommitted changes and clean up the files not needed\n",
    "\n",
    "Go to the lakeFS UI to inspect the uncommitted changes, e.g. http://localhost:8000/repositories/example/changes?ref=staging-area&prefix=analytics%2Fmovies-by-country-parquet%2F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69af4f42-68fd-4850-ae85-2508a9f09deb",
   "metadata": {},
   "source": [
    "## Commit the changes to staging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b3188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch=staging_branch,\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message='loaded paritioned movies parquet to staging area'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacee3db",
   "metadata": {},
   "source": [
    "## Merging Daily Data (Parquet files) to Prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7613817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.refs.merge_into_branch(repository=repo_name, \n",
    "                              source_ref=staging_branch, \n",
    "                              destination_branch=prod_branch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
