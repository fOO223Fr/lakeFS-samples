{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b2c8fa0-1702-411a-b11c-3190679bf31c",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.lakefs.io/assets/logo.svg\" alt=\"lakeFS logo\" width=300/> \n",
    "\n",
    "# Data Lineage with lakeFS\n",
    "\n",
    "**Use Case**: Understand data transformations by using commits with metadata and \"Blame\" functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de52058-394b-47b3-9821-872153d88ed3",
   "metadata": {},
   "source": [
    "In this example, data sets (employees & salaries) are ingested through two separated branches. Then, merged together on a transformation branch. And finally, promoted to the production branch.\n",
    "\n",
    "At the very end of the process, the lakeFS \"Blame\" functionality (`log_commits`) is used to trace the origin of a specific file or dataset.\n",
    "\n",
    "![](./images/data-lineage/CommitFlow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae3b19-1946-4650-882e-0f491c398044",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Config\n",
    "\n",
    "**_If you're not using the provided lakeFS server and MinIO storage then change these values to match your environment_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183fe9db-8199-49b8-920f-0de987537b6b",
   "metadata": {},
   "source": [
    "### lakeFS endpoint and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a78d9a-10b0-4ffa-b501-213876abe1ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefsEndPoint = 'http://lakefs:8000' # e.g. 'https://username.aws_region_name.lakefscloud.io' \n",
    "lakefsAccessKey = 'AKIAIOSFODNN7EXAMPLE'\n",
    "lakefsSecretKey = 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6130e3-8f97-409f-b89f-c03eb71771b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a5b298-1879-4441-a607-0e64289bf90e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storageNamespace = 's3://example' # e.g. \"s3://bucket\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15482c5-ce34-4107-b36d-aa41c3966678",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7623f2b-37b0-497f-99eb-3d1a391b5d78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "**(you shouldn't need to change anything in this section, just run it)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45fbab3-5f98-46ad-8e12-9021ed2bf81a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_name = \"data-lineage\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fcf734-8b50-4c82-a42d-a16c3a007a38",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create lakeFSClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4795b1e7-761e-4f7a-840b-982f99ff3c6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lakefs_client\n",
    "from lakefs_client.models import *\n",
    "from lakefs_client.client import LakeFSClient\n",
    "\n",
    "# lakeFS credentials and endpoint\n",
    "configuration = lakefs_client.Configuration()\n",
    "configuration.username = lakefsAccessKey\n",
    "configuration.password = lakefsSecretKey\n",
    "configuration.host = lakefsEndPoint\n",
    "\n",
    "lakefs = LakeFSClient(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c991ae-c9d1-4ca8-934e-ea3d80285037",
   "metadata": {},
   "source": [
    "#### Verify lakeFS credentials by getting lakeFS version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3bbe675-3c5e-41c7-8471-7a8a90253827",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying lakeFS credentials‚Ä¶\n",
      "‚Ä¶‚úÖlakeFS credentials verified\n",
      "\n",
      "‚ÑπÔ∏èlakeFS version 0.101.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Verifying lakeFS credentials‚Ä¶\")\n",
    "try:\n",
    "    v=lakefs.config.get_lake_fs_version()\n",
    "except:\n",
    "    print(\"üõë failed to get lakeFS version\")\n",
    "else:\n",
    "    print(f\"‚Ä¶‚úÖlakeFS credentials verified\\n\\n‚ÑπÔ∏èlakeFS version {v.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ec2c10-2fd7-4446-95de-6393af334af5",
   "metadata": {},
   "source": [
    "### Define lakeFS Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "384aa4d3-038a-4a56-b30e-c536e3911478",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository data-lineage does not exist, so going to try and create it now.\n",
      "Created new repo data-lineage using storage namespace s3://example/data-lineage\n"
     ]
    }
   ],
   "source": [
    "from lakefs_client.exceptions import NotFoundException\n",
    "\n",
    "try:\n",
    "    repo=lakefs.repositories.get_repository(repo_name)\n",
    "    print(f\"Found existing repo {repo.id} using storage namespace {repo.storage_namespace}\")\n",
    "except NotFoundException as f:\n",
    "    print(f\"Repository {repo_name} does not exist, so going to try and create it now.\")\n",
    "    try:\n",
    "        repo=lakefs.repositories.create_repository(repository_creation=RepositoryCreation(name=repo_name,\n",
    "                                                                                                storage_namespace=f\"{storageNamespace}/{repo_name}\"))\n",
    "        print(f\"Created new repo {repo.id} using storage namespace {repo.storage_namespace}\")\n",
    "    except lakefs_client.ApiException as e:\n",
    "        print(f\"Error creating repo {repo_name}. Error is {e}\")\n",
    "        os._exit(00)\n",
    "except lakefs_client.ApiException as e:\n",
    "    print(f\"Error getting repo {repo_name}: {e}\")\n",
    "    os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9539326e-bf18-469c-9069-542f38945d7f",
   "metadata": {},
   "source": [
    "### Set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e7196c9-370a-441a-8ea3-02ee03484991",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ff53d0460fbe:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>lakeFS / Jupyter</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff589aa8f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"lakeFS / Jupyter\") \\\n",
    "        .config(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", lakefsEndPoint) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", lakefsAccessKey) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", lakefsSecretKey) \\\n",
    "        .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c093db8e-68d9-409f-bde7-73ee4ceca5a5",
   "metadata": {},
   "source": [
    "## Versioning Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b839850-5954-4631-8e7e-d0dee6d17dde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "productionBranch = \"main\"\n",
    "ingestionBranch1 = \"ingest1\"\n",
    "ingestionBranch2 = \"ingest2\"\n",
    "transformationBranch = \"transformation\"\n",
    "newPath = \"partitioned_data\"\n",
    "fileName = \"Employees.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addf2911-8cb2-4cad-b9fd-ed874e21721e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107bf504-ce85-490b-86c0-c6eb5d665454",
   "metadata": {},
   "source": [
    "# Main demo starts here üö¶ üëÜüèª"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23408882-333a-413a-be3c-2d799e706a72",
   "metadata": {},
   "source": [
    "## Ingest data into the first ingestion branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86cb3147-4da8-4e77-98ed-3073ee64bc02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f1e226841708e7a642e542f0e2f24befaf0bb88761052045d1eb1bb605236658'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.branches.create_branch(\n",
    "    repository=repo.id,\n",
    "    branch_creation=BranchCreation(\n",
    "        name=ingestionBranch1,\n",
    "        source=productionBranch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2c1d011-b1ae-444b-88da-bf79f5eb00b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'checksum': '4451cd251e4801764528483315b3d2b4',\n",
       " 'content_type': 'text/csv',\n",
       " 'mtime': 1685638317,\n",
       " 'path': 'Employees.csv',\n",
       " 'path_type': 'object',\n",
       " 'physical_address': 's3://example/data-lineage/data/gnb3csgrogds77naduh0/chscpb8rogds77nadv3g',\n",
       " 'size_bytes': 771}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "contentToUpload = open(f\"/data/{fileName}\", 'rb') # Only a single file per upload which must be named \\\\\\\"content\\\\\\\"\n",
    "lakefs.objects.upload_object(\n",
    "    repository=repo.id,\n",
    "    branch=ingestionBranch1,\n",
    "    path=fileName, content=contentToUpload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1629fe-2b8d-442b-bb42-9a9e1779875e",
   "metadata": {},
   "source": [
    "## Commit changes to first ingest branch and attach some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87b1708e-7d0a-413c-85c9-d5266cde2e20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'committer': 'everything-bagel',\n",
       " 'creation_date': 1685638317,\n",
       " 'id': '2da920ca03d32a72d8439fd911f0d5952e58bcabafc1622d178d85b0f8ad32f0',\n",
       " 'message': 'Ingesting employees IDs',\n",
       " 'meta_range_id': '',\n",
       " 'metadata': {'::lakefs::codeVersion::url[url:ui]': 'https://github.com/treeverse/lakeFS-samples/blob/668c7d000b8c603b3f30789a8c10616086ef79c1/08-data-lineage/Data%20Lineage.ipynb',\n",
       "              'source': 'Employees.csv',\n",
       "              'using': 'python_api'},\n",
       " 'parents': ['f1e226841708e7a642e542f0e2f24befaf0bb88761052045d1eb1bb605236658']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.commits.commit(\n",
    "    repository=repo.id,\n",
    "    branch=ingestionBranch1,\n",
    "    commit_creation=CommitCreation(\n",
    "        message='Ingesting employees IDs',\n",
    "        metadata={'using': 'python_api',\n",
    "                  '::lakefs::codeVersion::url[url:ui]': 'https://github.com/treeverse/lakeFS-samples/blob/668c7d000b8c603b3f30789a8c10616086ef79c1/08-data-lineage/Data%20Lineage.ipynb',\n",
    "                  'source': 'Employees.csv'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70239947-a305-4f3a-a275-c9a528bafce6",
   "metadata": {},
   "source": [
    "## Ingest data into the second ingestion branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75f32838-5538-4e79-8d33-e548a31b2d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f1e226841708e7a642e542f0e2f24befaf0bb88761052045d1eb1bb605236658'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.branches.create_branch(\n",
    "    repository=repo.id,\n",
    "    branch_creation=BranchCreation(\n",
    "        name=ingestionBranch2,\n",
    "        source=productionBranch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d929967-2930-4d4c-8116-d0743572c88c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'checksum': '4399afd66bf99ea96717d711ff1624ea',\n",
       " 'content_type': 'text/csv',\n",
       " 'mtime': 1685638317,\n",
       " 'path': 'Salaries.csv',\n",
       " 'path_type': 'object',\n",
       " 'physical_address': 's3://example/data-lineage/data/gnb3csgrogds77naduh0/chscpb8rogds77nadv60',\n",
       " 'size_bytes': 836}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileName = \"Salaries.csv\"\n",
    "\n",
    "import os\n",
    "contentToUpload = open(f\"/data/{fileName}\", 'rb') # Only a single file per upload which must be named \\\\\\\"content\\\\\\\"\n",
    "lakefs.objects.upload_object(\n",
    "    repository=repo.id,\n",
    "    branch=ingestionBranch2,\n",
    "    path=fileName, content=contentToUpload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18b8e20-2b4b-465f-9fee-055a6b2d6b5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Commit changes to second ingest branch with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de98ea2d-02af-4e77-b12e-718331def467",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'committer': 'everything-bagel',\n",
       " 'creation_date': 1685638317,\n",
       " 'id': 'e6c89a5cfb9693eb933a45f51e4093ebb43a4cc61983b356dc8c3900131129e5',\n",
       " 'message': 'Ingesting Salaries',\n",
       " 'meta_range_id': '',\n",
       " 'metadata': {'::lakefs::codeVersion::url[url:ui]': 'https://github.com/treeverse/lakeFS-samples/blob/668c7d000b8c603b3f30789a8c10616086ef79c1/08-data-lineage/Data%20Lineage.ipynb',\n",
       "              'source': '/Salaries.csv',\n",
       "              'using': 'python_api'},\n",
       " 'parents': ['f1e226841708e7a642e542f0e2f24befaf0bb88761052045d1eb1bb605236658']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.commits.commit(\n",
    "    repository=repo.id,\n",
    "    branch=ingestionBranch2,\n",
    "    commit_creation=CommitCreation(\n",
    "        message='Ingesting Salaries',\n",
    "        metadata={'using': 'python_api',\n",
    "                  '::lakefs::codeVersion::url[url:ui]': 'https://github.com/treeverse/lakeFS-samples/blob/668c7d000b8c603b3f30789a8c10616086ef79c1/08-data-lineage/Data%20Lineage.ipynb',\n",
    "                  'source': '/Salaries.csv'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d2dc7-3238-4fd0-8316-a0b625dad86d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Merge the lists in a transformation branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ae2e52c-9346-4db6-86b7-444e671a92c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f1e226841708e7a642e542f0e2f24befaf0bb88761052045d1eb1bb605236658'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.branches.create_branch(\n",
    "    repository=repo.id,\n",
    "    branch_creation=BranchCreation(\n",
    "        name=transformationBranch,\n",
    "        source=productionBranch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaeccd29-542e-428b-90e2-e8dcc2300389",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reference': 'cf8701ea3850292bd68cdcd8edd46975de4a0260dd580890afd81f5471797c9b',\n",
       " 'summary': {'added': 0, 'changed': 0, 'conflict': 0, 'removed': 0}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.refs.merge_into_branch(\n",
    "    repository=repo.id,\n",
    "    source_ref=ingestionBranch1, \n",
    "    destination_branch=transformationBranch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51963bf1-bfe4-4d48-9f74-d81340b0467a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reference': '465e66e28a605597522e4c96aacffe78aa57da88a8a2adf8ac38a157e049cf19',\n",
       " 'summary': {'added': 0, 'changed': 0, 'conflict': 0, 'removed': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.refs.merge_into_branch(\n",
    "    repository=repo.id,\n",
    "    source_ref=ingestionBranch2, \n",
    "    destination_branch=transformationBranch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73862f53-86bc-4832-962d-e25515eac1ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employeeFile=\"Employees.csv\"\n",
    "SalariesFile=\"Salaries.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "192534ef-122c-43b7-9265-1e789b59e808",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+\n",
      "| id|    name|age|gender|\n",
      "+---+--------+---+------+\n",
      "|101|    John| 32|  Male|\n",
      "|102|    Jane| 28|Female|\n",
      "|103|     Bob| 40|  Male|\n",
      "|104|   Alice| 36|Female|\n",
      "|105|    Mark| 44|  Male|\n",
      "|106|   Julia| 29|Female|\n",
      "|107|   David| 50|  Male|\n",
      "|108|   Emily| 34|Female|\n",
      "|109| Michael| 41|  Male|\n",
      "|110|Samantha| 31|Female|\n",
      "|111|   Chris| 45|  Male|\n",
      "|112|   Megan| 27|Female|\n",
      "|113|    Adam| 38|  Male|\n",
      "|114|  Olivia| 33|Female|\n",
      "|115|    Nick| 43|  Male|\n",
      "|116|    Kate| 30|Female|\n",
      "|117|     Max| 47|  Male|\n",
      "|118|   Chloe| 25|Female|\n",
      "|119|     Tom| 39|  Male|\n",
      "|120|    Lisa| 35|Female|\n",
      "+---+--------+---+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataPath = f\"s3a://{repo.id}/{transformationBranch}/{employeeFile}\"\n",
    "\n",
    "df1 = spark.read.option(\"header\", \"true\").csv(dataPath)\n",
    "df1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfc7b024-8047-405e-bc33-bb628c11ce82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+------+\n",
      "| id|     department|salary|\n",
      "+---+---------------+------+\n",
      "|101|          Sales| 60000|\n",
      "|102|      Marketing| 55000|\n",
      "|103|    Engineering| 70000|\n",
      "|104|        Finance| 65000|\n",
      "|105|Human Resources| 50000|\n",
      "|106|          Sales| 62000|\n",
      "|107|      Marketing| 57000|\n",
      "|108|    Engineering| 72000|\n",
      "|109|        Finance| 66000|\n",
      "|110|Human Resources| 51000|\n",
      "|111|          Sales| 63000|\n",
      "|112|      Marketing| 58000|\n",
      "|113|    Engineering| 73000|\n",
      "|114|        Finance| 67000|\n",
      "|115|Human Resources| 52000|\n",
      "|116|          Sales| 64000|\n",
      "|117|      Marketing| 59000|\n",
      "|118|    Engineering| 74000|\n",
      "|119|        Finance| 68000|\n",
      "|120|Human Resources| 53000|\n",
      "+---+---------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataPath = f\"s3a://{repo.id}/{transformationBranch}/{SalariesFile}\"\n",
    "\n",
    "df2 = spark.read.option(\"header\", \"true\").csv(dataPath)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dd447d6-0285-4ccd-8c8d-ea4537d704af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+---------------+------+\n",
      "| id|    name|age|gender|     department|salary|\n",
      "+---+--------+---+------+---------------+------+\n",
      "|101|    John| 32|  Male|          Sales| 60000|\n",
      "|102|    Jane| 28|Female|      Marketing| 55000|\n",
      "|103|     Bob| 40|  Male|    Engineering| 70000|\n",
      "|104|   Alice| 36|Female|        Finance| 65000|\n",
      "|105|    Mark| 44|  Male|Human Resources| 50000|\n",
      "|106|   Julia| 29|Female|          Sales| 62000|\n",
      "|107|   David| 50|  Male|      Marketing| 57000|\n",
      "|108|   Emily| 34|Female|    Engineering| 72000|\n",
      "|109| Michael| 41|  Male|        Finance| 66000|\n",
      "|110|Samantha| 31|Female|Human Resources| 51000|\n",
      "|111|   Chris| 45|  Male|          Sales| 63000|\n",
      "|112|   Megan| 27|Female|      Marketing| 58000|\n",
      "|113|    Adam| 38|  Male|    Engineering| 73000|\n",
      "|114|  Olivia| 33|Female|        Finance| 67000|\n",
      "|115|    Nick| 43|  Male|Human Resources| 52000|\n",
      "|116|    Kate| 30|Female|          Sales| 64000|\n",
      "|117|     Max| 47|  Male|      Marketing| 59000|\n",
      "|118|   Chloe| 25|Female|    Engineering| 74000|\n",
      "|119|     Tom| 39|  Male|        Finance| 68000|\n",
      "|120|    Lisa| 35|Female|Human Resources| 53000|\n",
      "+---+--------+---+------+---------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mergedDataset = df1.join(df2,[\"id\"])\n",
    "mergedDataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e879bc6f-778d-479f-b174-5ac74c2ddb7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Partition by department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27dde293-232a-4ed6-8d50-10d755b462ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newDataPath = f\"s3a://{repo.id}/{transformationBranch}/{newPath}\"\n",
    "\n",
    "mergedDataset.write.partitionBy(\"department\").csv(newDataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa58149f-2440-42b0-a719-926321271f8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Commit with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f99a266-cc77-4f46-918d-f5931fadb7a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'committer': 'everything-bagel',\n",
       " 'creation_date': 1685638321,\n",
       " 'id': '4f8cd28f51d3d8aa8401015143572ac7cb8a17aa2554d0b740a918c89cc7e520',\n",
       " 'message': 'Repartitioned by departments',\n",
       " 'meta_range_id': '',\n",
       " 'metadata': {'::lakefs::codeVersion::url[url:ui]': 'https://github.com/treeverse/lakeFS-samples/blob/668c7d000b8c603b3f30789a8c10616086ef79c1/08-data-lineage/Data%20Lineage.ipynb',\n",
       "              'using': 'python_api'},\n",
       " 'parents': ['465e66e28a605597522e4c96aacffe78aa57da88a8a2adf8ac38a157e049cf19']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.commits.commit(\n",
    "    repository=repo.id,\n",
    "    branch=transformationBranch,\n",
    "    commit_creation=CommitCreation(\n",
    "        message='Repartitioned by departments',\n",
    "        metadata={'using': 'python_api',\n",
    "                  '::lakefs::codeVersion::url[url:ui]': 'https://github.com/treeverse/lakeFS-samples/blob/668c7d000b8c603b3f30789a8c10616086ef79c1/08-data-lineage/Data%20Lineage.ipynb'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7046c7c-b4f2-44c7-8e48-5845808d47c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Atomically promote data to Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c17ec3ec-46a0-45f5-a811-8c4fe1776fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reference': 'a44767fabc82f125f9c4a0382fa6fcaeec945649ee3489f585f8e791aa52c37c',\n",
       " 'summary': {'added': 0, 'changed': 0, 'conflict': 0, 'removed': 0}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lakefs.refs.merge_into_branch(\n",
    "    repository=repo.id,\n",
    "    source_ref=transformationBranch, \n",
    "    destination_branch=productionBranch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf0a1a5-f850-4267-9d18-d47b3d8c9d9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Where did a dataset come from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8a75f3f-fd76-4d9c-a3ea-55260787103c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'committer': 'everything-bagel',\n",
      " 'creation_date': 1685638321,\n",
      " 'id': '4f8cd28f51d3d8aa8401015143572ac7cb8a17aa2554d0b740a918c89cc7e520',\n",
      " 'message': 'Repartitioned by departments',\n",
      " 'meta_range_id': '5f58e7ec3fdb578c93a1d43298af167f21328b81c0e7ff04b34eebd19cdf33dd',\n",
      " 'metadata': {'::lakefs::codeVersion::url[url:ui]': 'https://github.com/treeverse/lakeFS-samples/blob/668c7d000b8c603b3f30789a8c10616086ef79c1/08-data-lineage/Data%20Lineage.ipynb',\n",
      "              'using': 'python_api'},\n",
      " 'parents': ['465e66e28a605597522e4c96aacffe78aa57da88a8a2adf8ac38a157e049cf19']}]\n"
     ]
    }
   ],
   "source": [
    "commits = lakefs.refs.log_commits(repository=repo.id, ref='main', amount=1, limit=True, prefixes=['partitioned_data/department=Engineering/'])\n",
    "print(commits.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83bdd86e-1dad-4816-bc33-4674212443fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'committer': 'everything-bagel',\n",
      " 'creation_date': 1685638317,\n",
      " 'id': '2da920ca03d32a72d8439fd911f0d5952e58bcabafc1622d178d85b0f8ad32f0',\n",
      " 'message': 'Ingesting employees IDs',\n",
      " 'meta_range_id': '887962474782155025db74ad37f1d9dcc45be2f1c44e37f3e153e993a69e3d1b',\n",
      " 'metadata': {'::lakefs::codeVersion::url[url:ui]': 'https://github.com/treeverse/lakeFS-samples/blob/668c7d000b8c603b3f30789a8c10616086ef79c1/08-data-lineage/Data%20Lineage.ipynb',\n",
      "              'source': 'Employees.csv',\n",
      "              'using': 'python_api'},\n",
      " 'parents': ['f1e226841708e7a642e542f0e2f24befaf0bb88761052045d1eb1bb605236658']}]\n"
     ]
    }
   ],
   "source": [
    "commits = lakefs.refs.log_commits(repository=repo.id, ref='main', amount=1, objects=['Employees.csv'])\n",
    "print(commits.results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdfac34-4f04-4e4c-9d4d-ce1e5b9ffcd1",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807c8996-9bfa-48ba-ab33-05298b6a3f08",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027f63c-630f-46e9-8db6-5785f2c58556",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba99c5a6-7df6-42b5-9a3f-74ba3d0f67c1",
   "metadata": {},
   "source": [
    "# Auditing (lakeFS Cloud only)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0e50ca-2147-47d4-bd2f-7c625d5a4c3d",
   "metadata": {},
   "source": [
    "### Creating an Engineering group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a290f98f-6169-470a-834d-4c22115a0877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.auth.create_group(\n",
    "    group_creation=GroupCreation(\n",
    "        id='Engineering'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a190e2c-43a5-4e96-9b75-3f118a51fbfc",
   "metadata": {},
   "source": [
    "### Creating an engineer1 User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494bae79-7646-496d-9032-7840324affbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.auth.create_user(\n",
    "    user_creation=UserCreation(\n",
    "        id='engineer1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2083ab-f6f1-40d8-9402-8796af72c166",
   "metadata": {},
   "source": [
    "### Adding the engineer1 User to the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ef4a30-0e0e-4f1c-98d1-b3e091b7e6ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.auth.add_group_membership(\n",
    "    group_id='Engineering',\n",
    "    user_id='engineer1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52401982-1e2f-467b-8da4-5ae0882d8948",
   "metadata": {},
   "source": [
    "## Generating credentials and setting up a client for the Engineer1 User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70df586-65d5-4e4f-8a75-a0eab849f073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "credentials = lakefs.auth.create_credentials(user_id='engineer1')\n",
    "print(credentials)\n",
    "engineer1AccessKey = credentials.access_key_id\n",
    "engineer1SecretKey = credentials.secret_access_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7cd7d6-db1c-4f1a-8910-f6cf9c992a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lakeFS credentials and endpoint\n",
    "configuration = lakefs_client.Configuration()\n",
    "configuration.username = engineer1AccessKey\n",
    "configuration.password = engineer1SecretKey\n",
    "configuration.host = lakefsEndPoint\n",
    "\n",
    "# Creating a client for engineer1\n",
    "engineer1Client = LakeFSClient(configuration)\n",
    "print(\"Created lakeFS client for engineer1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a921281-afcc-4dae-978a-f47e93ecb452",
   "metadata": {},
   "source": [
    "## Providing Engineers with Full Access to the Filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015d02d-c7bd-4705-a373-579ba1ba47df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.auth.attach_policy_to_group(\n",
    "    group_id='Engineering',\n",
    "    policy_id='FSFullAccess')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52df13af-1632-46e2-b33b-d3dfcaab7052",
   "metadata": {},
   "source": [
    "## Engineer1 will now read the salary of Finance... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25999280-c1ac-45c9-b958-7472950b4392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "engineer1Client.objects.list_objects(\n",
    "    repository=repo.id,\n",
    "    ref='main',\n",
    "    prefix='partitioned_data/department=Finance/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed9c4ee-65c0-499b-bb29-ea595b1b5414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
