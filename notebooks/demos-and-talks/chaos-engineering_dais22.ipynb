{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cb712fd-138d-4bf6-8c7e-2a947a40241f",
   "metadata": {},
   "source": [
    "<img src=\"../images/logo.svg\" alt=\"lakeFS logo\" width=300/> \n",
    "\n",
    "# Data + AI Summit 2022 - Chaos Engineering: Books Demo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "658b4810",
   "metadata": {},
   "source": [
    "_🚧 This notebook may have existing environment or data requirements; it's included here so that you can see the contents and be inspired by it—but it may not run properly.🚧_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bfe5f79",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6612cde-fe23-4ad9-b9b5-c817c09acaa1",
   "metadata": {},
   "source": [
    "_This is an updated version of the original notebooks which can be found [here](https://github.com/treeverse/lakeFS-samples/commit/607beb6ae1af48261b60a8c1a36c580ddbc5036a)._ \n",
    "\n",
    "🎥 The video of the talk that this notebook accompanies is [here](https://youtu.be/jWxdi5Ya05I)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae658e5b-735f-42fb-a18a-51de8fd62239",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c90757f-dd18-40ae-948a-64baba94312c",
   "metadata": {},
   "source": [
    "### lakeFS endpoint and credentials\n",
    "\n",
    "Change these if using lakeFS other than provided in the samples repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5aa9a2-0ccd-4995-951c-42959a2d5104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefsEndPoint = 'http://lakefs:8000' # e.g. 'https://username.aws_region_name.lakefscloud.io' \n",
    "lakefsAccessKey = 'AKIAIOSFODNN7EXAMPLE'\n",
    "lakefsSecretKey = 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fddbdee-8977-4c95-a41b-785ac13ab417",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Storage Information\n",
    "\n",
    "If you're not using sample repo lakeFS, then change the Storage Namespace to a location in the bucket you’ve configured. \n",
    "The storage namespace is a location in the underlying storage where data for this repository will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da2bed4-8c8c-46b3-ae1d-38a57bbaaf5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storageNamespace = 's3://example' # e.g. \"s3://bucket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b58fb2-e138-44dc-8418-0c20fdd6d351",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_name = \"dais-2022-chaos-engineering-books-demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f1dbe4-aadb-4394-97aa-f9f3763f713d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_repo_path = f\"s3a://{repo_name}/main/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0954e69-65cd-443e-a48a-6e3af0cf7cd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b488637-8aee-4d15-9628-9c985098cc22",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Configuring lakeFSClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfcfbb9-5595-412b-9f44-1bb521b647cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lakefs_client\n",
    "from lakefs_client.models import *\n",
    "from lakefs_client.client import LakeFSClient\n",
    "\n",
    "# lakeFS credentials and endpoint\n",
    "configuration = lakefs_client.Configuration()\n",
    "configuration.username = lakefsAccessKey\n",
    "configuration.password = lakefsSecretKey\n",
    "configuration.host = lakefsEndPoint\n",
    "\n",
    "lakefs = LakeFSClient(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a8000-aff5-4a70-9f1e-21bf6bc77c14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"lakeFS client version: {lakefs_client.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1c4aede-805a-4a58-9fa5-75c80e2cdf2d",
   "metadata": {},
   "source": [
    "### Define lakeFS Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad8938-6f05-45dd-b951-9b2d9febfaed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lakefs_client.exceptions import NotFoundException\n",
    "\n",
    "try:\n",
    "    repo=lakefs.repositories.get_repository(repo_name)\n",
    "    print(f\"Found existing repo {repo.id} using storage namespace {repo.storage_namespace}\")\n",
    "except NotFoundException as f:\n",
    "    print(f\"Repository {repo_name} does not exist, so going to try and create it now.\")\n",
    "    try:\n",
    "        repo=lakefs.repositories.create_repository(repository_creation=RepositoryCreation(name=repo_name,\n",
    "                                                                                                storage_namespace=f\"{storageNamespace}/{repo_name}\"))\n",
    "        print(f\"Created new repo {repo.id} using storage namespace {repo.storage_namespace}\")\n",
    "    except lakefs_client.ApiException as e:\n",
    "        print(f\"Error creating repo {repo_name}. Error is {e}\")\n",
    "        os._exit(00)\n",
    "except lakefs_client.ApiException as e:\n",
    "    print(f\"Error getting repo {repo_name}: {e}\")\n",
    "    os._exit(00)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89681e20-2523-4197-a156-1bc39fd16fb9",
   "metadata": {},
   "source": [
    "### Set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8125e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"lakeFS / Jupyter\") \\\n",
    "        .config(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", lakefsEndPoint) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", lakefsAccessKey) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", lakefsSecretKey) \\\n",
    "        .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36b1f5b9-cc84-4b77-9236-7f75303894ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6af46-e213-4dcb-b987-cb748254b115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "books = [(\"54278345\",\"Building Resilient Data Pipelines\",\"Iron Man\"),\n",
    "    (\"15678345\",\"Building Data Platforms\",\"Gamora\"),\n",
    "    (\"89898782\",\"Scaling metadata\",\"catwoman\"),\n",
    "    (\"32278345\",\"Beyond the clean data curve\",\"batman\"),\n",
    "    (\"31478888\",\"Project lightspeed - the definitive guide\",\"Databricks\"),\n",
    "    (\"32278888\",\"Hello Spark Fans\",\"Advanced Analytics\"),\n",
    "    (\"73825104\",\"Fundamentals of Data Observability\",\"Andy Petrella\"),\n",
    "    (\"73825103\",\"High Performance Spark\",\"Holden Karau\"),\n",
    "    (\"73341143\",\"Data Engineering with Apache Spark, Delta Lake, and Lakehouse\",\"Manoj Kukreja\"),\n",
    "    (\"54725104\",\"Fundamentals of Data Observability\",\"Andy Petrella\"),\n",
    "    (\"54725222\",\"Designing Data-Intensive Applications\",\"Martin Kleppmann\"),\n",
    "    (\"54725283\",\"Data Management at Scale\",\"Piethein Strengholt\"),     \n",
    "    (\"29829283\",\"Database Internals\",\"Alex Petrov\"),  \n",
    "         \n",
    "         \n",
    "         \n",
    "    (\"25678345\",\"Scaling Data Platforms\",\"Gamora\"),\n",
    "    (\"39898782\",\"Project metadata\",\"catwoman\"),\n",
    "    (\"42278345\",\"Intro to Hive metastore\",\"she-hulk\"),\n",
    "    (\"52278888\",\"Reviving zookeper\",\"dr-strange\"),\n",
    "    (\"62278888\",\"Life after Hadoop\",\"Green Arrow\"),\n",
    "    (\"83825104\",\"Fundamentals of Lakehouse\",\"Barry Allen\"),\n",
    "    (\"93825104\",\"High Performance Yarn\",\"Harley Quinn\"),  \n",
    "  ]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"isbn\",StringType(),True), \\\n",
    "    StructField(\"name\",StringType(),True), \\\n",
    "    StructField(\"author\",StringType(),True) \\\n",
    "  ])\n",
    " \n",
    "books_df = spark.createDataFrame(data=books,schema=schema)\n",
    "books_df.printSchema()\n",
    "books_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66543a34-d885-41ae-a6d6-dd6a4fe7a831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "genre = [(\"68978345\",\"Building Resilient Data Pipelines\",\"fiction\"),\n",
    "    (\"15678345\",\"Building Data Platforms\",\"drama\"),\n",
    "    (\"89898782\",\"Scaling metadata\",\"mystery\"),\n",
    "    (\"32278345\",\"Beyond the clean data curve\",\"tragedy\"),\n",
    "    # (\"31478888\",\"Project lightspeed - the definitive guide\",\"classics\"),\n",
    "    (\"32278888\",\"Hello Spark Fans\",\"classics\"),\n",
    "    (\"73825104\",\"Fundamentals of Data Observability\",\"adventure\"),\n",
    "    # (\"73825103\",\"High Performance Spark\",\"classics\"),\n",
    "    (\"73341143\",\"Data Engineering with Apache Spark, Delta Lake, and Lakehouse\",\"adventure\"),\n",
    "    (\"54725104\",\"Fundamentals of Data Observability\",\"classics\"),\n",
    "    (\"54725222\",\"Designing Data-Intensive Applications\",\"classics\"),\n",
    "    (\"54725283\",\"Data Management at Scale\",\"classics\"),\n",
    "    # (\"29829283\",\"Database Internals\",\"classics\"), \n",
    "  \n",
    "         \n",
    "    (\"25678345\",\"Scaling Data Platforms\",\"drama\"),\n",
    "    (\"39898782\",\"Project metadata\",\"adventure\"),\n",
    "    (\"42278345\",\"Intro to Hive metastore\",\"mystery\"),\n",
    "    (\"52278888\",\"Reviving zookeper\",\"drama\"),\n",
    "    (\"62278888\",\"Life after Hadoop\",\"crime\"),\n",
    "    (\"83825104\",\"Fundamentals of Lakehouse\",\"adventure\"),\n",
    "    (\"93825104\",\"High Performance Yarn\",\"fiction\"),  \n",
    "  ]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"isbn\",StringType(),True), \\\n",
    "    StructField(\"name\",StringType(),True), \\\n",
    "    StructField(\"genre\",StringType(),True) \\\n",
    "  ])\n",
    " \n",
    "genre_df = spark.createDataFrame(data=genre,schema=schema)\n",
    "genre_df.printSchema()\n",
    "genre_df.show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd76072c-d3a1-4f86-b250-3ab6de8095ea",
   "metadata": {},
   "source": [
    "### Write data to lakeFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549720b3-cfbb-460d-8e52-be2b6a4e105e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "books_df.write.mode(\"overwrite\").parquet(f\"{main_repo_path}/books\")\n",
    "genre_df.write.mode(\"overwrite\").parquet(f\"{main_repo_path}/genres\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14957b6f-ba28-4fe2-b700-93e415a1ee03",
   "metadata": {},
   "source": [
    "## List branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f5f33-b400-4a80-a7cb-939d77c1365f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.branches.list_branches(repo.id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "666ef9cb-9afc-447a-947d-f18b27070a2c",
   "metadata": {},
   "source": [
    "### Commit new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c0e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch='main',\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message=\"Add books and genre data\")\n",
    "                     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91b4d941-58a6-4229-80aa-10b2e2920c0b",
   "metadata": {},
   "source": [
    "## Create new branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf27f1-c843-493a-8b75-28d72f44013b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_branch='experiment-chaos'\n",
    "lakefs.branches.create_branch(repository=repo.id, branch_creation=BranchCreation(name=experiment_branch, source='main'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10fc02f-719a-4ecd-a084-e8172d380e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chaos_repo_path=f\"s3a://{repo_name}/{experiment_branch}/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ab5583b-8ad0-4ba3-8d2e-7796f2b7f380",
   "metadata": {},
   "source": [
    "## Diffing a single branch will show all uncommitted changes on that branch\n",
    "\n",
    "_There are no uncommitted changes yet as all we've done is create the branch_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c596a9e-30d7-4cad-87c2-bb159b92245b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.branches.diff_branch(repository=repo.id, branch='experiment-chaos').results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cfdf8f38-83f9-4302-9a0b-bd4546aa4388",
   "metadata": {},
   "source": [
    "## Load the data from the new branch\n",
    "\n",
    "Whilst reading from a different path, the data is actually just the same as we wrote to the `main` branch above because that's where this branch was created from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acdea15-4b78-4a56-9413-2a24ea4ff2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "books_df = spark.read.format(\"parquet\").load(chaos_repo_path+\"books\")\n",
    "genre_df = spark.read.format(\"parquet\").load(chaos_repo_path+\"genres\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34651bee-34c4-49a6-84ef-09fc7de7464d",
   "metadata": {},
   "source": [
    "### Inspect loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c988f3ba-f824-4928-90bb-dcaff6903e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "books_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f4618-910f-4305-bd1d-a240b40f8e7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "genre_df.show(10, truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8b6b9b9-cfd4-4f14-b28d-7c941419a2b0",
   "metadata": {},
   "source": [
    "## Load data into tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefdbca7-7b9e-495a-bf7c-4c7051bd9bae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8414ca72-3bc5-4907-8e74-17c0628dd7e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "books_df.write.saveAsTable(\"books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b92942-5dbe-49da-a30d-23b81b83661c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c04cb-1aa1-4e62-9e3b-6f5d5d054f24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "genre_df.write.saveAsTable(\"genre\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a765e26-30ed-46a4-b66e-09c24ff440d0",
   "metadata": {},
   "source": [
    "## Join operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202fc1b3-14ea-4293-8906-2b22a1a7b845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = genre_df.join( books_df, genre_df.isbn ==  books_df.isbn, \"left\" ).select(books_df.isbn, books_df.name, books_df.author, genre_df.genre)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad8b3d06-0d1c-4610-ae8f-6d554f97d51d",
   "metadata": {},
   "source": [
    "### Save the materialized view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0636ad39-909f-4730-9ec7-8c119d4b2762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.write.mode('overwrite').parquet(f\"{chaos_repo_path}/books-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56d3f3-7890-4679-88fa-bb8d0f5f104f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.show(20,truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b55df298-19fc-4ad9-8c97-23cf65cf72d3",
   "metadata": {},
   "source": [
    "## Run Quality checks on the experimentation brach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd182f36-0673-449c-b87d-f6af537a7787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in data.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3711b4f6-1804-4fc1-bd6b-a415589595c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dc0df7-38c5-4e21-a569-38454e6674a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "genre_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56723a23-f396-4609-8c5e-4a42ecff6ab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "books_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6fff3-605d-40cb-a7de-5f8fcddce730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "genre_df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a52ac4e-89bf-4da9-93b7-093e39b4d15d",
   "metadata": {},
   "source": [
    "## Join operation #2nd try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec85a33-fe8c-43eb-b865-bf89f4b6f5d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_v2 = books_df.join( genre_df, genre_df.isbn ==  books_df.isbn, \"left\" ).select(books_df.isbn, books_df.name, books_df.author, genre_df.genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9b445f-85af-4ea7-a631-33989320cfc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "data_v2.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in data_v2.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51abc370-8b42-4ff5-8f49-4d78b500969b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "genre_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3387a-c532-4ebc-9f20-c468679929cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "books_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79a2ef9-bc66-4132-b855-dcc745befac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "763394ca-844d-48b0-a4d1-8cdf3289dace",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fix missed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc923c5d-0e46-42df-b778-3ee705574e49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_v3 = data_v2.fillna(\"classics\",subset=[\"genre\"])\n",
    "data_v3.write.mode('overwrite').parquet(chaos_repo_path+\"books-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a677bc-e55b-44cc-b86d-56bd5487ad0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.branches.diff_branch(repository=repo_name, branch=experiment_branch).results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5a72e64-42a3-4887-a938-5670a897e07c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Git like interface - Branching out\n",
    "\n",
    "![](https://docs.lakefs.io/assets/img/branching_7.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4695d1b7-31f0-4dde-b85f-3521a347e3c4",
   "metadata": {},
   "source": [
    "## Cross collection consistency\n",
    "We often need consistency between different data collections. A few examples may be:\n",
    "\n",
    "* To join different collections in order to create a unified view of an account, a user or another entity we measure.\n",
    "* To introduce the same data in different formats\n",
    "* To introduce the same data with a different leading index or sorting due to performance considerations\n",
    "\n",
    "![](https://docs.lakefs.io/assets/img/branching_8.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "765fc9c6-c8f2-4b75-8e5e-f7af1dcd6e36",
   "metadata": {},
   "source": [
    "## More Questions?\n",
    "\n",
    "**👉🏻 Join the lakeFS Slack group - https://lakefs.io/slack**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
