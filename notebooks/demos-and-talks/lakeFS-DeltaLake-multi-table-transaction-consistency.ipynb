{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "28490dd9-995c-4769-9eaa-f22de5e99230",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#  Level Up Your Data Lakehouse \n",
    "#  with Data Source Control and \n",
    "#  Cross Collection Consistency\n",
    "\n",
    "<img src=\"https://pages.databricks.com/rs/094-YMS-629/images/delta-lake-logo-whitebackground.png\" width=300/>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/Heart_coraz%C3%B3n.svg/1200px-Heart_coraz%C3%B3n.svg.png\" width=100/> \n",
    "<img src=\"https://github.com/treeverse/lakeFS/blob/master/docs/assets/img/logo_large.png?raw=true\" width=400/>\n",
    "\n",
    "\n",
    "This is a companion notebook to walktrough the power of combining Delta Lake and lakeFS for you Data & ML workloads.\n",
    "* This notebook has been tested with *DBR 7.3 LTS, Python 3*, Scala 2.12\n",
    "* You will need a lakeFS installation  checkout -> [docs.lakefs.io](http://docs.lakefs.io/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_ðŸš§ This notebook may have existing environment or data requirements; it's included here so that you can see the contents and be inspired by itâ€”but it may not run properly.ðŸš§_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3702b9bc-400a-49cd-8317-e7ceecaa0be3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# What is a Data Lakehouse ?\n",
    "\n",
    "Data Lakehouse is combining the best elements of data lakes and data warehouse into a single platform to assist data teams to operate efficiently. \n",
    "With this modern data stack and Lakehouse capabilities, we can enable multiple types of data transformations to co-exist, while eliminating the data silos in data teams. That means better data flows, simpler operational maintenance, and overall better data products!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3084916d-7453-40f8-bd6a-07cfc66b6275",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ![Delta Lake Tiny Logo](https://pages.databricks.com/rs/094-YMS-629/images/delta-lake-tiny-logo.png) Delta Lake\n",
    "\n",
    "Optimization Layer a top blob storage for Reliability (i.e. ACID compliance) and Low Latency of Streaming + Batch data pipelines."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c029686f-ae97-4ea2-aa98-ab8438a89929",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#What is lakeFS ?\n",
    "lakeFS is an open-source project that provides a git-like version control interface for data lakes, with seamless integration to most data tools and frameworks.\n",
    "\n",
    "lakeFS enables you to easily implement parallel pipelines for experimentation, reproducibility and CI/CD for data.\n",
    "\n",
    "lakeFS supports AWS S3, Azure Blob Storage and Google Cloud Storage (GCS) as its underlying storage service. It is API compatible with S3 and works seamlessly with all modern data frameworks such as Spark, Hive, AWS Athena, Presto, etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "db3cafc3-ddfe-44cb-8354-5440a94e9119",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# What is a Cross Collection Consistency ? \n",
    "\n",
    "Consistency between different data collections. A few examples may be:\n",
    "\n",
    "* To join different collections in order to create a unified view of an account, a user or another entity we measure.\n",
    "* To introduce the same data in different formats\n",
    "* To introduce the same data with a different leading index or sorting due to performance considerations\n",
    "\n",
    "<img src=\"https://lakefs.io/wp-content/uploads/2022/02/level2-git-for-data-lakefs-data-lake-1.png\" width=900/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f66b8b48-4023-453b-b24e-80126c192f1d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## The Data\n",
    "\n",
    "The data used is public data from Lending Club. It includes all funded loans from 2012 to 2017. Each loan includes applicant information provided by the applicant as well as the current loan status (Current, Late, Fully Paid, etc.) and latest payment information. For a full view of the data please view the data dictionary available [here](https://resources.lendingclub.com/LCDataDictionary.xlsx).\n",
    "\n",
    "\n",
    "![Loan_Data](https://preview.ibb.co/d3tQ4R/Screen_Shot_2018_02_02_at_11_21_51_PM.png)\n",
    "\n",
    "https://www.kaggle.com/wendykan/lending-club-loan-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8c5c6c9f-bd30-466d-8211-8bc5cf599b53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configure Delta Lake Silver Path\n",
    "DELTALAKE_SILVER_PATH = \"lakefs://bi-reports/main/tables/loan_by_state/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b56bfc99-76fc-4227-90ee-ef8624a0edb4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM delta.`lakefs://bi-reports/main/tables/loan_by_state/` LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f68433dd-7f2a-4169-87b0-134cdd0fcfdf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM delta.`lakefs://bi-reports/main/tables/loan_payments/` LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0a19a995-ae85-481e-bf4b-5bc4658f3cf2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM delta.`lakefs://bi-reports/main/tables/loan_details/` LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8fe63964-554e-4ceb-a41c-bfec79500e58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "\n",
    "CREATE TABLE IF NOT EXISTS loan_by_state\n",
    "USING delta\n",
    "LOCATION \"lakefs://bi-reports/main/tables/loan_by_state/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e369c0a0-f7a4-41b0-8af4-05dc1448580c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "DESCRIBE DETAIL delta.`lakefs://bi-reports/main/tables/loan_by_state/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cce90471-6a39-40fc-98e0-b5a252ebf32f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "-- View Delta Lake table\n",
    "SELECT * FROM loan_by_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a7080ac0-522c-4da6-9b5e-34b08b898c74",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Stop the notebook before the streaming cell, in case of a \"run all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9ad2c814-b810-41e5-9f21-22a47c03d86e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit(\"stop\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f25ca97b-e6c8-4a35-8240-3124181c6ffb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls lakefs://bi-reports/main/tables/loan_by_state/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "962722be-7e05-40ef-b15e-587739adb4c8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ![Delta Lake Tiny Logo](https://pages.databricks.com/rs/094-YMS-629/images/delta-lake-tiny-logo.png) Unified Batch and Streaming Source and Sink\n",
    "\n",
    "These cells showcase streaming and batch concurrent queries (inserts and reads)\n",
    "* This notebook will run an `INSERT` every 10s against our `loan_stats` table\n",
    "* We will run two streaming queries concurrently against this data\n",
    "* Note, you can also use `writeStream` but this version is easier to run in DBCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "52068a05-03d9-49e6-b607-7754eb9bdb38",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the insertion of data\n",
    "loan_by_state_readStream = spark.readStream.format(\"delta\").load(DELTALAKE_SILVER_PATH)\n",
    "loan_by_state_readStream.createOrReplaceTempView(\"loan_by_state_readStream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "99dee840-b735-439b-8d3c-bec4d4431481",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select addr_state, sum(`count`) as loans from loan_by_state_readStream group by addr_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6d7eacf0-44da-4f72-9340-09d44995a07a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Wait** until the stream is up and running before executing the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6ae6c24b-628a-4ca7-8f05-9e49836d143e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "i = 1\n",
    "while i <= 6:\n",
    "  # Execute Insert statement\n",
    "  insert_sql = \"INSERT INTO loan_by_state VALUES ('IA', 450)\"\n",
    "  spark.sql(insert_sql)\n",
    "  print('loan_by_state: inserted new row of data, loop: [%s]' % i)\n",
    "    \n",
    "  # Loop through\n",
    "  i = i + 1\n",
    "  time.sleep(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e9c48ac0-4ec7-4f25-8b7b-1e8b0717114f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Note**: Once the previous cell is finished and the state of Iowa is fully populated in the map (in cell 14), click *Cancel* in Cell 14 to stop the `readStream`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "71bc151a-7016-4458-9cdf-bc6e9836ab31",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's review our current set of loans using our map visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d433b5e6-b08d-439a-93a8-e88a4a4975f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Review current loans within the `loan_by_state` Delta Lake table\n",
    "select addr_state, sum(`count`) as loans from loan_by_state group by addr_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f6f87608-4974-482e-8226-b918a6d89f89",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Observe that the Iowa (middle state) has the largest number of loans due to the recent stream of data.  Note that the original `loan_by_state` table is updated as we're reading `loan_by_state_readStream`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e642c4e1-781a-456d-ac5f-f7a3859632a6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##![Delta Lake Logo Tiny](https://pages.databricks.com/rs/094-YMS-629/images/delta-lake-tiny-logo.png) Full DML Support\n",
    "\n",
    "**Note**: Full DML Support is a feature that will be coming soon to Delta Lake; the preview is currently available in Databricks.\n",
    "\n",
    "Delta Lake supports standard DML(Data manipulation language) including UPDATE, DELETE and MERGE INTO providing developers more controls to manage their big datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "64e1bc07-bd87-415a-8752-292b35964710",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's start by creating a traditional Parquet table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2c0cb3c1-0837-4ac3-807b-912b7c245bab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load new DataFrame based on current Delta table\n",
    "lbs_df = sql(\"select * from loan_by_state\")\n",
    "\n",
    "# Save DataFrame to Parquet\n",
    "lbs_df.write.mode(\"overwrite\").parquet(\"/tmp/loan_by_state.parquet\")\n",
    "\n",
    "# Create new table on this parquet data\n",
    "spark.sql(\"drop table if exists loan_by_state_pq\")\n",
    "spark.sql(\"create table loan_by_state_pq using parquet as select * from parquet.`/tmp/loan_by_state.parquet`\")\n",
    "\n",
    "# Review data\n",
    "display(sql(\"select * from loan_by_state_pq\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "84bc57ae-6954-4bb8-9815-fce866090410",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###![Delta Lake Logo Tiny](https://pages.databricks.com/rs/094-YMS-629/images/delta-lake-tiny-logo.png) DELETE Support\n",
    "\n",
    "The data was originally supposed to be assigned to `WA` state, so let's `DELETE` those values assigned to `IA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9a526ae0-3bbe-4ef8-b1d6-57bbb8c6cc9d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Attempting to run `DELETE` on the Parquet table\n",
    "DELETE FROM loan_by_state_pq WHERE addr_state = 'IA'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "93ed9e93-e4b0-4783-b2a4-1e2d4094ce35",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Note**: This command fails because the `DELETE` statements are not supported in Parquet, but are supported in Delta Lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e07b09e3-7e43-4092-9068-1d6815084d42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Running `DELETE` on the Delta Lake table\n",
    "DELETE FROM loan_by_state WHERE addr_state = 'IA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dd7e5daf-a6eb-401b-afd6-693ab5d3ce96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Review current loans within the `loan_by_state` Delta Lake table\n",
    "select addr_state, sum(`count`) as loans from loan_by_state group by addr_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a51154cd-87df-4991-a4ff-63678a451143",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###![Delta Lake Logo Tiny](https://pages.databricks.com/rs/094-YMS-629/images/delta-lake-tiny-logo.png) UPDATE Support\n",
    "The data was originally supposed to be assigned to `WA` state, so let's `UPDATE` those values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3e504b63-1611-463e-8209-6dfb96a381c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Attempting to run `UPDATE` on the Parquet table\n",
    "UPDATE loan_by_state_pq SET `count` = 2700 WHERE addr_state = 'WA'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "81741770-b866-457b-b9e5-8b44d08c28c3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Note**: This command fails because the `UPDATE` statements are not supported in Parquet, but are supported in Delta Lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6e7726ac-c63d-486b-af07-2c13446e7895",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Running `UPDATE` on the Delta Lake table\n",
    "UPDATE loan_by_state SET `count` = 2700 WHERE addr_state = 'WA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7cafea67-27ab-4e74-b2c5-13df55c37cf6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Review current loans within the `loan_by_state` Delta Lake table\n",
    "select addr_state, sum(`count`) as loans from loan_by_state group by addr_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "50c04ac8-996f-4a02-bfc6-a1bee66a20de",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###![Delta Lake Logo Tiny](https://pages.databricks.com/rs/094-YMS-629/images/delta-lake-tiny-logo.png) MERGE INTO Support\n",
    "\n",
    "#### INSERT or UPDATE parquet: 7-step process\n",
    "\n",
    "With a legacy data pipeline, to insert or update a table, you must:\n",
    "1. Identify the new rows to be inserted\n",
    "2. Identify the rows that will be replaced (i.e. updated)\n",
    "3. Identify all of the rows that are not impacted by the insert or update\n",
    "4. Create a new temp based on all three insert statements\n",
    "5. Delete the original table (and all of those associated files)\n",
    "6. \"Rename\" the temp table back to the original table name\n",
    "7. Drop the temp table\n",
    "\n",
    "![](https://pages.databricks.com/rs/094-YMS-629/images/merge-into-legacy.gif)\n",
    "\n",
    "\n",
    "#### INSERT or UPDATE with Delta Lake\n",
    "\n",
    "2-step process: \n",
    "1. Identify rows to insert or update\n",
    "2. Use `MERGE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c0d995e4-72f7-488d-884f-88521d2c76ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's create a simple table to merge\n",
    "items = [('IA', 10), ('CA', 2500), ('OR', None)]\n",
    "cols = ['addr_state', 'count']\n",
    "merge_table = spark.createDataFrame(items, cols)\n",
    "merge_table.createOrReplaceTempView(\"merge_table\")\n",
    "display(merge_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cfa8637f-d899-4cab-851f-f7b282fce13b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Instead of writing separate `INSERT` and `UPDATE` statements, we can use a `MERGE` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c32848b9-d725-4f40-9db9-a5644317b02d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "MERGE INTO loan_by_state as d\n",
    "USING merge_table as m\n",
    "on d.addr_state = m.addr_state\n",
    "WHEN MATCHED THEN \n",
    "  UPDATE SET *\n",
    "WHEN NOT MATCHED \n",
    "  THEN INSERT *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "716c175a-4290-4eec-abf6-37986a6521db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Review current loans within the `loan_by_state` Delta Lake table\n",
    "select addr_state, sum(`count`) as loans from loan_by_state group by addr_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "234babab-0a9d-4419-8f76-4daed921e0e6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##![Delta Lake Logo Tiny](https://pages.databricks.com/rs/094-YMS-629/images/delta-lake-tiny-logo.png) Schema Evolution\n",
    "With the `mergeSchema` option, you can evolve your Delta Lake table schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "61166f6b-4689-422f-b090-b7225e6a7db5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate new loans with dollar amounts \n",
    "loans = sql(\"select addr_state, cast(rand(10)*count as bigint) as count, cast(rand(10) * 10000 * count as double) as amount from loan_by_state\")\n",
    "display(loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e54a6629-0243-4fc8-95ee-bed104deb8ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's write this data out to our Delta table\n",
    "loans.write.format(\"delta\").mode(\"append\").save(DELTALAKE_SILVER_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "05e3c3de-f00d-4c9e-919a-1d79de3a422e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Note**: This command fails because the schema of our new data does not match the schema of our original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "351070f9-6bf0-4b63-8cac-bbede41ac19f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add the mergeSchema option\n",
    "loans.write.option(\"mergeSchema\",\"true\").format(\"delta\").mode(\"append\").save(DELTALAKE_SILVER_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9ea7ae33-879a-4dee-8873-744a386e34a7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Note**: With the `mergeSchema` option, we can merge these different schemas together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5b389d37-d0b2-4f8c-9e66-d42b119bd8b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Review current loans within the `loan_by_state` Delta Lake table\n",
    "select addr_state, sum(`amount`) as amount from loan_by_state group by addr_state order by sum(`amount`) desc limit 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6863370c-1ff1-4a59-8423-68d52cacd363",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ![Delta Lake Tiny Logo](https://pages.databricks.com/rs/094-YMS-629/images/delta-lake-tiny-logo.png) Let's Travel back in Time!\n",
    "Databricks Deltaâ€™s time travel capabilities simplify building data pipelines for the following use cases. \n",
    "\n",
    "* Audit Data Changes\n",
    "* Reproduce experiments & reports\n",
    "* Rollbacks\n",
    "\n",
    "As you write into a Delta table or directory, every operation is automatically versioned.\n",
    "\n",
    "You can query by:\n",
    "1. Using a timestamp\n",
    "1. Using a version number\n",
    "\n",
    "using Python, Scala, and/or Scala syntax; for these examples we will use the SQL syntax.  \n",
    "\n",
    "For more information, refer to [Introducing Delta Time Travel for Large Scale Data Lakes](https://databricks.com/blog/2019/02/04/introducing-delta-time-travel-for-large-scale-data-lakes.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a452f7ac-1450-4218-b46e-9c0f804e7c16",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### ![Delta Lake Tiny Logo](https://pages.databricks.com/rs/094-YMS-629/images/delta-lake-tiny-logo.png) Review Delta Lake Table History\n",
    "All the transactions for this table are stored within this table including the initial set of insertions, update, delete, merge, and inserts with schema modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8109d63a-e186-4a52-bde4-efbbbf4c0bc5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY loan_by_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "351ac819-9b30-4e2d-8aa8-eb2268b3d337",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### ![Delta Lake Tiny Logo](https://pages.databricks.com/rs/094-YMS-629/images/delta-lake-tiny-logo.png) Time Travel via Version Number\n",
    "Below are SQL syntax examples of Delta Time Travel by using a Version Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "52c6cf55-2a0d-4802-8603-abd1c3463555",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM loan_by_state VERSION AS OF 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "01c34081-9042-48de-87e8-439e69098c59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM loan_by_state VERSION AS OF 9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "70ad4769-1e7a-41e6-a4c1-3c7cc1da0f38",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Run Our Model\n",
    "Let's run a simple linear regression model to predict the number of loans based on the population of the state\n",
    "* The following shell statements downloads the us_census_2020 data that we will join with the `loan_by_state` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6f2f6bcf-c277-4684-93d4-2449df52b8d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh mkdir -p /dbfs/tmp/sais_eu_19_demo/census/ && wget -O /dbfs/tmp/sais_eu_19_demo/census/us_census_2010.csv https://pages.databricks.com/rs/094-YMS-629/images/us_census_2010.csv && ls -al /dbfs/tmp/sais_eu_19_demo/census/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "557634f3-25da-4f3e-b38d-552849b4e5d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.cp(\"file:/dbfs/tmp/sais_eu_19_demo/census\", \"dbfs:/tmp/sais_eu_19_demo/census/\", recurse=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "52b20350-de4a-4fa1-b278-43a2b401189c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Notes\n",
    "If you forgot to install `mlflow` and `yellowbrick` on your cluster, instead of re-running everything all over again:\n",
    "* Note that the Delta Lake table is stored in `DELTALAKE_SILVERPATH` or `/ml/loan_by_state`\n",
    "* You can add the libraries, restart the cluster and then start reading the data from the following cells (instead of rerunning everything all over again)\n",
    "* Just uncomment the cell below to reconnect to your Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bbe85def-a117-4056-83ff-7405905d0eb0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dda96809-a804-40a3-8674-2de16ac19144",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Recreate loan_by_state view\n",
    "spark.read.format(\"delta\").load(\"/ml/loan_by_state\").createOrReplaceTempView(\"loan_by_state\")\n",
    "# Check data\n",
    "display(spark.sql(\"select count(1) from loan_by_state\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0e84edc1-8d2a-4d7d-86f4-9cb73896ab3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Include census data\n",
    "census = spark.read.csv('/tmp/sais_eu_19_demo/census/us_census_2010.csv', sep=',', inferSchema=True, header=True)\n",
    "census.createOrReplaceTempView(\"census\")\n",
    "\n",
    "# Data versions (0, 6, 9)\n",
    "dfv0 = spark.sql(\"select c.Population, l.count as label from (select addr_state as State, count from loan_by_state  version as of 0) l left outer join census c on c.State = l.State\")\n",
    "dfv6 = spark.sql(\"select c.Population, l.count as label from (select addr_state as State, count from loan_by_state  version as of 6) l left outer join census c on c.State = l.State\")\n",
    "dfv9 = spark.sql(\"select c.Population, l.count as label from (select addr_state as State, count from loan_by_state  version as of 9 where count is not null) l left outer join census c on c.State = l.State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "447f97c9-1ab3-4c0a-a576-c8aaaf1d25bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate predictions\n",
    "# Initial version of data (v0)\n",
    "predictLoanCount(dfv0, 'v0')\n",
    "\n",
    "# Version 6 (after streaming of Iowa data)\n",
    "displayResiduals(dfv0, dfv6)\n",
    "predictLoanCount(dfv6, 'v6')\n",
    "\n",
    "# Version 9 (after correction of data: update, delete, merge)\n",
    "displayResiduals(dfv0, dfv9)\n",
    "predictLoanCount(dfv9, 'v9')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "lakeFS - DeltaLake session (1)",
   "notebookOrigID": 864406934323209,
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
