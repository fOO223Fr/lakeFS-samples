{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2871c4c7",
   "metadata": {},
   "source": [
    "<img src=\"./images/logo.svg\" alt=\"lakeFS logo\" width=300/> \n",
    "\n",
    "# ML Experimentation 02 (Wine Quality)\n",
    "\n",
    "In this tutorial, you will learn how to version your ML training data, model artifacts, metrics and your training code together with lakeFS. We will be using [Wine-Quality-Dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality) for the multi class classification \n",
    "\n",
    "To learn more about how lakeFS can be used for ML experimentation and reproducibility, check out the [published blog](https://lakefs.io/blog/building-an-ml-experimentation-platform-for-easy-reproducibility-using-lakefs/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251d5405",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "**_If you're not using the provided lakeFS server and MinIO storage then change these values to match your environment_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e50753",
   "metadata": {},
   "source": [
    "### lakeFS endpoint and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab50223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefsEndPoint = 'http://lakefs:8000' # e.g. 'https://username.aws_region_name.lakefscloud.io' \n",
    "lakefsAccessKey = 'AKIAIOSFODNN7EXAMPLE'\n",
    "lakefsSecretKey = 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3275a1",
   "metadata": {},
   "source": [
    "### Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc8b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storageNamespace = 's3://example' # e.g. \"s3://bucket\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c81d5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5ba145",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "**(you shouldn't need to change anything in this section, just run it)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b81bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_name = \"ml-experimentation-wine-quality\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7239dca6",
   "metadata": {},
   "source": [
    "### Create lakeFSClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d0d465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lakefs_client\n",
    "from lakefs_client.models import *\n",
    "from lakefs_client.client import LakeFSClient\n",
    "\n",
    "# lakeFS credentials and endpoint\n",
    "configuration = lakefs_client.Configuration()\n",
    "configuration.username = lakefsAccessKey\n",
    "configuration.password = lakefsSecretKey\n",
    "configuration.host = lakefsEndPoint\n",
    "\n",
    "lakefs = LakeFSClient(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30db010",
   "metadata": {},
   "source": [
    "#### Verify lakeFS credentials by getting lakeFS version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0288ecd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Verifying lakeFS credentials‚Ä¶\")\n",
    "try:\n",
    "    v=lakefs.config.get_lake_fs_version()\n",
    "except:\n",
    "    print(\"üõë failed to get lakeFS version\")\n",
    "else:\n",
    "    print(f\"‚Ä¶‚úÖlakeFS credentials verified\\n\\n‚ÑπÔ∏èlakeFS version {v.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f17b5",
   "metadata": {},
   "source": [
    "### Define lakeFS Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe1b04f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lakefs_client.exceptions import NotFoundException\n",
    "\n",
    "try:\n",
    "    repo=lakefs.repositories.get_repository(repo_name)\n",
    "    print(f\"Found existing repo {repo.id} using storage namespace {repo.storage_namespace}\")\n",
    "except NotFoundException as f:\n",
    "    print(f\"Repository {repo_name} does not exist, so going to try and create it now.\")\n",
    "    try:\n",
    "        repo=lakefs.repositories.create_repository(repository_creation=RepositoryCreation(name=repo_name,\n",
    "                                                                                                storage_namespace=f\"{storageNamespace}/{repo_name}\"))\n",
    "        print(f\"Created new repo {repo.id} using storage namespace {repo.storage_namespace}\")\n",
    "    except lakefs_client.ApiException as e:\n",
    "        print(f\"Error creating repo {repo_name}. Error is {e}\")\n",
    "        os._exit(00)\n",
    "except lakefs_client.ApiException as e:\n",
    "    print(f\"Error getting repo {repo_name}: {e}\")\n",
    "    os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d941bb",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6175ebb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import date, time, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef803a82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import csv\n",
    "import duckdb\n",
    "import s3fs\n",
    "import json\n",
    "import tempfile\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eaf293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa3efd-2c1c-4e0f-acb2-ec84ea5f2744",
   "metadata": {},
   "source": [
    "### Configure boto3 client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c356ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3',\n",
    "    endpoint_url=lakefsEndPoint,\n",
    "    aws_access_key_id=lakefsAccessKey,\n",
    "    aws_secret_access_key=lakefsSecretKey)\n",
    "\n",
    "s3_resource = boto3.resource('s3',\n",
    "    endpoint_url=lakefsEndPoint,\n",
    "    aws_access_key_id=lakefsAccessKey,\n",
    "    aws_secret_access_key=lakefsSecretKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5952a460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = s3fs.S3FileSystem(anon=False,\n",
    "                      key=lakefsAccessKey,\n",
    "                      secret=lakefsSecretKey,\n",
    "                      client_kwargs={'endpoint_url': lakefsEndPoint})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f4e0b6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744be8ac",
   "metadata": {},
   "source": [
    "# Main Tutorial starts here üö¶ üëáüèª"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d07acc4",
   "metadata": {},
   "source": [
    "# Creating Ingest branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997200c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingest_branch = \"ingest-data\"\n",
    "prod_branch = \"main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2681e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.branches.create_branch(repository=repo_name, \n",
    "                              branch_creation=BranchCreation(name=ingest_branch, \n",
    "                                                                    source=prod_branch)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22215b",
   "metadata": {},
   "source": [
    "# Upload wine-quality-dataset to ingest branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897649d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingest_data = \"wine-quality-white-and-red.csv\"\n",
    "ingest_path = f'dt={str(date.today())}/raw/{ingest_data}' \n",
    "ingest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87b305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'/data/{ingest_data}', 'rb') as f:     \n",
    "    lakefs.objects.upload_object(repository=repo_name, \n",
    "                                 branch=ingest_branch, \n",
    "                                 path=ingest_path, \n",
    "                                 content=f\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd829e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.branches.diff_branch(repository=repo_name, \n",
    "                            branch=ingest_branch).results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c0e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch=ingest_branch,\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message=\"wine quality data uploaded to ingest branch\")\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf4dd66",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c40a330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = f\"s3://{repo_name}/{ingest_branch}/{ingest_path}\"\n",
    "print(filepath)\n",
    "\n",
    "obj = s3_client.get_object(Bucket=repo_name, Key=f'{ingest_branch}/{ingest_path}')\n",
    "wine_df = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')\n",
    "wine_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76cf3c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fb4ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.pairplot(wine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17376a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Counter(wine_df['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b2457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='quality', data=wine_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db7cf1f",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4914f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_input(x):\n",
    "    sc = StandardScaler()\n",
    "    x = sc.fit_transform(x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb2ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_pca(pca):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_), 'ro-')\n",
    "    plt.grid()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5292c3",
   "metadata": {},
   "source": [
    "# Experimentation Begins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e842d8",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dda0ce2",
   "metadata": {},
   "source": [
    "- Preprocess - Standard Scaler, PCA\n",
    "- Training - RandomForestClassifier\n",
    "- Evaluation - F1 score\n",
    "- Labels - Multiclass classification (quality: 1 to 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1afec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'branch_name': 'exp-1',\n",
    "    'drop_columns': ['type'],\n",
    "    'f1_average': 'micro', #imbalance class problem\n",
    "    'is_scale_input': True,\n",
    "    'is_pca': True,\n",
    "    'test_size': '0.25'\n",
    "}\n",
    "params1 = config\n",
    "\n",
    "filepath = f\"s3://{repo_name}/{params1['branch_name']}/{ingest_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be968799",
   "metadata": {},
   "source": [
    "### Create new branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17c688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "lakefs.branches.create_branch(repository=repo_name, \n",
    "                              branch_creation=BranchCreation(name=params1['branch_name'], \n",
    "                                                                    source=ingest_branch)\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ddc105",
   "metadata": {},
   "source": [
    "### Save configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3820da59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_df = pd.DataFrame.from_dict(params1)\n",
    "config_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d689a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with s3.open(f\"/{repo_name}/{params1['branch_name']}/dt={str(date.today())}/config/config.csv\",'w') as f:\n",
    "    config_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75852313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch=params1['branch_name'],\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message=\"Uploaded training configs\")\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2c03e7",
   "metadata": {},
   "source": [
    "### Create model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb35e42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=repo_name, Key=f\"{params1['branch_name']}/{ingest_path}\")\n",
    "wine_df = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455945c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc98c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wine_df.drop(columns=['type'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d35037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = wine_df.iloc[:,:11]\n",
    "y = wine_df['quality']\n",
    "y_col = ['quality']\n",
    "x_cols = [col for col in x.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb371793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if params1['is_scale_input']:\n",
    "    x = scale_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467a06c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5fc611",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if params1['is_pca']:\n",
    "    pca = PCA()\n",
    "    x_pca = pca.fit_transform(x)\n",
    "    plot_pca(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0454a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if params1['is_pca']:\n",
    "    n_comp = 6\n",
    "    pca_new = PCA(n_components=n_comp)\n",
    "    x = pca_new.fit_transform(x)\n",
    "    x_cols = [f\"pca_{i}\" for i in range(n_comp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecedcd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7387d6d",
   "metadata": {},
   "source": [
    "### Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc99e36b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame(x, columns = x_cols)\n",
    "label = pd.DataFrame(y, columns = y_col)\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5c148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddcc121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with s3.open(f\"/{repo_name}/{params1['branch_name']}/dt={str(date.today())}/features/features.csv\",'w') as f:\n",
    "    features.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1a17c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with s3.open(f\"/{repo_name}/{params1['branch_name']}/dt={str(date.today())}/features/label.csv\",'w') as f:\n",
    "    label.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10bb03e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch=params1['branch_name'],\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message=\"Uploaded features\")\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d452ff",
   "metadata": {},
   "source": [
    "### Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a8260",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "x_train = pd.DataFrame(x_train, columns = x_cols)\n",
    "x_test = pd.DataFrame(x_test, columns = x_cols)\n",
    "y_train = pd.DataFrame(y_train, columns = y_col)\n",
    "y_test = pd.DataFrame(y_test, columns = y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15257f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db104eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with s3.open(f\"/{repo_name}/{params1['branch_name']}/dt={str(date.today())}/preprocessed/x_train.csv\",'w') as f:\n",
    "    x_train.to_csv(f)\n",
    "    \n",
    "    \n",
    "with s3.open(f\"/{repo_name}/{params1['branch_name']}/dt={str(date.today())}/preprocessed/x_test.csv\",'w') as f:\n",
    "    x_test.to_csv(f)\n",
    "    \n",
    "    \n",
    "with s3.open(f\"/{repo_name}/{params1['branch_name']}/dt={str(date.today())}/preprocessed/y_train.csv\",'w') as f:\n",
    "    y_train.to_csv(f)\n",
    "    \n",
    "    \n",
    "with s3.open(f\"/{repo_name}/{params1['branch_name']}/dt={str(date.today())}/preprocessed/y_test.csv\",'w') as f:\n",
    "    y_test.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1890a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "rf_predict=rf.predict(x_test)\n",
    "\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_predict)\n",
    "rf_f1_score = f1_score(y_test, rf_predict, average=params1['f1_average'])\n",
    "print(rf_conf_matrix)\n",
    "print(\"\\nF1-score: \\t\", round(rf_f1_score*100,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24490dd",
   "metadata": {},
   "source": [
    "### Save model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05301a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_file = os.path.join(f\"s3://{repo_name}/{params1['branch_name']}/dt={str(date.today())}/artifacts/\", \"model.joblib\")\n",
    "print(output_file)\n",
    "\n",
    "with s3.open(output_file, 'wb') as f:\n",
    "    joblib.dump(rf, f) \n",
    "\n",
    "# # Read\n",
    "# with s3.open(output_file, 'rb') as f:\n",
    "#     rf = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b6e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch=params1['branch_name'],\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message=\"Uploaded model artifacts\")\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9748ee0",
   "metadata": {},
   "source": [
    "### Save model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b2296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame.from_dict({'f1': [rf_f1_score]})\n",
    "with s3.open(f\"/{repo_name}/{params1['branch_name']}/dt={str(date.today())}/metrics/scores.csv\",'w') as f:\n",
    "    metrics_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1b7431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch=params1['branch_name'],\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message=\"Uploaded training metrics\")\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218a4dd7",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a690bb05",
   "metadata": {},
   "source": [
    "- Preprocess - Regroup labels\n",
    "- Training - RandomForestClassifier\n",
    "- Evaluation - F1 score\n",
    "- Labels - Multiclass classification (quality: Bad, Okay, Good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96df3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'branch_name': 'exp-2',\n",
    "    'drop_columns': ['type'],\n",
    "    'f1_average': 'weighted', #imbalance class problem\n",
    "    'is_scale_input': False,\n",
    "    'is_pca': False,\n",
    "    'test_size': '0.25'\n",
    "}\n",
    "params2 = config\n",
    "\n",
    "filepath = f\"s3://{repo_name}/{params2['branch_name']}/{ingest_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65107bda",
   "metadata": {},
   "source": [
    "### Create new branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b3e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.branches.create_branch(repository=repo_name, \n",
    "                              branch_creation=BranchCreation(name=params2['branch_name'], \n",
    "                                                                    source=ingest_branch)\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c6aa71",
   "metadata": {},
   "source": [
    "### Save configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16a3028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_df = pd.DataFrame.from_dict(params2)\n",
    "config_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d108ec75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with s3.open(f\"/{repo_name}/{params2['branch_name']}/dt={str(date.today())}/config/config.csv\",'w') as f:\n",
    "    config_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efee1e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch=params2['branch_name'],\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message=\"Uploaded training configs\")\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c032e7c",
   "metadata": {},
   "source": [
    "### Create model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be7af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=repo_name, Key=f\"{params2['branch_name']}/{ingest_path}\")\n",
    "wine_df = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d2546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9eb7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wine_df.drop(columns=['type'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3550dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for i in wine_df['quality']:\n",
    "    if i >= 1 and i <= 3:\n",
    "        reviews.append('1')\n",
    "    elif i >= 4 and i <= 6:\n",
    "        reviews.append('2')\n",
    "    elif i >= 7 and i <= 10:\n",
    "        reviews.append('3')\n",
    "wine_df['reviews'] = reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be61f108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = wine_df.iloc[:,:11]\n",
    "y = wine_df['reviews']\n",
    "y_col = ['reviews']\n",
    "x_cols = [col for col in x.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99ee196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4304c7e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28660bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=y, data=wine_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f2af22",
   "metadata": {},
   "source": [
    "### Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126b24be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame(x, columns = x_cols)\n",
    "label = pd.DataFrame(y, columns = y_col)\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f5511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806b4483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with s3.open(f\"/{repo_name}/{params2['branch_name']}/dt={str(date.today())}/features/features.csv\",'w') as f:\n",
    "    features.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2732865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with s3.open(f\"/{repo_name}/{params2['branch_name']}/dt={str(date.today())}/features/label.csv\",'w') as f:\n",
    "    label.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba03611a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch=params2['branch_name'],\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message=\"Uploaded features\")\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f8fbb",
   "metadata": {},
   "source": [
    "### Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d7ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "x_train = pd.DataFrame(x_train, columns = x_cols)\n",
    "x_test = pd.DataFrame(x_test, columns = x_cols)\n",
    "y_train = pd.DataFrame(y_train, columns = y_col)\n",
    "y_test = pd.DataFrame(y_test, columns = y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b339c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with s3.open(f\"/{repo_name}/{params2['branch_name']}/dt={str(date.today())}/preprocessed/x_train.csv\",'w') as f:\n",
    "    x_train.to_csv(f)\n",
    "    \n",
    "    \n",
    "with s3.open(f\"/{repo_name}/{params2['branch_name']}/dt={str(date.today())}/preprocessed/x_test.csv\",'w') as f:\n",
    "    x_test.to_csv(f)\n",
    "    \n",
    "    \n",
    "with s3.open(f\"/{repo_name}/{params2['branch_name']}/dt={str(date.today())}/preprocessed/y_train.csv\",'w') as f:\n",
    "    y_train.to_csv(f)\n",
    "    \n",
    "    \n",
    "with s3.open(f\"/{repo_name}/{params2['branch_name']}/dt={str(date.today())}/preprocessed/y_test.csv\",'w') as f:\n",
    "    y_test.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5ec66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "rf_predict=rf.predict(x_test)\n",
    "\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_predict)\n",
    "rf_f1_score = f1_score(y_test, rf_predict, average='weighted')\n",
    "print(rf_conf_matrix)\n",
    "print(\"F1-score: \\t\", round(rf_f1_score*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623def87",
   "metadata": {},
   "source": [
    "### Save model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac0644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_file = os.path.join(f\"s3://{repo_name}/{params2['branch_name']}/dt={str(date.today())}/artifacts/\", \"model.joblib\")\n",
    "print(output_file)\n",
    "\n",
    "with s3.open(output_file, 'wb') as f:\n",
    "    joblib.dump(rf, f) \n",
    "\n",
    "# # Read\n",
    "# with s3.open(output_file, 'rb') as f:\n",
    "#     rf = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4041ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch=params2['branch_name'],\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message=\"Uploaded model artifacts\")\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa126f1f",
   "metadata": {},
   "source": [
    "### Save model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a4b160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame.from_dict({'f1': [rf_f1_score]})\n",
    "with s3.open(f\"/{repo_name}/{params2['branch_name']}/dt={str(date.today())}/metrics/scores.csv\",'w') as f:\n",
    "    metrics_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679158e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.commits.commit(repository=repo_name,\n",
    "                      branch=params2['branch_name'],\n",
    "                      commit_creation=CommitCreation(\n",
    "                          message=\"Uploaded training metrics\")\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9722b",
   "metadata": {},
   "source": [
    "### Reproduce an experiment with lakeFS tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51130d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tag_branch = \"exp-1\"\n",
    "tag = f'{datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")}_{tag_branch}'\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549fe159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.tags.create_tag(\n",
    "    repository=repo_name,\n",
    "    tag_creation=TagCreation(\n",
    "        id=tag, \n",
    "        ref=tag_branch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5385c729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_path = f\"{tag}/dt={str(date.today())}/features/features.csv\"\n",
    "label_path = f\"{tag}/dt={str(date.today())}/features/label.csv\"\n",
    "print(features_path,\"\\n\",label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb2df7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_path = f\"{tag}/dt={str(date.today())}/preprocessed/x_train.csv\"\n",
    "x_test_path = f\"{tag}/dt={str(date.today())}/preprocessed/x_test.csv\"\n",
    "y_train_path = f\"{tag}/dt={str(date.today())}/preprocessed/y_train.csv\"\n",
    "y_test_path = f\"{tag}/dt={str(date.today())}/preprocessed/y_test.csv\"\n",
    "print(x_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7daa91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=repo_name, Key=x_train_path)\n",
    "x_train = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')\n",
    "x_train.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2cb63f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=repo_name, Key=x_test_path)\n",
    "x_test = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')\n",
    "x_test.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a96ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=repo_name, Key=y_train_path)\n",
    "y_train = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')\n",
    "y_train.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e1e71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=repo_name, Key=y_test_path)\n",
    "y_test = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')\n",
    "y_test.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ead57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=repo_name, Key=features_path)\n",
    "features = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')\n",
    "features.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46c2641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=repo_name, Key=label_path)\n",
    "label = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')\n",
    "label.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61328a88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_file = os.path.join(f\"s3://{repo_name}/{tag}/dt={str(date.today())}/artifacts/\", \"model.joblib\")\n",
    "print(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b9a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read\n",
    "with s3.open(output_file, 'rb') as f:\n",
    "    rf = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b68161b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_predict=rf.predict(x_test)\n",
    "\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_predict)\n",
    "rf_f1_score = f1_score(y_test, rf_predict, average=params1['f1_average'])\n",
    "print(rf_conf_matrix)\n",
    "print(\"\\nF1-score: \\t\", round(rf_f1_score*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2500e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
